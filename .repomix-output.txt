This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-25T18:37:00.402Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
mcp-server/src/capabilities/resources/
mcp-server/src/test/
src/services/
.eslintrc.json
.gitignore
.prettierrc
dependencies.md
docs/web-search-tool.md
jest.config.js
LICENSE
local-research/codebase-analysis.md
local-research/cursor-tools-analysis.md
local-research/cursor-tools-implementation.md
local-research/dependencies-installation-guide.md
local-research/dependencies-research.md
local-research/mcp-clarifications.md
local-research/mcp-detailed-steps.md
local-research/mcp-final-recommendations.md
local-research/mcp-final-review.md
local-research/mcp-implementation-plan.md
local-research/mcp-installation-research.md
local-research/mcp-plan.md
local-research/mcp-research.md
local-research/mcp-setup-guide.md
local-research/mcp-user-experience.md
local-research/typescript-esm-config.md
mcp-server/.eslintrc.json
mcp-server/.prettierrc
mcp-server/.repomix-output.txt
mcp-server/jest.config.js
mcp-server/local-research/implementation-plan.md
mcp-server/local-research/mcp-implementation-research.md
mcp-server/local-research/typescript-esm-research.md
mcp-server/package.json
mcp-server/src/capabilities/tools/__tests__/web-search.test.ts
mcp-server/src/capabilities/tools/web-search.js
mcp-server/src/capabilities/tools/web-search.ts
mcp-server/src/config/index.js
mcp-server/src/config/index.ts
mcp-server/src/gemini/__tests__/service.test.ts
mcp-server/src/gemini/config.ts
mcp-server/src/gemini/service.ts
mcp-server/src/server.js
mcp-server/src/server.ts
mcp-server/src/test-client.js
mcp-server/src/test-client.ts
mcp-server/src/test-setup.js
mcp-server/src/test-setup.ts
mcp-server/src/utils/logger.js
mcp-server/src/utils/logger.ts
mcp-server/src/utils/retry.ts
mcp-server/tsconfig.json
package.json
README.md
src/capabilities/tools/__tests__/web-search.test.ts
src/capabilities/tools/repo-analysis.ts
src/capabilities/tools/web-search.ts
src/config/index.ts
src/server.ts
src/test-client.ts
src/test-setup.ts
src/test/setup.ts
src/types/tool.ts
src/utils/logger.ts
tsconfig.json
wiki-home.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".eslintrc.json">
{
  "env": {
    "node": true,
    "es2021": true
  },
  "extends": [
    "eslint:recommended",
    "plugin:@typescript-eslint/recommended",
    "plugin:prettier/recommended"
  ],
  "parser": "@typescript-eslint/parser",
  "parserOptions": {
    "ecmaVersion": "latest",
    "sourceType": "module"
  },
  "plugins": [
    "@typescript-eslint"
  ],
  "rules": {
    "@typescript-eslint/explicit-function-return-type": "warn",
    "@typescript-eslint/no-unused-vars": ["error", { "argsIgnorePattern": "^_" }],
    "@typescript-eslint/no-explicit-any": "error",
    "no-console": ["warn", { "allow": ["warn", "error"] }]
  }
}
</file>

<file path=".gitignore">
# Dependencies
node_modules/
package-lock.json

# Environment variables and secrets
.env
.env.*
!.env.example
.cursorrules


# Build outputs
dist/
build/
*.tsbuildinfo

# Logs and traces
logs/
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
trace/

# IDE and editor files
.idea/
.vscode/
*.swp
*.swo
*~

# Operating System
.DS_Store
Thumbs.db

# Test coverage
coverage/

# Temporary files
tmp/
temp/
</file>

<file path=".prettierrc">
{
  "semi": true,
  "trailingComma": "es5",
  "singleQuote": true,
  "printWidth": 100,
  "tabWidth": 2,
  "useTabs": false,
  "endOfLine": "auto"
}
</file>

<file path="dependencies.md">
# MCP Server Dependencies

This document lists all dependencies required to build the MCP server, including their versions, purposes, and documentation links.

## Core Dependencies

### Model Context Protocol SDK
- **Package**: `@modelcontextprotocol/sdk`
- **Version**: 1.2.0
- **Purpose**: Core SDK for implementing the Model Context Protocol
- **Documentation**: [MCP SDK Documentation](https://modelcontextprotocol.github.io/sdk/)
- **Installation**: `npm install @modelcontextprotocol/sdk@1.2.0`

### Perplexity API (Web Search)
- **Package**: `perplexity-api`
- **Version**: 1.1.2
- **Purpose**: Integration with Perplexity AI for web search functionality
- **Documentation**: [Perplexity API Documentation](https://docs.perplexity.ai/)
- **Installation**: `npm install perplexity-api@1.1.2`
- **Note**: Requires API key from Perplexity

### GitHub API Client
- **Package**: `@octokit/rest`
- **Version**: 19.0.13
- **Purpose**: GitHub API integration for repository management
- **Documentation**: [Octokit REST Documentation](https://octokit.github.io/rest.js/)
- **Installation**: `npm install @octokit/rest@19.0.13`
- **Note**: Requires GitHub Personal Access Token

### Browser Automation
- **Package**: `playwright`
- **Version**: 1.41.2
- **Purpose**: Browser automation for web interaction and testing
- **Documentation**: [Playwright Documentation](https://playwright.dev/docs/api/class-playwright)
- **Installation**: `npm install playwright@1.41.2`

### HTTP Client
- **Package**: `axios`
- **Version**: 1.6.5
- **Purpose**: Making HTTP requests to external APIs
- **Documentation**: [Axios Documentation](https://axios-http.com/docs/intro)
- **Installation**: `npm install axios@1.6.5`

### Environment Variables
- **Package**: `dotenv`
- **Version**: 16.3.1
- **Purpose**: Loading environment variables from .env files
- **Documentation**: [dotenv Documentation](https://github.com/motdotla/dotenv#readme)
- **Installation**: `npm install dotenv@16.3.1`

## Development Dependencies

### TypeScript
- **Package**: `typescript`
- **Version**: 5.3.3
- **Purpose**: Static typing and modern JavaScript features
- **Documentation**: [TypeScript Documentation](https://www.typescriptlang.org/docs/)
- **Installation**: `npm install --save-dev typescript@5.3.3`

### TypeScript Node
- **Package**: `ts-node`
- **Version**: 10.9.2
- **Purpose**: Running TypeScript files directly
- **Documentation**: [ts-node Documentation](https://typestrong.org/ts-node/docs/)
- **Installation**: `npm install --save-dev ts-node@10.9.2`

### Node.js Types
- **Package**: `@types/node`
- **Version**: 20.11.5
- **Purpose**: TypeScript type definitions for Node.js
- **Documentation**: [Node.js Types Package](https://www.npmjs.com/package/@types/node)
- **Installation**: `npm install --save-dev @types/node@20.11.5`

## Quick Install Commands

### Production Dependencies
```bash
npm install @modelcontextprotocol/sdk@1.2.0 perplexity-api@1.1.2 @octokit/rest@19.0.13 playwright@1.41.2 axios@1.6.5 dotenv@16.3.1
```

### Development Dependencies
```bash
npm install --save-dev typescript@5.3.3 ts-node@10.9.2 @types/node@20.11.5
```

## Environment Variables Required

Create a `.env` file in your project root with the following variables:
```env
# Required for web search functionality
PERPLEXITY_API_KEY=your_perplexity_api_key

# Required for GitHub integration (optional if only using public repos)
GITHUB_TOKEN=your_github_token

# Optional configuration
NODE_ENV=development
LOG_LEVEL=info
```

## Post-Installation Steps

1. **Initialize TypeScript Configuration**
   ```bash
   npx tsc --init
   ```

2. **Install Playwright Browsers**
   ```bash
   npx playwright install
   ```

3. **Create tsconfig.json**
   ```json
   {
     "compilerOptions": {
       "target": "ES2020",
       "module": "ESNext",
       "moduleResolution": "node",
       "esModuleInterop": true,
       "strict": true,
       "outDir": "./dist",
       "rootDir": "./src",
       "declaration": true
     },
     "include": ["src/**/*"],
     "exclude": ["node_modules", "dist"]
   }
   ```

## Version Management

- All dependencies use semantic versioning (MAJOR.MINOR.PATCH)
- Regular updates recommended for security patches
- Major version updates should be carefully tested for breaking changes

## Security Notes

- Keep API keys and tokens secure in `.env` file
- Add `.env` to `.gitignore`
- Regularly update dependencies for security patches
- Review security advisories for all dependencies

## Support and Resources

- MCP SDK Issues: [GitHub Issues](https://github.com/modelcontextprotocol/sdk/issues)
- Perplexity API Support: [Documentation](https://docs.perplexity.ai/support)
- Playwright Help: [Discord Community](https://playwright.dev/community/discord)
- TypeScript Questions: [Stack Overflow](https://stackoverflow.com/questions/tagged/typescript)
</file>

<file path="docs/web-search-tool.md">
# Web Search Tool Documentation

## Overview
The web search tool provides a way to perform web searches using the Perplexity AI API. It supports both production and test environments, with graceful fallbacks for testing scenarios.

## Configuration

### Environment Variables
- `PERPLEXITY_API_KEY` (optional in test environment): Your Perplexity AI API key
- `NODE_ENV`: The current environment ('development', 'production', or 'test')

### Test Environment
In test environment:
- If `PERPLEXITY_API_KEY` is not provided, the tool returns mock results
- If `PERPLEXITY_API_KEY` is provided, real API calls are made

## Usage

### Basic Search
```typescript
const result = await webSearchTool.execute({
    query: "Your search query"
});
```

### Save Results to File
```typescript
const result = await webSearchTool.execute({
    query: "Your search query",
    saveToFile: true
});
```

## Request Schema
```typescript
{
    query: string;      // Required, non-empty string
    saveToFile: boolean; // Optional, defaults to false
}
```

## Response Schema
```typescript
{
    searchResults: string;
    savedToFile?: string; // Present only when saveToFile is true
}
```

## Error Handling

The tool handles various error scenarios:

1. Configuration Errors:
   - Missing API key (in non-test environment)
   - Invalid API key

2. Request Validation:
   - Empty query
   - Invalid request format

3. API Errors:
   - Rate limiting (429)
   - Authentication errors (401/403)
   - Invalid response format
   - Network timeouts (10s default)

4. File System Errors:
   - Failed to create directory
   - Failed to write file
   - File system permissions

## Testing

The tool includes comprehensive tests covering:
- Mock response behavior
- API integration
- Error handling
- File saving functionality

See `__tests__/web-search.test.ts` for test examples.

## Logging

All operations are logged using the application logger:
- Info: Search operations
- Debug: File operations
- Warn: API response issues
- Error: Failed operations

## Best Practices

1. Always handle potential errors when using the tool
2. Use appropriate timeouts for your use case
3. Monitor rate limiting in production
4. Consider implementing retry logic for transient failures
5. Keep queries focused and specific for better results
</file>

<file path="jest.config.js">
/** @type {import('ts-jest').JestConfigWithTsJest} */
export default {
  preset: 'ts-jest/presets/default-esm',
  testEnvironment: 'node',
  roots: ['<rootDir>/src'],
  testMatch: ['**/__tests__/**/*.ts', '**/?(*.)+(spec|test).ts'],
  transform: {
    '^.+\\.tsx?$': [
      'ts-jest',
      {
        useESM: true,
        tsconfig: 'tsconfig.json'
      },
    ],
  },
  moduleNameMapper: {
    '^(\\.{1,2}/.*)\\.js$': '$1',
    '^(\\.{1,2}/.*)\\.ts$': '$1'
  },
  extensionsToTreatAsEsm: ['.ts'],
  testTimeout: 10000,
  setupFiles: ['<rootDir>/src/test/setup.ts'],
  coverageDirectory: 'coverage',
  collectCoverageFrom: [
    'src/**/*.ts',
    '!src/**/*.d.ts',
    '!src/**/*.test.ts',
    '!src/**/__tests__/**',
  ],
  coverageThreshold: {
    global: {
      branches: 80,
      functions: 80,
      lines: 80,
      statements: 80,
    },
  },
};
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2024 freshtechbro

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="local-research/codebase-analysis.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, let's analyze the implementation of the MCP server and its tools, along with the dependencies.

**1. MCP Server Implementation (`src/server.ts`)**

The `src/server.ts` file serves as the entry point for the MCP server and sets up the core server functionalities. Here's a breakdown of its implementation:

*   **Server Initialization:**
    *   It imports the `Server` class from `@modelcontextprotocol/sdk/server/index.js` and `StdioServerTransport` from `@modelcontextprotocol/sdk/server/stdio.js`.
    *   It initializes a `Server` instance with metadata like `name`, `version`, and `description` from the `config` module.
    *   The `capabilities` option in the `Server` constructor is used to register resources and tools. Currently, it registers `web-search` and `repo-analysis` tools.
*   **Transport Layer:**
    *   It uses `StdioServerTransport` for communication. This transport is suitable for local execution and testing, as it uses standard input and output streams.
    *   The server connects to the transport using `server.connect(transport)`.
*   **Tool Registration:**
    *   The `capabilities.tools` object is used to register the `webSearchTool` and `repoAnalysisTool`. The keys (`'web-search'`, `'repo-analysis'`) are the tool names that clients will use to invoke these tools.
    *   A `health-check` tool is also registered, demonstrating a simple built-in tool for server status monitoring.
*   **Request Handling:**
    *   The server uses `setRequestHandler` to define how to handle incoming requests. It specifically handles requests matching the `ToolExecuteRequestSchema`.
    *   The `ToolExecuteRequestSchema` is defined using `zod` for schema validation, ensuring that incoming requests for tool execution adhere to a specific structure (`method`, `params` including `toolName`, `version`, and `arguments`).
    *   Inside the request handler, it retrieves the `toolName` from the request parameters and looks up the corresponding tool from the `tools` record.
    *   It then executes the `tool.execute(args)` function, passing the arguments from the request. The result of the tool's execution is returned as part of the response.
*   **Error Handling and Process Management:**
    *   **Uncaught Exceptions and Rejections:** The server sets up handlers for `uncaughtException` and `unhandledRejection` to log errors and terminate the process in case of unexpected errors. This is crucial for server stability.
    *   **Process Termination Signals:** Handlers for `SIGINT` and `SIGTERM` signals are set up to gracefully shut down the server upon receiving these signals.
    *   **Startup Error Handling:** The `main` function uses a `try...catch` block to handle potential startup errors and log them before exiting.
*   **Logging:**
    *   The server uses a `logger` module (likely a custom logger as seen in `src/utils/logger.ts`) for logging informational messages, debug messages, and errors. This is essential for monitoring and debugging the server's operation.
*   **Configuration Validation:**
    *   The server validates the configuration using `ServerConfigSchema.parse(config)` from the `config/index.ts` module. This ensures that the server is started with a valid configuration.

**Overall Implementation of MCP Server:**

The server implementation is well-structured and follows good practices:

*   **Modularity:**  It separates the core server logic from the tool implementations.
*   **Schema Validation:**  Uses `zod` for schema validation of requests and responses, ensuring data integrity and type safety.
*   **Error Handling:**  Robust error handling is implemented at multiple levels (request handling, startup, process termination).
*   **Logging:**  Comprehensive logging is integrated for monitoring and debugging.
*   **Configuration:**  Configuration is managed through a dedicated module and validated using schemas.
*   **MCP SDK Usage:** Correctly utilizes the `@modelcontextprotocol/sdk` for server setup and transport management.

**2. Tool Implementations**

Let's analyze the implementations of the `web-search` and `repo-analysis` tools.

**2.1. `web-search` Tool (`src/capabilities/tools/web-search.ts`)**

*   **Purpose:** This tool enables web searching using the Perplexity AI API.
*   **Functionality:**
    *   Takes a `query` string as input. Optionally, it can also take a `saveToFile` boolean flag.
    *   Uses `axios` to make HTTP requests to the Perplexity AI API (`PERPLEXITY_API_URL`).
    *   Authenticates with the Perplexity API using an API key (`PERPLEXITY_API_KEY`) loaded from environment variables via `dotenv`.
    *   Handles different environments (`test`, `production`, etc.) using `config.env`. In the `test` environment, if the API key is not provided, it returns mock results.
    *   Parses the API response to extract the search results from `response.data.choices[0].message.content`.
    *   If `saveToFile` is true, it saves the search results to a markdown file in the `local-research` directory.
    *   Implements error handling for API requests, including specific handling for Axios errors, API key issues (401, 403), and rate limits (429).
    *   Uses `zod` for request (`WebSearchRequestSchema`) and response (`WebSearchResponseSchema`) schema validation, ensuring that the tool receives and returns data in the expected format.
    *   Logs operations using the `logger` module, including search queries, API calls, saving to file, and errors.
*   **Request and Response Schemas:**
    *   `WebSearchRequestSchema`: Defines the expected structure for the tool's request, including `query` (required string) and `saveToFile` (optional boolean).
    *   `WebSearchResponseSchema`: Defines the structure of the tool's response, including `searchResults` (string) and `savedToFile` (optional string, path to saved file).

**2.2. `repo-analysis` Tool (`src/capabilities/tools/repo-analysis.ts`)**

*   **Purpose:** This tool analyzes code and documentation within a repository using Google Gemini.
*   **Functionality:**
    *   Takes a `query` (analysis question), `analysisType` (code, documentation, or both), `targetPath` (optional path to analyze within the repo), and `maxDepth` (directory depth for analysis) as input.
    *   Retrieves repository content using the `getRepositoryContent` function, which recursively reads files up to a specified depth.
    *   Uses `axios` to interact with the Google Gemini API.
    *   Authenticates with the Gemini API using an API key (`config.googleApiKey`).
    *   Caches analysis results in memory (`analysisCache`) to avoid redundant API calls for the same queries within a TTL (Time To Live) period.
    *   Constructs a detailed prompt for the Gemini API, including the query, analysis type, and retrieved repository content.
    *   Attempts to parse and structure the Gemini API response, though the parsing logic is noted as "TODO" in the code, currently returning a simplified structured response with a main analysis and placeholders for code and documentation insights.
    *   Implements error handling for file system operations (`fs.stat`, `fs.readdir`, `fs.readFile`) and Gemini API calls.
    *   Uses `zod` for request (`repoAnalysisRequestSchema`) and response (`repoAnalysisResponseSchema`) schema validation.
    *   Logs operations using the `logger` module, including API calls, cache usage, and errors.
*   **Request and Response Schemas:**
    *   `repoAnalysisRequestSchema`: Defines the request structure, including `query`, `analysisType`, `targetPath`, and `maxDepth`.
    *   `repoAnalysisResponseSchema`: Defines the response structure, including `analysis` (main analysis text), `codeInsights` (optional structured code insights), and `documentationInsights` (optional structured documentation insights).
*   **`getRepositoryContent` Function:**
    *   Recursively traverses a directory structure up to `maxDepth`.
    *   Reads file contents and adds them to a list of strings, prefixed with "File: <filepath>".
    *   Skips directories starting with `.` and `node_modules`.
    *   Includes basic error handling for file system operations.
*   **`analyzeWithGemini` Function:**
    *   Constructs a prompt for the Gemini API based on the query, analysis type, and repository content.
    *   Makes a POST request to the Gemini API endpoint using `axios`.
    *   Handles potential errors during API calls, including Axios errors.
    *   Returns a `GeminiAnalysis` interface object, currently with a simplified structure.

**Overall Tool Implementation:**

Both `web-search` and `repo-analysis` tools demonstrate good implementation practices:

*   **Schema Validation:**  Use `zod` for robust input and output validation.
*   **API Integration:** Properly integrate with external APIs (Perplexity and Gemini) using `axios`.
*   **Error Handling:**  Implement error handling for API calls, file system operations, and validation errors.
*   **Configuration Management:**  Utilize `config` module to access API keys and environment settings.
*   **Logging:**  Employ `logger` for detailed logging of tool operations and errors.
*   **Caching (`repo-analysis`):** Implement a caching mechanism to improve performance and reduce API calls for repository analysis.
*   **Modularity:** Tools are implemented as separate modules, making the codebase organized and maintainable.

**3. Dependency Analysis**

Let's review the dependencies used in the project, as listed in `package.json` and `dependencies.md` (though `dependencies.md` is from a different project version and might be outdated, `package.json` is the source of truth).

**Dependencies (from `package.json`):**

*   **Core MCP SDK:**
    *   `@modelcontextprotocol/sdk: "1.2.0"`: The core SDK for implementing the Model Context Protocol. Essential for building the MCP server and client.
*   **AI API Clients:**
    *   `@google/generative-ai: "^0.22.0"`: Google Generative AI SDK, used for interacting with the Gemini API in the `repo-analysis` tool.
    *   `axios: "1.6.5"`: HTTP client for making requests to Perplexity and Gemini APIs.
*   **Utility Libraries:**
    *   `dotenv: "16.3.1"`: Loads environment variables from `.env` files, used for managing API keys and configuration.
    *   `zod: "^3.24.2"`: Schema validation library, used for defining and validating request and response schemas for tools and server configuration.
*   **Browser Automation (Potentially for future tools, not directly used in analyzed tools but included in project dependencies):**
    *   `playwright: "1.41.2"`: Browser automation library, included in dependencies, suggesting potential future browser-based tools (as indicated in the initial `cursor-tools Integration` description).
*   **GitHub API Client (Potentially for future tools, not directly used in analyzed tools but included in project dependencies):**
    *   `@octokit/rest: "19.0.13"`: GitHub API client, also included, hinting at possible future GitHub integration tools (as also suggested by `cursor-tools Integration`).

**Development Dependencies (from `package.json`):**

*   **TypeScript and related tools:**
    *   `typescript: "5.3.3"`: TypeScript compiler.
    *   `ts-node: "10.9.2"`: Allows running TypeScript files directly in Node.js, useful for development.
    *   `@types/node: "20.11.5"`: TypeScript type definitions for Node.js APIs.
*   **Testing:**
    *   `jest: "^29.7.0"`: JavaScript testing framework.
    *   `@types/jest: "^29.5.11"`: TypeScript type definitions for Jest.
    *   `ts-jest: "^29.1.2"`: TypeScript preprocessor for Jest, allowing testing of TypeScript code directly.
    *   `cross-env: "^7.0.3"`: Cross-platform environment variable setting for test scripts.
*   **Linting and Formatting:**
    *   `eslint`, `@typescript-eslint/*`, `eslint-config-prettier`, `eslint-plugin-prettier`, `prettier`:  For code linting and formatting, ensuring code quality and consistency.
*   **Git Hooks:**
    *   `husky: "^8.0.3"`: Git hooks manager, likely used to run linters and formatters before commits.
    *   `lint-staged: "^15.2.0"`: Runs linters only on staged files for faster feedback.
*   **Utility:**
    *   `rimraf: "^5.0.5"`:  Utility for deleting directories recursively, used in build scripts (`clean` script).
*   **Cursor Tools (for Integration Testing/Example):**
    *   `cursor-tools: "latest"`: Inclusion of `cursor-tools` suggests it might be used for integration testing or as an example of how the MCP server could be used with a client like `cursor-tools`.

**Overall Dependency Analysis:**

The project utilizes a well-chosen set of dependencies:

*   **Essential Dependencies:** Includes the core MCP SDK and necessary libraries for API communication, configuration management, and schema validation.
*   **Development Focused:**  Includes a comprehensive set of development dependencies for TypeScript compilation, testing, linting, and formatting, indicating a focus on code quality and developer experience.
*   **Potential Future Features:** The inclusion of `playwright` and `@octokit/rest` suggests planned expansions to browser automation and GitHub integration functionalities, aligning with the initial feature set of `cursor-tools`.

**Summary of Implementation and Dependencies:**

The MCP server and tools are implemented in a modular, well-structured, and robust manner. They leverage appropriate libraries and follow best practices for error handling, logging, and configuration. The project is set up with a strong focus on code quality, testability, and potential future extensibility. The choice of dependencies is sensible and supports the intended functionalities of the MCP server and its tools.
</file>

<file path="local-research/cursor-tools-analysis.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, let's analyze the `cursor-tools` integration description provided and map its features to an MCP server context.

**Cursor-Tools Architecture and Features Analysis for MCP Replication**

`cursor-tools` appears to be a command-line tool designed to provide AI assistance within a coding environment (like Cursor IDE, presumably, given the name). It leverages various AI models and external tools through a set of commands.  The core architecture seems to be a command dispatcher that routes user commands to specific functionalities, interacting with different services (Perplexity, Gemini, GitHub API, Playwright).

Here's a breakdown of `cursor-tools` features and how they can be viewed from an MCP perspective:

**1. Web Search (`cursor-tools web`)**

*   **Functionality:**  Performs web searches using Perplexity AI and returns answers. Can suggest writing output to a file.
*   **Input:**  Search query (string). Options: `--model`, `--max-tokens`, `--save-to`, `--help`.
*   **Output:**  Search results (text, potentially markdown).
*   **Underlying Tech:** Perplexity AI API.
*   **MCP Mapping:**
    *   **MCP Resource:**  Could be modeled as a `web-search-result` resource type.
        *   `list` capability:  Might not be directly applicable.
        *   `read` capability:  Could take a search query as input and return the search results. The URI could be dynamically generated based on the query (e.g., `web-search-result://<query-hash>`).
    *   **MCP Tool:**  Alternatively, or additionally, a `web-search` tool.
        *   `execute` capability: Takes a search query as input and returns the search results.

**2. Repository Context (`cursor-tools repo`)**

*   **Functionality:**  Provides context-aware answers about the current repository using Google Gemini.
*   **Input:**  Question (string). Options: `--model`, `--max-tokens`, `--save-to`, `--help`.
*   **Output:**  Contextual answer (text).
*   **Underlying Tech:** Google Gemini API, likely with repository content indexing.
*   **MCP Mapping:**
    *   **MCP Resource:**  Perhaps a `repository-context` resource.
        *   `read` capability:  Takes a question as input, provides context-aware answer. URI could be generic like `repository-context://current`.
    *   **MCP Tool:**  A `repository-query` tool might be more appropriate.
        *   `execute` capability: Takes a question as input related to the repository, returns an answer.

**3. Documentation Generation (`cursor-tools doc`)**

*   **Functionality:**  Generates documentation for a repository. Supports local and remote (GitHub) repositories.
*   **Input:** Options: `--output`, `--from-github`.
*   **Output:**  Documentation (markdown, potentially other formats if configurable).
*   **Underlying Tech:** Code parsing and documentation generation logic (potentially leveraging AI for summarization and structuring).
*   **MCP Mapping:**
    *   **MCP Tool:**  Definitely a `generate-documentation` tool.
        *   `execute` capability:  Takes repository location (local path or GitHub URL) and output options as input, returns the generated documentation (or a URI to the generated documentation file).

**4. GitHub Information (`cursor-tools github pr`, `cursor-tools github issue`)**

*   **Functionality:**  Retrieves GitHub PRs and issues, either last 10 or specific by number. Supports specifying a repository via `--from-github`.
*   **Input:**  `pr` or `issue` command, optional number, `--from-github` option.
*   **Output:**  PR/Issue details (text, likely formatted).
*   **Underlying Tech:** GitHub API.
*   **MCP Mapping:**
    *   **MCP Resource:** `github-pull-request` and `github-issue` resource types.
        *   `list` capability (for last 10): Returns a list of PR/Issue summaries.
        *   `read` capability (for specific number): Takes PR/Issue number as input, returns detailed information. URI would be like `github-pull-request://<repo>/<pr-number>`.

**5. Browser Automation (`cursor-tools browser open`, `cursor-tools browser act`, `cursor-tools browser observe`, `cursor-tools browser extract`)**

*   **Functionality:**  Automates browser interactions, captures page content, console logs, network activity, and extracts data. Stateless browser instances. Supports actions through natural language instructions and multi-step workflows.
*   **Input:**  URL, instruction (for `act`, `observe`, `extract`), options: `--html`, `--console`, `--network`, `--screenshot`, `--timeout`, `--viewport`, `--headless`, `--no-headless`, `--connect-to`, `--wait`, `--video`.
*   **Output:**  Page content (HTML), console logs, network activity, screenshots, extracted data (depending on the command and options).
*   **Underlying Tech:** Playwright (browser automation library).
*   **MCP Mapping:**
    *   **MCP Tool:**  A suite of browser automation tools.
        *   `browser-open`: `execute` capability, takes URL and options, returns initial browser state (maybe a session ID if state was managed, but `cursor-tools` is stateless, so likely just success/failure).
        *   `browser-act`: `execute` capability, takes URL, instruction string, and options, performs actions and returns the result of actions (maybe updated page content or action success).
        *   `browser-observe`: `execute` capability, takes URL, instruction, and options, returns observed elements and suggested actions.
        *   `browser-extract`: `execute` capability, takes URL, extraction instruction, and options, returns extracted data.
    *   **MCP Resource:**  Less clear if browser automation is a resource. Maybe a `browser-page` resource, but tools seem more fitting for actions.

**General Command Options (`--model`, `--max-tokens`, `--save-to`, `--help`)**

*   **MCP Mapping:** These are likely server-level configurations or request parameters.
    *   `--model`, `--max-tokens`:  Could be request parameters for tools that use AI models.
    *   `--save-to`: Could be a general output handling feature, maybe less directly MCP related, more about client-side behavior.
    *   `--help`:  Server introspection capabilities in MCP could expose command help (though not explicitly defined in MCP spec, server info can be exposed).


**Replicating Cursor-Tools Features in an MCP Server**

To replicate `cursor-tools` functionality in an MCP server, you would need to:

1.  **Choose a Programming Language:** Node.js is a strong choice because the MCP SDK example is in Node.js, and `cursor-tools` likely uses Node.js as well, given the npm commands for installation.

2.  **Use MCP SDK:** Utilize the `@modelcontextprotocol/sdk` (Node.js version) to handle MCP protocol details, message parsing, schema validation, and transport layers.

3.  **Implement Resource and Tool Providers:** For each `cursor-tools` command category, create corresponding MCP resource and/or tool providers.

    *   **Web Search:** Integrate with Perplexity AI API within a `web-search` tool provider. Handle API calls, result formatting, and schema definition for requests (search query) and responses (search results).
    *   **Repository Context:**  Integrate with Google Gemini API within a `repository-query` tool provider. You'll need to handle repository content access and indexing to provide context. This is likely the most complex part, as it requires understanding the repository structure.  Alternatively, you could simplify this initially to just use Gemini for general code-related questions *without* specific repository context, and then enhance it later.
    *   **Documentation Generation:** Implement a `generate-documentation` tool provider. This would involve code parsing (using libraries for different languages), documentation generation logic (potentially using tools like JSDoc for JavaScript, or similar for other languages, or even AI-based documentation summarization), and handling output formatting.
    *   **GitHub Information:** Create `github-pull-request` and `github-issue` resource providers. Use the GitHub API to fetch PR and issue data. Implement `list` and `read` capabilities according to the MCP resource model.
    *   **Browser Automation:** Implement a suite of browser tools (`browser-open`, `browser-act`, `browser-observe`, `browser-extract`).  Integrate with Playwright within these tool providers.  Carefully consider how to manage the stateless nature of `cursor-tools` browser commands in an MCP context.  Each tool execution might start a new Playwright browser instance.

4.  **Define Schemas:**  Crucially, define MCP schemas for all requests and responses for your resources and tools. This ensures type safety and proper data exchange between the client and server, as per MCP best practices.  Look at the schema examples provided in the `mcp-plan.md` for guidance.

5.  **Transport Layer:** Start with `stdio` transport for initial development and testing, as it's simpler.  Later, add HTTP/SSE transport for network accessibility.

6.  **Error Handling and Logging:** Implement robust error handling in your resource and tool providers. Return MCP-compliant error responses. Implement logging for debugging and monitoring.

7.  **Documentation for your MCP Server:**  Provide clear documentation for your MCP server, explaining the resources and tools it offers, how to use them, and how to set up and run the server.

**Simplified First Steps (Beginner-Friendly Approach):**

To start simpler, you could initially focus on implementing a subset of `cursor-tools` features as MCP resources and tools. For example:

*   **Start with `stdio` transport.**
*   **Implement the `web-search` tool.** This is relatively self-contained and demonstrates tool execution.
*   **Implement the `github-pull-request` resource (just `list` capability initially).**  This shows resource listing and interaction with an external API.
*   **Skip browser automation and repository context initially**, as these are more complex.
*   **Focus on clear schemas and basic error handling.**

By building these core features first, you can get a working MCP server and gradually expand its capabilities to more closely resemble `cursor-tools`.  Remember to prioritize clear, beginner-friendly design and documentation throughout the development process, as emphasized in the research documents.
</file>

<file path="local-research/cursor-tools-implementation.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Here's how we can implement the web search, repo search, and browser automation features from `cursor-tools` in our MCP server, along with dependencies, APIs, and server structure considerations:

**1. Feature Implementation in MCP Server:**

*   **Web Search (`cursor-tools web`)**
    *   **MCP Tool:** Implement this as an MCP tool, let's name it `web-search`.
    *   **Capability:**  It will have an `execute` capability.
    *   **Request Schema:**  The request schema for `execute` will include a `query` parameter (string) for the search term.
    *   **Response Schema:** The response schema will include a `results` parameter (string, or potentially a more structured object) containing the search results. We can initially return plain text results and later enhance it to markdown or a structured format.
    *   **Implementation Logic:** Inside the `execute` handler for the `web-search` tool:
        1.  Take the `query` from the request.
        2.  Use the Perplexity AI API to perform the web search.
        3.  Format the results into the response schema.
        4.  Return the response.

*   **Repository Context Search (`cursor-tools repo`)**
    *   **MCP Tool:** Implement this as an MCP tool, let's name it `repo-query` or `repository-context-query`.
    *   **Capability:** It will have an `execute` capability.
    *   **Request Schema:** The request schema for `execute` will include a `query` parameter (string) for the question about the repository.
    *   **Response Schema:** The response schema will include an `answer` parameter (string) containing the context-aware answer.
    *   **Implementation Logic:** Inside the `execute` handler for the `repo-query` tool:
        1.  Take the `query` from the request.
        2.  **Repository Context Acquisition:** This is the most complex part.  We need to figure out how to get the "repository context."  For a basic implementation, we might initially skip deep repository context and just use Gemini for general code-related questions.  For more advanced context:
            *   **Option 1 (Simplified):**  Assume the MCP server is running within a repository directory.  The "context" is the files within that directory. We could potentially feed the contents of all files in the repository to Gemini for context. This is computationally expensive and might have token limits.
            *   **Option 2 (More realistic, but complex):**  Implement repository indexing. This would involve:
                *   Parsing code files in the repository.
                *   Creating an index of code elements (functions, classes, variables, comments, etc.).
                *   Using this index to provide context to Gemini based on the user's query.  This would likely require a vector database or similar technology for efficient semantic search within the code index.
                *   For now, let's focus on the simplified approach (Option 1) or even just general code questions without *specific* repo context.
        3.  Use the Google Gemini API, providing the user's `query` and the acquired repository context (or just the query for the simplified version).
        4.  Format Gemini's response into the `answer` parameter in the response schema.
        5.  Return the response.

*   **Browser Automation (`cursor-tools browser ...`)**
    *   **MCP Tool Suite:** Implement a suite of MCP tools, mirroring the `cursor-tools browser` commands: `browser-open`, `browser-act`, `browser-observe`, `browser-extract`.
    *   **Capabilities:** Each tool will have an `execute` capability.
    *   **Request Schemas:**
        *   `browser-open/execute`:  Request schema will include `url` (string) and options like `html`, `console`, `network`, `screenshot`, `timeout`, `viewport`, `headless`.
        *   `browser-act/execute`, `browser-observe/execute`, `browser-extract/execute`: Request schema will include `url` (string), `instruction` (string), and options like `html`, `console`, `network`, `screenshot`, `timeout`, `viewport`, `headless`.
    *   **Response Schemas:** The response schemas will depend on the command and options chosen. They could include:
        *   `htmlContent` (string): Page HTML.
        *   `consoleLogs` (array of strings): Browser console logs.
        *   `networkActivity` (object or array): Network request/response data.
        *   `screenshotPath` (string): Path to the saved screenshot.
        *   `extractedData` (object or array): Extracted data from the page.
    *   **Implementation Logic:**  For each browser tool's `execute` handler:
        1.  Take the `url`, `instruction` (if applicable), and options from the request.
        2.  Use Playwright to:
            *   Launch a new browser instance (stateless, as in `cursor-tools`).
            *   Navigate to the `url`.
            *   Perform actions based on the `instruction` (for `act`), observe elements (for `observe`), or extract data (for `extract`).
            *   Capture HTML, console logs, network activity, screenshot as requested by options.
        3.  Format the output (HTML, logs, data, etc.) into the response schema.
        4.  Close the browser instance.
        5.  Return the response.

**2. Key Dependencies and APIs:**

*   **Web Search (`web-search` tool):**
    *   **Dependency:**  An HTTP client library for Node.js (like `node-fetch` or `axios`).
    *   **API:** Perplexity AI API. You'll need an API key from Perplexity AI.

*   **Repository Context Search (`repo-query` tool):**
    *   **Dependency:** An HTTP client library.
    *   **API:** Google Gemini API. You'll need a Google Cloud API key with access to the Gemini API.
    *   **Optional (for advanced context):** Libraries for code parsing and indexing (language-specific parsers, vector database like Pinecone or Weaviate).  Initially, we can skip this complexity.

*   **Browser Automation (`browser-*` tools):**
    *   **Dependency:** `playwright` npm package.  This is essential for browser automation.

*   **MCP Server Core:**
    *   **Dependency:** `@modelcontextprotocol/sdk` (Node.js SDK) - already included in the plan.

**3. Server Structure for Efficient Request Handling:**

To structure the server effectively, we should use a modular approach as outlined in the `mcp-plan.md`.  Here's a suggested structure:

*   **`server.js` (or `index.js`):**
    *   Main server entry point.
    *   Initializes the MCP `Server` instance.
    *   Sets up the `stdio` (and potentially HTTP/SSE) transport.
    *   Registers all resource and tool providers.
    *   Starts the server.

*   **`capabilities/` directory:**
    *   **`resources/` directory (initially empty or for future resources):**  Place resource provider modules here if we decide to implement any MCP resources in the future.  For now, we are focusing on tools.
    *   **`tools/` directory:**
        *   **`web-search.js`:** Module containing the implementation for the `web-search` tool (including the `execute` handler and Perplexity API interaction).
        *   **`repo-query.js`:** Module for the `repo-query` tool (including the `execute` handler and Gemini API interaction, and repository context logic).
        *   **`browser-automation/` directory:**
            *   **`browser-open.js`:** Module for the `browser-open` tool.
            *   **`browser-act.js`:** Module for the `browser-act` tool.
            *   **`browser-observe.js`:** Module for the `browser-observe` tool.
            *   **`browser-extract.js`:** Module for the `browser-extract` tool.
            *   **(Potentially) `browser-utils.js`:**  A utility module for shared Playwright browser setup and teardown logic across browser tools.

*   **`schemas/` directory:**
    *   Define JSON schemas for all requests and responses for resources and tools.  For example:
        *   `web-search-request.json`
        *   `web-search-response.json`
        *   `repo-query-request.json`
        *   `repo-query-response.json`
        *   `browser-open-request.json`
        *   `browser-open-response.json`
        *   ... and so on for other browser tools.

*   **`config/` directory (optional):**
    *   `config.js` or `.env` file to store API keys (Perplexity, Gemini), and other server configuration.  Use environment variables for API keys for security.

**Request Handling Efficiency:**

*   **Asynchronous Operations:** All API calls (Perplexity, Gemini, Playwright) are asynchronous. Use `async/await` throughout the handlers to ensure non-blocking operations. This is crucial for server responsiveness.
*   **Stateless Tool Implementations:** The browser automation tools are designed to be stateless, which simplifies concurrency. Each tool execution starts a new browser instance and closes it.  This inherently helps with handling concurrent requests.
*   **Modular Design:** The modular structure makes it easier to manage and maintain the code, and to potentially optimize individual tool implementations without affecting others.
*   **Error Handling:** Implement robust error handling in each tool handler. Return MCP-compliant error responses to the client. Log errors for debugging.
*   **Resource Management (Playwright):**  Be mindful of Playwright browser instance management, especially if there are many concurrent browser automation requests.  While statelessness helps, consider resource limits if needed in a high-load scenario.

**Simplified First Steps:**

To make this beginner-friendly, start by implementing:

1.  **`web-search` tool:** This is relatively self-contained and good for demonstrating tool execution.
2.  **Basic `repo-query` tool (without deep repository context):**  Focus on just passing the user's query to Gemini for general code/programming questions.  Skip the complex repository indexing for now.
3.  **`browser-open` tool:**  Implement a simple `browser-open` tool to open a URL and maybe capture a screenshot.  This will introduce Playwright integration.

Gradually expand to other browser tools and then consider adding more sophisticated repository context features and resources as you progress. Remember to define schemas for all requests and responses as you build out the functionality for type safety and clarity.
</file>

<file path="local-research/dependencies-installation-guide.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...

# MCP Server Dependencies Installation Guide

This guide provides step-by-step instructions for installing and configuring all dependencies required for the MCP server project.

## Prerequisites

1. **Node.js and npm**
   ```bash
   # Check if Node.js is installed
   node --version  # Should be v14 or later
   npm --version   # Should be v6 or later
   
   # If not installed, download from https://nodejs.org/
   ```

2. **Git**
   ```bash
   # Check if Git is installed
   git --version
   
   # If not installed, download from https://git-scm.com/
   ```

## Project Setup

1. **Create Project Directory**
   ```bash
   mkdir mcp-server
   cd mcp-server
   ```

2. **Initialize Git Repository**
   ```bash
   git init
   ```

3. **Create .gitignore**
   ```bash
   echo "node_modules/
   dist/
   .env
   *.log" > .gitignore
   ```

## Core Dependencies Installation

### 1. Model Context Protocol SDK
```bash
# Install MCP SDK
npm install @modelcontextprotocol/sdk@1.2.0

# Verify installation
npm list @modelcontextprotocol/sdk
```

### 2. Perplexity API
```bash
# Install Perplexity API client
npm install perplexity-api@1.1.2

# Verify installation
npm list perplexity-api
```

### 3. GitHub API Client (Octokit)
```bash
# Install Octokit REST
npm install @octokit/rest@19.0.13

# Verify installation
npm list @octokit/rest
```

### 4. Playwright (Browser Automation)
```bash
# Install Playwright
npm install playwright@1.41.2

# Install browser binaries
npx playwright install

# Install supported browsers (chromium, firefox, webkit)
npx playwright install-deps

# Verify installation
npx playwright --version
```

### 5. Axios (HTTP Client)
```bash
# Install Axios
npm install axios@1.6.5

# Verify installation
npm list axios
```

### 6. Dotenv (Environment Variables)
```bash
# Install dotenv
npm install dotenv@16.3.1

# Verify installation
npm list dotenv

# Create .env file
touch .env
```

## Development Dependencies Installation

### 1. TypeScript
```bash
# Install TypeScript
npm install --save-dev typescript@5.3.3

# Initialize TypeScript configuration
npx tsc --init

# Verify installation
npx tsc --version
```

### 2. TypeScript Node
```bash
# Install ts-node
npm install --save-dev ts-node@10.9.2

# Verify installation
npx ts-node --version
```

### 3. Node.js Types
```bash
# Install Node.js types
npm install --save-dev @types/node@20.11.5

# Verify installation
npm list @types/node
```

## Configuration Files Setup

### 1. TypeScript Configuration (tsconfig.json)
```bash
# Create tsconfig.json with recommended settings
cat > tsconfig.json << EOL
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "moduleResolution": "node",
    "esModuleInterop": true,
    "strict": true,
    "outDir": "./dist",
    "rootDir": "./src",
    "declaration": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
EOL
```

### 2. Environment Variables (.env)
```bash
# Create .env file with required variables
cat > .env << EOL
# Required for web search functionality
PERPLEXITY_API_KEY=your_perplexity_api_key

# Required for GitHub integration
GITHUB_TOKEN=your_github_token

# Optional configuration
NODE_ENV=development
LOG_LEVEL=info
EOL
```

### 3. Package.json Scripts
```bash
# Add useful scripts to package.json
npm pkg set scripts.build="tsc"
npm pkg set scripts.start="node dist/server.js"
npm pkg set scripts.dev="ts-node src/server.ts"
npm pkg set scripts.test="echo \"No tests specified\" && exit 1"
```

## Project Structure Setup
```bash
# Create source directory
mkdir src

# Create directories for capabilities
mkdir -p src/capabilities/resources
mkdir -p src/capabilities/tools

# Create directories for utilities
mkdir -p src/utils
mkdir -p src/config
```

## Verification Steps

1. **Verify All Dependencies**
   ```bash
   npm list
   ```

2. **Verify TypeScript Setup**
   ```bash
   # Create a test TypeScript file
   echo "console.log('TypeScript is working!')" > src/test.ts
   
   # Try compiling it
   npx tsc
   ```

3. **Verify Playwright Setup**
   ```bash
   # Run Playwright test
   npx playwright --version
   ```

## Troubleshooting

### Common Issues and Solutions

1. **Node Version Mismatch**
   ```bash
   # Check Node.js version
   node --version
   
   # If needed, install nvm and switch version
   nvm install 14
   nvm use 14
   ```

2. **Permission Issues**
   ```bash
   # If npm install fails with permission errors
   sudo npm install -g npm@latest  # On Linux/macOS
   # Or run PowerShell as Administrator on Windows
   ```

3. **Playwright Browser Installation Issues**
   ```bash
   # If browser installation fails
   npx playwright install --force
   ```

4. **TypeScript Configuration Issues**
   ```bash
   # Reset TypeScript configuration
   rm tsconfig.json
   npx tsc --init
   ```

### Dependency Version Conflicts

If you encounter version conflicts:
1. Clear npm cache: `npm cache clean --force`
2. Delete node_modules: `rm -rf node_modules`
3. Delete package-lock.json: `rm package-lock.json`
4. Reinstall dependencies: `npm install`

## Post-Installation Verification

Create a simple test file to verify all major dependencies:

```typescript
// src/test-setup.ts
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { chromium } from 'playwright';
import { Octokit } from '@octokit/rest';
import axios from 'axios';
import dotenv from 'dotenv';

async function testSetup() {
  try {
    // Test MCP SDK
    const server = new Server({
      name: "test-server",
      version: "1.0.0"
    }, {
      capabilities: {}
    });
    console.log(' MCP SDK working');

    // Test Playwright
    const browser = await chromium.launch();
    await browser.close();
    console.log(' Playwright working');

    // Test Octokit
    const octokit = new Octokit();
    console.log(' Octokit working');

    // Test Axios
    await axios.get('https://api.github.com');
    console.log(' Axios working');

    // Test dotenv
    dotenv.config();
    console.log(' dotenv working');

  } catch (error) {
    console.error(' Setup test failed:', error);
  }
}

testSetup();
```

Run the test:
```bash
npx ts-node src/test-setup.ts
```

## Next Steps

After successful installation:
1. Set up your API keys in `.env`
2. Start implementing your MCP server
3. Run the verification test
4. Begin development using `npm run dev`
</file>

<file path="local-research/dependencies-research.md">
Querying Perplexity AI using sonar-pro for: List all dependencies needed to build an MCP server, including the Model Context Protocol SDK, web search (Perplexity), GitHub integration, browser automation (Playwright), and any utility libraries. For each dependency, provide the latest stable version and documentation URL.
Here's a list of dependencies for building an MCP server with the specified features:

1. @modelcontextprotocol/sdk: v1.2.0
   https://modelcontextprotocol.io/docs/sdk/

2. perplexity-api: v1.1.2
   https://docs.perplexity.ai/

3. @octokit/rest: v19.0.13
   https://octokit.github.io/rest.js/

4. playwright: v1.41.2
   https://playwright.dev/docs/api/class-playwright

5. axios: v1.6.5
   https://axios-http.com/docs/intro

6. dotenv: v16.3.1
   https://github.com/motdotla/dotenv#readme

7. typescript: v5.3.3
   https://www.typescriptlang.org/docs/

8. ts-node: v10.9.2
   https://typestrong.org/ts-node/docs/

9. @types/node: v20.11.5
   https://www.npmjs.com/package/@types/node

These versions are the latest stable as of February 2025. Install using:

```bash
npm install @modelcontextprotocol/sdk@1.2.0 perplexity-api@1.1.2 @octokit/rest@19.0.13 playwright@1.41.2 axios@1.6.5 dotenv@16.3.1
npm install --save-dev typescript@5.3.3 ts-node@10.9.2 @types/node@20.11.5
```

Query: Write a TypeScript code for an MCP server that implements tools for web search using Perplexity API, GitHub repository management, and browser automation with Playwright. Include error handling and proper typing.
</file>

<file path="local-research/mcp-clarifications.md">
Querying Perplexity AI using sonar-pro for: 1. What are the specific security best practices for MCP servers? 2. How should versioning and backwards compatibility be handled? 3. What are the recommended approaches for scaling MCP servers? 4. How should the server handle state management and session persistence?
1. Security best practices for MCP servers:
- Use TLS for remote connections[1]
- Implement authentication when needed[1]
- Validate all incoming messages[1]
- Sanitize inputs[1]
- Check message size limits[1]
- Implement access controls[1]
- Monitor resource usage[1]
- Rate limit requests[1]
- Don't leak sensitive information in errors[1]
- Log security-relevant events[1]

2. Versioning and backwards compatibility:
- Use package specifiers to version services (e.g. greet.v1.Greeter)[7]
- Host multiple versions side-by-side[7]
- Strive for backwards compatibility with old clients[7]
- Make breaking changes in new versions[7]

3. Scaling MCP servers:
- Use horizontal scaling by adding more instances[3]
- Implement autoscaling to dynamically adjust capacity[3]
- Create scale units that can be added together[3]
- Set scaling limits to prevent over-scaling[3]
- Use meaningful load metrics as scaling triggers[3]
- Add a buffer to handle unexpected spikes[3]

4. State management and session persistence:
- Use session state for short-lived, user-specific data[4][9]
- Store critical data in databases, not session[4]
- Set appropriate session timeouts[4]
- Use cookies to maintain session IDs[4]
- Consider alternatives like caching for better scalability[4][9]
- Avoid relying on session state for critical application functionality[4]
</file>

<file path="local-research/mcp-detailed-steps.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, here is a detailed, step-by-step implementation plan for building the MCP server with `cursor-tools` features. This plan breaks down the process into the smallest possible steps to ensure clarity and ease of implementation, especially for beginners.

**Phase 1: Project Setup and Basic Server Structure**

**Step 1: Create Project Directory**

1.  Open your terminal.
2.  Navigate to the directory where you want to create your project.
3.  Create a new directory for your MCP server:
    ```bash
    mkdir mcp-server
    cd mcp-server
    ```

**Step 2: Initialize Node.js Project**

1.  Inside the `mcp-server` directory, initialize a new Node.js project using npm:
    ```bash
    npm init -y
    ```
    This will create a `package.json` file with default settings.

**Step 3: Install MCP SDK and Core Dependencies**

1.  Install the `@modelcontextprotocol/sdk` which is essential for building MCP servers. We'll also install `node-fetch` for making HTTP requests (needed for web search and potentially GitHub API).
    ```bash
    npm install @modelcontextprotocol/sdk node-fetch
    ```

**Step 4: Create `server.js` - Basic Server Structure**

1.  Create a new file named `server.js` in your project root.
2.  Add the following basic server structure to `server.js`:

    ```javascript
    // server.js
    import { Server } from "@modelcontextprotocol/sdk/server/index.js";
    import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

    async function main() {
        const server = new Server({
            name: "cursor-tools-mcp-server",
            version: "0.1.0",
            description: "MCP server mimicking cursor-tools functionalities."
        }, {
            capabilities: {
                resources: {}, // Resources will be defined here
                tools: {}      // Tools will be defined here
            }
        });

        const transport = new StdioServerTransport();
        await server.connect(transport);
        console.log("MCP Server started using stdio transport.");
    }

    main().catch(console.error);
    ```

**Step 5: Run the Basic Server**

1.  In your terminal, run the server:
    ```bash
    node server.js
    ```
    You should see the output: `MCP Server started using stdio transport.` This confirms your basic server setup is working. Press `Ctrl+C` to stop the server.

**Phase 2: Implement Web Search Tool (`cursor-tools web`)**

**Step 6: Install Perplexity AI API Client (or use `node-fetch` directly)**

1.  For this example, we'll use `node-fetch` directly for simplicity to interact with Perplexity AI. If a dedicated Perplexity Node.js SDK becomes available, you could consider using it later.

**Step 7: Create `web-search.js` Tool Module**

1.  Create a new directory `capabilities` in your project root.
2.  Inside `capabilities`, create a directory `tools`.
3.  Inside `tools`, create a file named `web-search.js`.
4.  Add the following code to `capabilities/tools/web-search.js`:

    ```javascript
    // capabilities/tools/web-search.js
    import fetch from 'node-fetch';

    const PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions"; // Replace with actual API endpoint if different
    const PERPLEXITY_API_KEY = process.env.PERPLEXITY_API_KEY; // Load API key from environment variable

    export const webSearchTool = {
        name: 'web-search',
        version: '0.1.0',
        description: 'Performs a web search using Perplexity AI.',
        execute: async (request) => {
            if (!PERPLEXITY_API_KEY) {
                throw new Error("Perplexity API key is not set in environment variables (PERPLEXITY_API_KEY)");
            }
            const { query } = request;
            if (!query) {
                throw new Error("Search query is required.");
            }

            try {
                const response = await fetch(PERPLEXITY_API_URL, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${PERPLEXITY_API_KEY}`
                    },
                    body: JSON.stringify({
                        model: "pplx-7b-online", // Or another suitable Perplexity model
                        messages: [{ role: "user", content: query }]
                    })
                });

                if (!response.ok) {
                    const errorDetails = await response.text();
                    throw new Error(`Perplexity API request failed: ${response.status} - ${errorDetails}`);
                }

                const data = await response.json();
                const searchResults = data.choices[0]?.message?.content || "No results found."; // Extract result from API response

                return {
                    searchResults: searchResults
                };

            } catch (error) {
                console.error("Error during web search:", error);
                throw new Error(`Web search failed: ${error.message}`);
            }
        },
        requestSchema: {
            type: 'object',
            properties: {
                query: { type: 'string', description: 'The search query.' }
            },
            required: ['query']
        },
        responseSchema: {
            type: 'object',
            properties: {
                searchResults: { type: 'string', description: 'Web search results.' }
            },
            required: ['searchResults']
        }
    };
    ```

**Step 8: Register `web-search` Tool in `server.js`**

1.  Open `server.js` and modify the `capabilities.tools` section and import the `webSearchTool`:

    ```javascript
    // server.js
    import { Server } from "@modelcontextprotocol/sdk/server/index.js";
    import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
    import { webSearchTool } from './capabilities/tools/web-search.js'; // Import the web search tool

    async function main() {
        const server = new Server({
            name: "cursor-tools-mcp-server",
            version: "0.1.0",
            description: "MCP server mimicking cursor-tools functionalities."
        }, {
            capabilities: {
                resources: {},
                tools: {
                    'web-search': webSearchTool, // Register the web search tool
                }
            }
        });

        // ... (rest of server.js remains the same) ...
    }

    main().catch(console.error);
    ```

**Step 9: Set Perplexity API Key**

1.  You need a Perplexity API key to use their API. If you don't have one, sign up at [https://developer.perplexity.ai/](https://developer.perplexity.ai/).
2.  Set the API key as an environment variable named `PERPLEXITY_API_KEY`. How you set environment variables depends on your operating system:
    *   **Linux/macOS:**
        ```bash
        export PERPLEXITY_API_KEY="your_perplexity_api_key_here"
        ```
    *   **Windows (Command Prompt):**
        ```cmd
        set PERPLEXITY_API_KEY=your_perplexity_api_key_here
        ```
    *   **Windows (PowerShell):**
        ```powershell
        $env:PERPLEXITY_API_KEY="your_perplexity_api_key_here"
        ```
    *(Replace `your_perplexity_api_key_here` with your actual API key.)*

**Step 10: Test the `web-search` Tool**

1.  Start your MCP server in the terminal:
    ```bash
    node server.js
    ```
2.  To test the `web-search` tool, you'll need an MCP client. For a quick test, you can use a simple Node.js script to act as a client and send an `ExecuteToolRequest`. Create a new file `test-client.js` in your project root:

    ```javascript
    // test-client.js
    import { Client } from "@modelcontextprotocol/sdk/client/index.js";
    import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";

    async function main() {
        const transport = new StdioClientTransport();
        const client = new Client();
        await client.connect(transport);

        try {
            const response = await client.executeTool({
                toolName: 'web-search',
                version: '0.1.0',
                arguments: {
                    query: "latest news on AI" // Your search query
                }
            });

            console.log("Web Search Results:\n", response.tool_response.searchResults);

        } catch (error) {
            console.error("Error executing web-search tool:", error);
        } finally {
            client.close();
        }
    }

    main().catch(console.error);
    ```

3.  Run the test client in a *separate* terminal window (while your server is running in the first terminal):
    ```bash
    node test-client.js
    ```
    You should see web search results from Perplexity AI printed in your client terminal. If you encounter errors, check your API key, network connection, and server logs for details.

**Phase 3: Implement Repository Context Tool (`cursor-tools repo`) (Simplified)**

For this initial implementation, we'll create a simplified `repo-query` tool that uses Gemini API for general code-related questions *without* deep repository context indexing. We'll add basic functionality and can enhance it later.

**Step 11: Install Google Gemini API Client (or use `node-fetch` directly)**

1.  Similar to Perplexity, we'll use `node-fetch` for simplicity to interact with the Gemini API. You might consider using a dedicated Google API client library in a more advanced setup.

**Step 12: Create `repo-query.js` Tool Module**

1.  Inside `capabilities/tools`, create a new file named `repo-query.js`.
2.  Add the following code to `capabilities/tools/repo-query.js`:

    ```javascript
    // capabilities/tools/repo-query.js
    import fetch from 'node-fetch';

    const GOOGLE_GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent"; // Gemini Pro API endpoint
    const GOOGLE_API_KEY = process.env.GOOGLE_API_KEY; // Load Google API key from environment variable

    export const repoQueryTool = {
        name: 'repo-query',
        version: '0.1.0',
        description: 'Answers questions about the repository using Google Gemini (simplified).',
        execute: async (request) => {
            if (!GOOGLE_API_KEY) {
                throw new Error("Google API key is not set in environment variables (GOOGLE_API_KEY)");
            }
            const { query } = request;
            if (!query) {
                throw new Error("Repository query is required.");
            }

            try {
                const response = await fetch(`${GOOGLE_GEMINI_API_URL}?key=${GOOGLE_API_KEY}`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        contents: [{ role: "user", parts: [{ text: query }] }],
                    })
                });

                if (!response.ok) {
                    const errorDetails = await response.text();
                    throw new Error(`Google Gemini API request failed: ${response.status} - ${errorDetails}`);
                }

                const data = await response.json();
                const answer = data.candidates?.[0]?.content?.parts?.[0]?.text || "No answer found.";

                return {
                    answer: answer
                };

            } catch (error) {
                console.error("Error during repository query:", error);
                throw new Error(`Repository query failed: ${error.message}`);
            }
        },
        requestSchema: {
            type: 'object',
            properties: {
                query: { type: 'string', description: 'Question about the repository.' }
            },
            required: ['query']
        },
        responseSchema: {
            type: 'object',
            properties: {
                answer: { type: 'string', description: 'Context-aware answer from Gemini.' }
            },
            required: ['answer']
        }
    };
    ```

**Step 13: Register `repo-query` Tool in `server.js`**

1.  Open `server.js` and import and register the `repoQueryTool`:

    ```javascript
    // server.js
    // ... other imports ...
    import { webSearchTool } from './capabilities/tools/web-search.js';
    import { repoQueryTool } from './capabilities/tools/repo-query.js'; // Import repo query tool

    async function main() {
        // ... server setup ...
            capabilities: {
                resources: {},
                tools: {
                    'web-search': webSearchTool,
                    'repo-query': repoQueryTool, // Register repo query tool
                }
            }
        // ... rest of server.js ...
    }

    main().catch(console.error);
    ```

**Step 14: Set Google API Key**

1.  You need a Google Cloud API key with access to the Gemini API. If you don't have one, you'll need to set up a Google Cloud project and enable the Gemini API. Instructions can be found in Google Cloud documentation.
2.  Set your Google API key as an environment variable named `GOOGLE_API_KEY`:
    *   **Linux/macOS:** `export GOOGLE_API_KEY="your_google_api_key_here"`
    *   **Windows (Command Prompt):** `set GOOGLE_API_KEY=your_google_api_key_here`
    *   **Windows (PowerShell):** `$env:GOOGLE_API_KEY="your_google_api_key_here"`
    *(Replace `your_google_api_key_here` with your actual Google API key.)*

**Step 15: Test the `repo-query` Tool**

1.  Ensure your MCP server is running (`node server.js`).
2.  Modify your `test-client.js` to test `repo-query`:

    ```javascript
    // test-client.js
    // ... imports ...

    async function main() {
        // ... transport and client setup ...

        try {
            // ... web-search test (you can keep it or comment out) ...

            const repoQueryResponse = await client.executeTool({
                toolName: 'repo-query',
                version: '0.1.0',
                arguments: {
                    query: "Explain the basic structure of a Node.js project." // Your repo question
                }
            });

            console.log("\nRepository Query Answer:\n", repoQueryResponse.tool_response.answer);

        } catch (error) {
            console.error("Error executing repo-query tool:", error);
        } finally {
            client.close();
        }
    }

    main().catch(console.error);
    ```

3.  Run the modified `test-client.js` (`node test-client.js`). You should see an answer from Gemini related to your query about a Node.js project.

**Phase 4: Implement GitHub PRs Resource (`cursor-tools github pr`)**

**Step 16: Create `github-pr.js` Resource Module**

1.  Create a new directory `resources` inside `capabilities` directory.
2.  Inside `resources`, create a file named `github-pr.js`.
3.  Add the following code to `capabilities/resources/github-pr.js`:

    ```javascript
    // capabilities/resources/github-pr.js
    import fetch from 'node-fetch';

    const GITHUB_API_BASE_URL = "https://api.github.com";
    const GITHUB_TOKEN = process.env.GITHUB_TOKEN; // Optional, but recommended for higher rate limits

    export const githubPullRequestResource = {
        name: 'github-pr',
        version: '0.1.0',
        description: 'Provides information about GitHub Pull Requests.',
        list: async (request) => {
            const { owner, repo } = request;
            if (!owner || !repo) {
                throw new Error("GitHub repository owner and name are required.");
            }

            const apiUrl = `${GITHUB_API_BASE_URL}/repos/${owner}/${repo}/pulls?state=open`; // Get open PRs by default
            const headers = GITHUB_TOKEN ? { 'Authorization': `token ${GITHUB_TOKEN}` } : {};

            try {
                const response = await fetch(apiUrl, { headers });
                if (!response.ok) {
                    const errorDetails = await response.json();
                    throw new Error(`GitHub API request failed: ${response.status} - ${JSON.stringify(errorDetails)}`);
                }
                const prs = await response.json();
                const resourceList = prs.map(pr => ({
                    uri: `github-pr://${owner}/${repo}/${pr.number}`, // Construct URI
                    title: pr.title,
                    number: pr.number,
                    url: pr.html_url
                }));

                return { resources: resourceList };

            } catch (error) {
                console.error("Error fetching GitHub PRs:", error);
                throw new Error(`Failed to fetch GitHub PRs: ${error.message}`);
            }
        },
        read: async (request) => {
            const { uri } = request; // e.g., "github-pr://owner/repo/123"
            const parts = uri.substring(9).split('/'); // Remove "github-pr://" and split
            if (parts.length !== 3) {
                throw new Error("Invalid GitHub PR URI format. Expected format: github-pr://owner/repo/number");
            }
            const owner = parts[0];
            const repo = parts[1];
            const prNumber = parts[2];

            const apiUrl = `${GITHUB_API_BASE_URL}/repos/${owner}/${repo}/pulls/${prNumber}`;
            const headers = GITHUB_TOKEN ? { 'Authorization': `token ${GITHUB_TOKEN}` } : {};

            try {
                const response = await fetch(apiUrl, { headers });
                if (!response.ok) {
                    const errorDetails = await response.json();
                    throw new Error(`GitHub API request failed: ${response.status} - ${JSON.stringify(errorDetails)}`);
                }
                const prDetails = await response.json();
                const resource = {
                    uri: `github-pr://${owner}/${repo}/${prNumber}`,
                    title: prDetails.title,
                    number: prDetails.number,
                    url: prDetails.html_url,
                    body: prDetails.body, // PR description
                    author: prDetails.user.login,
                    author_url: prDetails.user.html_url,
                    state: prDetails.state, // open, closed
                    created_at: prDetails.created_at,
                    updated_at: prDetails.updated_at
                };
                return { resource };

            } catch (error) {
                console.error("Error fetching GitHub PR details:", error);
                throw new Error(`Failed to fetch GitHub PR details: ${error.message}`);
            }
        },
        listRequestSchema: { // Schema for list capability request
            type: 'object',
            properties: {
                owner: { type: 'string', description: 'GitHub repository owner (username or organization).' },
                repo: { type: 'string', description: 'GitHub repository name.' }
            },
            required: ['owner', 'repo']
        },
        listResponseSchema: { // Schema for list capability response
            type: 'object',
            properties: {
                resources: {
                    type: 'array',
                    items: {
                        type: 'object',
                        properties: {
                            uri: { type: 'string', description: 'Unique URI for the GitHub PR resource.' },
                            title: { type: 'string', description: 'Title of the Pull Request.' },
                            number: { type: 'number', description: 'Pull Request number.' },
                            url: { type: 'string', description: 'URL to the Pull Request on GitHub.' }
                        },
                        required: ['uri', 'title', 'number', 'url']
                    }
                }
            },
            required: ['resources']
        },
        readRequestSchema: { // Schema for read capability request
            type: 'object',
            properties: {
                uri: { type: 'string', description: 'URI of the GitHub PR resource to read (e.g., github-pr://owner/repo/number).' }
            },
            required: ['uri']
        },
        readResponseSchema: { // Schema for read capability response
            type: 'object',
            properties: {
                resource: {
                    type: 'object',
                    properties: {
                        uri: { type: 'string' },
                        title: { type: 'string' },
                        number: { type: 'number' },
                        url: { type: 'string' },
                        body: { type: 'string', description: 'Pull Request description.' },
                        author: { type: 'string' },
                        author_url: { type: 'string' },
                        state: { type: 'string' },
                        created_at: { type: 'string' },
                        updated_at: { type: 'string' }
                    },
                    required: ['uri', 'title', 'number', 'url', 'body', 'author', 'author_url', 'state', 'created_at', 'updated_at']
                }
            },
            required: ['resource']
        }
    };
    ```

**Step 17: Register `github-pr` Resource in `server.js`**

1.  Open `server.js` and import and register the `githubPullRequestResource`:

    ```javascript
    // server.js
    // ... other imports ...
    import { webSearchTool } from './capabilities/tools/web-search.js';
    import { repoQueryTool } from './capabilities/tools/repo-query.js';
    import { githubPullRequestResource } from './capabilities/resources/github-pr.js'; // Import GitHub PR resource

    async function main() {
        // ... server setup ...
            capabilities: {
                resources: {
                    'github-pr': githubPullRequestResource, // Register GitHub PR resource
                },
                tools: {
                    'web-search': webSearchTool,
                    'repo-query': repoQueryTool,
                }
            }
        // ... rest of server.js ...
    }

    main().catch(console.error);
    ```

**Step 18: Set GitHub Token (Optional but Recommended)**

1.  For unauthenticated requests to the GitHub API, you are subject to rate limits. To increase your rate limit, you can create a personal access token on GitHub (no specific scopes needed for public repos).
2.  Set your GitHub token as an environment variable named `GITHUB_TOKEN`:
    *   **Linux/macOS:** `export GITHUB_TOKEN="your_github_token_here"`
    *   **Windows (Command Prompt):** `set GITHUB_TOKEN=your_github_token_here`
    *   **Windows (PowerShell):** `$env:GITHUB_TOKEN="your_github_token_here"`
    *(Replace `your_github_token_here` with your actual GitHub token, or leave it unset for lower rate limits.)*

**Step 19: Test the `github-pr` Resource**

1.  Ensure your MCP server is running (`node server.js`).
2.  Modify your `test-client.js` to test `github-pr` resource's `list` and `read` capabilities:

    ```javascript
    // test-client.js
    // ... imports ...

    async function main() {
        // ... transport and client setup ...

        try {
            // ... web-search and repo-query tests (you can keep them or comment out) ...

            console.log("\n--- GitHub PRs List ---");
            const prListResponse = await client.listResources({
                resourceName: 'github-pr',
                version: '0.1.0',
                arguments: {
                    owner: "nodejs", // Example: Node.js organization
                    repo: "node"     // Example: Node.js repository
                }
            });
            console.log("Open PRs in nodejs/node:\n", prListResponse.resource_list.resources.map(r => `${r.title} (${r.uri})`).join('\n'));

            if (prListResponse.resource_list.resources.length > 0) {
                const firstPrUri = prListResponse.resource_list.resources[0].uri;
                console.log(`\n--- GitHub PR Details for ${firstPrUri} ---`);
                const prDetailsResponse = await client.readResource({
                    resourceUri: firstPrUri
                });
                const pr = prDetailsResponse.resource_response.resource;
                console.log("PR Details:\n", `Title: ${pr.title}\nURL: ${pr.url}\nAuthor: ${pr.author}\nState: ${pr.state}\nDescription (truncated):\n${pr.body?.substring(0, 200)}...`);
            }

        } catch (error) {
            console.error("Error interacting with github-pr resource:", error);
        } finally {
            client.close();
        }
    }

    main().catch(console.error);
    ```

3.  Run the modified `test-client.js` (`node test-client.js`). You should see a list of open pull requests for the `nodejs/node` repository and details of the first PR listed.

**Phase 5: Implement Browser Open Tool (`cursor-tools browser open`)**

**Step 20: Install Playwright**

1.  If you haven't already, install Playwright which is needed for browser automation:
    ```bash
    npm install playwright
    ```

**Step 21: Create `browser-open.js` Tool Module**

1.  Inside `capabilities/tools/browser-automation`, create a new directory named `browser-automation` (if it doesn't exist already).
2.  Inside `browser-automation`, create a file named `browser-open.js`.
3.  Add the following code to `capabilities/tools/browser-automation/browser-open.js`:

    ```javascript
    // capabilities/tools/browser-automation/browser-open.js
    import playwright from 'playwright';
    import fs from 'node:fs/promises';
    import path from 'node:path';

    export const browserOpenTool = {
        name: 'browser-open',
        version: '0.1.0',
        description: 'Opens a URL in a browser and captures page content and metadata.',
        execute: async (request) => {
            const { url, html, console: captureConsole, network, screenshot, timeout, viewport, headless } = request;
            if (!url) {
                throw new Error("URL is required for browser-open tool.");
            }

            const browserType = 'chromium'; // Or 'firefox', 'webkit' if needed, Chromium is default for cursor-tools
            const browser = await playwright[browserType].launch({ headless: headless !== false }); // Default headless: true
            const page = await browser.newPage({ viewport: viewport ? parseViewport(viewport) : undefined });
            let consoleLogs = [];
            let networkActivity = [];
            let screenshotPath = null;
            let htmlContent = null;

            if (captureConsole !== false) { // Capture console logs by default
                page.on('console', msg => consoleLogs.push(`${msg.type().toUpperCase()} ${msg.text()}`));
            }
            if (network !== false) { // Capture network activity by default
                page.on('requestfinished', req => networkActivity.push({
                    url: req.url(),
                    method: req.method(),
                    status: req.response()?.status(),
                    // ... you can add more details if needed, but keep it concise for now
                }));
            }

            try {
                await page.goto(url, { timeout: timeout || 30000 }); // Default timeout: 30 seconds

                if (screenshot) {
                    screenshotPath = path.resolve(screenshot); // Ensure absolute path or relative to server working dir
                    await page.screenshot({ path: screenshotPath, fullPage: true });
                }
                if (html) {
                    htmlContent = await page.content();
                }

                return {
                    ...(html ? { htmlContent } : {}),
                    ...(captureConsole !== false ? { consoleLogs } : {}),
                    ...(network !== false ? { networkActivity } : {}),
                    ...(screenshot ? { screenshotPath } : {}),
                    message: `Successfully opened URL: ${url}`
                };

            } catch (error) {
                console.error("Error during browser automation:", error);
                throw new Error(`Browser automation failed: ${error.message}`);
            } finally {
                await browser.close();
            }
        },
        requestSchema: {
            type: 'object',
            properties: {
                url: { type: 'string', description: 'URL to open in the browser.' },
                html: { type: 'boolean', description: 'Capture page HTML content (optional, default: false).' },
                console: { type: 'boolean', description: 'Capture browser console logs (optional, default: true).' },
                network: { type: 'boolean', description: 'Capture network activity (optional, default: true).' },
                screenshot: { type: 'string', description: 'File path to save a screenshot (optional).' },
                timeout: { type: 'number', description: 'Navigation timeout in milliseconds (optional, default: 30000ms).' },
                viewport: { type: 'string', description: 'Viewport size in format "widthxheight" (e.g., "1280x720", optional).' },
                headless: { type: 'boolean', description: 'Run browser in headless mode (optional, default: true).' },
            },
            required: ['url']
        },
        responseSchema: {
            type: 'object',
            properties: {
                message: { type: 'string', description: 'Confirmation message.' },
                htmlContent: { type: 'string', description: 'Page HTML content (if requested).' },
                consoleLogs: { type: 'array', items: { type: 'string' }, description: 'Captured browser console logs (if requested).' },
                networkActivity: { type: 'array', items: { type: 'object' }, description: 'Captured network activity (if requested).' },
                screenshotPath: { type: 'string', description: 'Path to the saved screenshot (if requested).' },
            },
            required: ['message']
        }
    };

    function parseViewport(viewportString) {
        const [width, height] = viewportString.split('x').map(Number);
        return { width, height };
    }
    ```

**Step 22: Register `browser-open` Tool in `server.js`**

1.  Open `server.js` and import and register the `browserOpenTool`:

    ```javascript
    // server.js
    // ... other imports ...
    import { webSearchTool } from './capabilities/tools/web-search.js';
    import { repoQueryTool } from './capabilities/tools/repo-query.js';
    import { githubPullRequestResource } from './capabilities/resources/github-pr.js';
    import { browserOpenTool } from './capabilities/tools/browser-automation/browser-open.js'; // Import browser-open tool

    async function main() {
        // ... server setup ...
            capabilities: {
                resources: {
                    'github-pr': githubPullRequestResource,
                },
                tools: {
                    'web-search': webSearchTool,
                    'repo-query': repoQueryTool,
                    'browser-open': browserOpenTool, // Register browser-open tool
                }
            }
        // ... rest of server.js ...
    }

    main().catch(console.error);
    ```

**Step 23: Test the `browser-open` Tool**

1.  Ensure your MCP server is running (`node server.js`).
2.  Modify your `test-client.js` to test `browser-open` tool:

    ```javascript
    // test-client.js
    // ... imports ...

    async function main() {
        // ... transport and client setup ...

        try {
            // ... previous tests (you can keep them or comment out) ...

            console.log("\n--- Browser Open Tool ---");
            const browserOpenResponse = await client.executeTool({
                toolName: 'browser-open',
                version: '0.1.0',
                arguments: {
                    url: "https://www.example.com", // Example URL
                    html: true,          // Request HTML content
                    screenshot: "example.png", // Save screenshot to example.png in project root
                    viewport: "800x600"  // Set viewport size
                }
            });
            console.log("Browser Open Message:", browserOpenResponse.tool_response.message);
            if (browserOpenResponse.tool_response.htmlContent) {
                console.log("\nHTML Content (truncated):\n", browserOpenResponse.tool_response.htmlContent.substring(0, 300) + "...");
            }
            if (browserOpenResponse.tool_response.screenshotPath) {
                console.log("\nScreenshot saved to:", browserOpenResponse.tool_response.screenshotPath);
                // You can open example.png in your project root to view the screenshot
            }

        } catch (error) {
            console.error("Error executing browser-open tool:", error);
        } finally {
            client.close();
        }
    }

    main().catch(console.error);
    ```

3.  Run the modified `test-client.js` (`node test-client.js`). You should see output indicating the URL was opened, and if successful, a truncated HTML content snippet and a message about the screenshot being saved. A file named `example.png` should be created in your project root directory containing a screenshot of `example.com`.

**Next Steps:**

This detailed plan has guided you through implementing the `web-search`, `repo-query`, `github-pr` and `browser-open` functionalities. You can continue implementing the remaining `cursor-tools` features (`browser act`, `browser observe`, `browser extract`, `cursor-tools doc`, `cursor-tools github issue`) by following a similar pattern:

1.  **Create a new tool or resource module** (e.g., `browser-act.js`, `github-issue.js`, `generate-doc.js`).
2.  **Implement the necessary capabilities** (`execute` for tools, `list`, `read` for resources) within the module, using appropriate APIs and libraries (Playwright for browser tools, GitHub API for issues, a documentation generation library for `doc`).
3.  **Define request and response schemas** in the module.
4.  **Register the new module** in the `capabilities` section of your `server.js`.
5.  **Test the new functionality** using your `test-client.js` or by creating new test scripts.

Remember to handle errors gracefully, add logging, and document your code as you proceed. This step-by-step approach will help you build a comprehensive MCP server mirroring the features of `cursor-tools`.
</file>

<file path="local-research/mcp-final-recommendations.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, I've reviewed the updated documentation in `local-research/`, focusing on how well the `cursor-tools` features are incorporated into the MCP server implementation plan and whether it meets best practices.

Here's a breakdown of my review and final recommendations:

**Summary of `cursor-tools` Feature Integration in the MCP Plan:**

The `mcp-plan.md` and related documents (`cursor-tools-analysis.md`, `cursor-tools-implementation.md`, `mcp-detailed-steps.md`) demonstrate a strong understanding of how to translate `cursor-tools` functionalities into an MCP server architecture.

*   **Clear Mapping:** The analysis in `cursor-tools-analysis.md` effectively maps each `cursor-tools` command (web, repo, doc, github, browser) to potential MCP resources and tools.  It correctly identifies which functionalities are better suited as resources (like GitHub PRs/issues) and which are better as tools (like web search, documentation generation, browser automation).
*   **Detailed Implementation Steps:** `mcp-detailed-steps.md` provides a very granular, step-by-step guide to implementing a subset of `cursor-tools` features (web search, repo query, github PRs, browser open) as MCP resources and tools. This is excellent for beginner-friendliness.
*   **Practical Examples:** The detailed steps include code snippets for server setup, tool/resource modules, request handlers, and even a basic test client. This makes the plan very actionable.
*   **Prioritization and Simplification:** The plan intelligently suggests starting with a simplified approach, focusing on core features and `stdio` transport first, and gradually adding complexity. This is crucial for a beginner-friendly approach and allows for iterative development.
*   **Schema Awareness:** The plan recognizes the importance of schemas for request and response validation, although the initial examples are kept simple for clarity. `mcp-plan.md` includes example schema definitions within capability descriptions.
*   **Dependency Identification:** `cursor-tools-implementation.md` correctly identifies key dependencies and APIs (Perplexity, Gemini, GitHub API, Playwright) needed for implementing the features.

**Review against Best Practices (Based on `mcp-clarifications.md`, `mcp-research.md`, `mcp-final-review.md`):**

The plan incorporates many best practices for MCP server development, as highlighted in `mcp-final-review.md`:

*   **Security:** The plan acknowledges security best practices (TLS, authentication, input validation, rate limiting, logging security events). `mcp-final-review.md` suggests further elaboration on these, which is a valid point.
*   **Versioning and Backwards Compatibility:** The plan mentions semantic versioning and striving for backwards compatibility, although detailed versioning strategies for resources and tools could be further elaborated.
*   **Scaling:** The plan considers horizontal scaling and statelessness, especially for HTTP/SSE transport.
*   **State Management:**  The plan correctly recommends a stateless server design, which is a key best practice for scalability and simplicity.
*   **Error Handling and Logging:** The plan emphasizes graceful error handling and basic logging. `mcp-final-review.md` recommends more specific error response structures and structured logging.
*   **Documentation:**  The plan strongly emphasizes clear and comprehensive documentation, including a `README.md` and code comments, which is excellent for beginner-friendliness.
*   **Modular Design:** The modular architecture is a core principle, promoting maintainability and extensibility.
*   **Transport Layer Flexibility:** Planning for both `stdio` and HTTP/SSE provides flexibility for different use cases.

**Beginner-Friendliness Assessment (Based on `mcp-user-experience.md` and overall plan):**

The plan is very well-aligned with making the MCP server beginner-friendly:

*   **Simple Setup and Configuration:** The plan starts with `stdio` transport, which greatly simplifies setup. The detailed steps in `mcp-detailed-steps.md` are designed for beginners.
*   **Intuitive API Design:** While the server API is defined by the MCP protocol itself, the plan focuses on creating clear resource and tool names and descriptions. The example schemas also contribute to API clarity.
*   **Comprehensive Documentation:** The plan prioritizes documentation, including a `README.md` and code comments. `mcp-detailed-steps.md` itself acts as a detailed tutorial.
*   **Error Handling and Feedback:** The plan mentions error handling and logging, which are important for debugging and user feedback.
*   **Modular Design:** The modular design allows beginners to focus on implementing one tool or resource at a time, gradually learning and expanding their server.
*   **Interactive Learning Tools (Future):** While not yet implemented, the plan could potentially incorporate interactive elements like a CLI or playground in the future, as suggested in `mcp-user-experience.md`.

**Power and Flexibility Assessment:**

The plan lays a solid foundation for a powerful and flexible MCP server:

*   **Extensible Architecture:** The modular design and clear separation of concerns make the server architecture inherently extensible. New resources and tools can be added relatively easily.
*   **Support for Diverse Functionalities:** By mapping `cursor-tools` features, the plan demonstrates the potential to integrate a wide range of functionalities into the MCP server, from web search to browser automation and GitHub interactions.
*   **Scalability Potential:** Planning for HTTP/SSE transport and statelessness opens the door for scaling the server for more demanding applications.
*   **Future Enhancements:** The plan explicitly lists powerful features as future enhancements (multiple transports, robust error handling, schema validation, security, IDE integration), showing a forward-looking approach.

**Final Recommendations for Improvement:**

Based on my review and the points raised in `mcp-final-review.md`, here are my final recommendations to further improve the plan and its execution:

1.  **Schema Definition Examples:**  In `mcp-plan.md` and `mcp-detailed-steps.md`, add more concrete examples of schema definitions, especially using the MCP SDK's schema capabilities. Show how schemas are used for request and response validation in code. This will make schemas less abstract for beginners.

2.  **Detailed Error Handling Examples:** Expand on error handling in code examples. Show how to construct and return MCP-compliant error responses in request handlers. Provide examples of different error types and how to handle them gracefully.

3.  **Testing Strategy Expansion:**  Elaborate on the testing strategy. Provide examples of unit tests for handlers and integration tests to verify MCP protocol interactions.  Suggest a testing framework (like `jest` or `mocha` for Node.js) and demonstrate basic test cases.

4.  **Security Best Practices - Actionable Steps:** For each security best practice mentioned, provide more actionable steps and code snippets or references. For example:
    *   **Input Validation:** Show examples of using libraries like `joi` or `zod` for input validation in request handlers.
    *   **TLS for HTTP/SSE:** Briefly explain how to set up HTTPS in Node.js using `https` module or `express` with TLS certificates.
    *   **Authentication:**  Suggest a simple authentication method like API keys for initial implementation and provide a basic example of how to implement API key authentication in a tool/resource.
    *   **Rate Limiting:** Recommend a Node.js rate limiting middleware (e.g., `express-rate-limit`) and show a basic configuration example.

5.  **Structured Logging Example:** Demonstrate how to implement structured logging (e.g., using `pino` or `winston` with JSON format) in the server. Show how to log requests, responses, and errors with different log levels.

6.  **Health Check Endpoint Example:** Include a code snippet for implementing a basic health check endpoint in Node.js (e.g., using `http` module or `express` to create a `/healthz` endpoint).

7.  **Basic MCP Client Example:**  Provide a minimal, runnable Node.js script using `@modelcontextprotocol/sdk/client` to interact with the server. This client should demonstrate sending `ListResourcesRequest`, `ReadResourceRequest`, and `ExecuteToolRequest` and handling responses. This will be extremely helpful for beginners to test and understand client-server interaction.

8.  **Deployment Considerations (Brief Overview):** Add a brief section on deployment considerations, mentioning containerization with Docker and potential cloud deployment platforms (like AWS, Google Cloud, or Azure). This will give a more complete picture of the server's lifecycle.

**Final Conclusion:**

The documentation and implementation plan for the MCP server are **excellent and well-structured**. They effectively integrate `cursor-tools` features and address many MCP server best practices. By incorporating the final recommendations, especially by adding more concrete examples for schemas, error handling, testing, security, logging, client interaction, and deployment, the plan will become even more robust, beginner-friendly, and practically valuable for developers looking to build MCP servers. The plan is already very strong and these additions will make it truly outstanding.
</file>

<file path="local-research/mcp-final-review.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, I've reviewed the documentation generated in `local-research/`, specifically `mcp-clarifications.md`, `mcp-plan.md`, `mcp-research.md`, and `mcp-user-experience.md`. Here's my final assessment of the `mcp-plan.md` against global best practices for MCP server development:

**Overall Assessment:**

The `mcp-plan.md` is a well-structured and comprehensive plan for developing a beginner-friendly MCP server. It successfully incorporates many best practices identified in the research and user experience considerations. The plan is particularly strong in its step-by-step implementation guide, focus on `stdio` transport for initial simplicity, and emphasis on clear documentation.

**Strengths of the Plan:**

*   **Beginner-Friendly Approach:** The plan explicitly prioritizes beginner-friendliness by starting with `stdio`, simple examples, and clear documentation. This aligns strongly with the user experience research.
*   **Modular Architecture:** The plan emphasizes a modular design, separating concerns into core logic, resource/tool providers, and configuration. This promotes maintainability, extensibility, and allows for gradual feature adoption, as recommended for beginner-friendly systems.
*   **Step-by-Step Implementation Guide:** The detailed, numbered implementation steps with code snippets provide a clear and actionable path for development, making it easy for someone new to MCP to follow.
*   **Focus on Core MCP Concepts:** The plan correctly focuses on resources and tools as the initial capabilities, which are fundamental to MCP.
*   **Inclusion of Best Practices:** The plan explicitly addresses security, versioning, scaling, and state management best practices in a dedicated section, demonstrating awareness of these critical aspects.
*   **Documentation Emphasis:**  The plan highlights the importance of documentation, including a `README.md` and code comments, crucial for beginner onboarding.
*   **Iterative Development Approach:** The plan promotes iterative refinement and expansion, suggesting starting simple and gradually adding features, which is a practical approach for complex projects and aligns with agile methodologies.
*   **Transport Layer Flexibility:**  Planning for both `stdio` and HTTP/SSE transport layers offers flexibility for different deployment scenarios and future scalability.

**Areas for Improvement and Additional Consideration:**

*   **Schema Definition Depth:** While the plan mentions schema definitions, it could benefit from more concrete examples of schema usage and how they contribute to type safety and validation.  Perhaps adding a simple schema definition example using the MCP SDK's schema capabilities would be beneficial.
*   **Error Handling Specificity:**  The plan mentions error handling but could elaborate further on specific error response structures according to MCP conventions and best practices for providing informative error messages to clients. Showcasing how to return MCP-compliant error responses would be helpful.
*   **Testing Strategy Details:** The plan mentions testing but lacks specifics. It could be improved by outlining a more detailed testing strategy. This could include:
    *   Unit tests for individual handlers and modules.
    *   Integration tests to verify the interaction between server components and the MCP protocol.
    *   Example test cases for resources and tools.
    *   Guidance on using testing frameworks suitable for Node.js.
*   **Security Best Practices Elaboration:** While security is mentioned, the plan could provide more specific and actionable steps for each security best practice. For example:
    *   **Input Validation:**  Provide examples of input validation techniques in the request handlers.
    *   **TLS for HTTP/SSE:** Briefly mention how to configure TLS for an HTTP server in Node.js when implementing HTTP/SSE transport.
    *   **Authentication:**  Suggest a few common authentication methods suitable for MCP servers (e.g., API keys, JWT) and point to resources for implementation.
    *   **Rate Limiting:** Recommend libraries or techniques for implementing rate limiting in a Node.js server.
*   **Logging Best Practices:** Expand on logging recommendations. Suggest using structured logging (e.g., JSON format) for easier analysis and integration with logging tools. Recommend what kind of information should be logged at different levels (info, warning, error).
*   **Health Checks Implementation:** Provide a code snippet or guidance on how to implement a basic health check endpoint in Node.js.
*   **Client Interaction Examples:** While `cursor-tools` was mentioned (and noted as not ideal for this purpose), providing a simple, runnable example of a basic MCP client (even a very minimal Node.js script using the MCP SDK client library) would be extremely helpful for beginners to test and understand how to interact with the server.
*   **Deployment Considerations (briefly):**  Although the initial focus is local development, briefly touching upon deployment considerations (e.g., containerization with Docker, cloud deployment platforms) would provide a more complete picture for users looking to move beyond local testing.

**Final Recommendation:**

The `mcp-plan.md` is a solid foundation for building a beginner-friendly MCP server. The plan effectively balances simplicity with the necessary considerations for a robust server.  By incorporating the suggested improvements, particularly by adding more detail and concrete examples around schema definition, error handling, testing, security, logging, client interaction, and deployment, the plan will become even more comprehensive and valuable, further enhancing its beginner-friendliness and practical utility.

**In summary, the plan is very good and meets global best practices for MCP server development at a high level. Addressing the areas for improvement will elevate it to an excellent and highly actionable guide.**
</file>

<file path="local-research/mcp-implementation-plan.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, based on all the research in `local-research/`, here's a comprehensive implementation plan for our MCP server, designed to be both beginner-friendly and powerful, drawing inspiration from Claude's MCP, popular servers, and best practices:

## MCP Server Implementation Plan: Beginner-Friendly & Powerful

**I. Project Goals & Principles:**

*   **Goal:** Build an MCP server that mirrors the core functionalities of `cursor-tools`, providing AI assistance for web search, repository context, GitHub information, and browser automation.
*   **Beginner-Friendliness:**  Prioritize ease of installation, setup, and initial use. Offer a smooth onboarding experience for developers new to MCP.
*   **Power & Flexibility:** Design an extensible and modular architecture that can be easily expanded with new resources, tools, and features. Ensure scalability and robustness for future growth.
*   **Best Practices:**  Incorporate security, versioning, error handling, logging, and documentation best practices throughout the development process.
*   **Iterative Development:** Adopt an iterative approach, starting with core features and progressively adding complexity and enhancements.

**II. Architectural Design:**

1.  **Client-Server Model:** Adhere to the standard MCP client-server architecture using `@modelcontextprotocol/sdk` (Node.js).
2.  **Transport Layer:**
    *   **Initial:** `stdio` (Standard Input/Output) for local development and beginner simplicity.
    *   **Future:** HTTP/SSE (Server-Sent Events) for remote access, scalability, and broader deployment scenarios.
3.  **Modular Design:**
    *   **Core Server:** Handles MCP protocol, request routing, and capability registration.
    *   **Capabilities:** Organized into `resources/` and `tools/` directories, each in its own module for maintainability and extensibility.
    *   **Schemas:**  `schemas/` directory to store JSON schemas for request and response validation, ensuring type safety and clear API contracts.
    *   **Configuration:**  `config/` directory for server configuration (API keys, settings), using environment variables for sensitive information.
4.  **Statelessness:**  Design server components to be as stateless as possible for improved scalability and simplified management.
5.  **Error Handling & Logging:** Implement robust error handling with MCP-compliant error responses. Utilize structured logging for debugging and monitoring.

**III. Implementation Phases & Steps:**

**Phase 1: Project Setup & Basic Server Core (Beginner-Focused)**

1.  **Step 1: Project Initialization:**
    *   Create project directory: `mkdir mcp-server && cd mcp-server`
    *   Initialize Node.js project: `npm init -y`
    *   Install MCP SDK: `npm install @modelcontextprotocol/sdk node-fetch` (for API interactions)

2.  **Step 2: Create Basic `server.js`:**
    ```javascript
    // server.js
    import { Server } from "@modelcontextprotocol/sdk/server/index.js";
    import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

    async function main() {
        const server = new Server({
            name: "cursor-tools-mcp-server",
            version: "0.1.0",
            description: "MCP server mimicking cursor-tools functionalities."
        }, {
            capabilities: {
                resources: {},
                tools: {}
            }
        });

        const transport = new StdioServerTransport();
        await server.connect(transport);
        console.log("MCP Server started using stdio transport.");
    }

    main().catch(console.error);
    ```

3.  **Step 3: Run the Basic Server:**
    *   Execute: `node server.js`
    *   Verify output: "MCP Server started using stdio transport."

**Phase 2: Implement Web Search Tool (`cursor-tools web`)**

1.  **Step 4: Create `web-search.js` Tool Module:**
    *   Create directories: `mkdir -p capabilities/tools`
    *   Create file: `capabilities/tools/web-search.js`
    *   Implement `webSearchTool` (using Perplexity API - refer to `mcp-detailed-steps.md` and `cursor-tools-implementation.md` for code structure and API interaction).  Remember to use environment variables for `PERPLEXITY_API_KEY`.

2.  **Step 5: Register `web-search` Tool:**
    *   Modify `server.js` to import and register `webSearchTool` in `capabilities.tools`.

3.  **Step 6: Set Perplexity API Key:**
    *   Instruct users to obtain a Perplexity API key and set the `PERPLEXITY_API_KEY` environment variable.

4.  **Step 7: Test `web-search` Tool:**
    *   Create `test-client.js` (based on `mcp-detailed-steps.md`) to send `ExecuteToolRequest` for `web-search`.
    *   Run server in one terminal (`node server.js`), client in another (`node test-client.js`).
    *   Verify web search results are returned.

**Phase 3: Implement GitHub PRs Resource (`cursor-tools github pr`)**

1.  **Step 8: Create `github-pr.js` Resource Module:**
    *   Create directory: `mkdir capabilities/resources`
    *   Create file: `capabilities/resources/github-pr.js`
    *   Implement `githubPullRequestResource` (using GitHub API - refer to `mcp-detailed-steps.md` and `cursor-tools-implementation.md` for code structure and API interaction). Use environment variable for `GITHUB_TOKEN` (optional but recommended).

2.  **Step 9: Register `github-pr` Resource:**
    *   Modify `server.js` to import and register `githubPullRequestResource` in `capabilities.resources`.

3.  **Step 10: Set GitHub Token (Optional):**
    *   Instruct users on how to create a GitHub personal access token and set `GITHUB_TOKEN` for higher rate limits.

4.  **Step 11: Test `github-pr` Resource:**
    *   Modify `test-client.js` to test `ListResourcesRequest` and `ReadResourceRequest` for `github-pr` (refer to `mcp-detailed-steps.md`).
    *   Run client and server, verify PR list and details are retrieved.

**Phase 4: Implement Browser Open Tool (`cursor-tools browser open`)**

1.  **Step 12: Install Playwright:**
    *   Instruct users to install Playwright: `npm install playwright`

2.  **Step 13: Create `browser-open.js` Tool Module:**
    *   Create directory: `mkdir -p capabilities/tools/browser-automation`
    *   Create file: `capabilities/tools/browser-automation/browser-open.js`
    *   Implement `browserOpenTool` (using Playwright - refer to `mcp-detailed-steps.md` and `cursor-tools-implementation.md` for code structure and Playwright usage).

3.  **Step 14: Register `browser-open` Tool:**
    *   Modify `server.js` to import and register `browserOpenTool` in `capabilities.tools`.

4.  **Step 15: Test `browser-open` Tool:**
    *   Modify `test-client.js` to test `ExecuteToolRequest` for `browser-open` (refer to `mcp-detailed-steps.md`).
    *   Run client and server, verify browser automation and screenshot functionality.

**Phase 5:  Repository Context Tool (Simplified `cursor-tools repo`)**

1.  **Step 16: Create `repo-query.js` Tool Module:**
    *   Create file: `capabilities/tools/repo-query.js`
    *   Implement `repoQueryTool` (using Gemini API - refer to `mcp-detailed-steps.md` and `cursor-tools-implementation.md` for code structure and Gemini API interaction).  Initially, implement a *simplified* version without deep repository indexing, focusing on general code questions. Use environment variable for `GOOGLE_API_KEY`.

2.  **Step 17: Register `repo-query` Tool:**
    *   Modify `server.js` to import and register `repoQueryTool` in `capabilities.tools`.

3.  **Step 18: Set Google API Key:**
    *   Instruct users to obtain a Google Cloud API key with Gemini API access and set `GOOGLE_API_KEY` environment variable.

4.  **Step 19: Test `repo-query` Tool:**
    *   Modify `test-client.js` to test `ExecuteToolRequest` for `repo-query` (refer to `mcp-detailed-steps.md`).
    *   Run client and server, verify Gemini-powered code question answering.

**Phase 6: Documentation, Refinement & Best Practices Integration**

1.  **Step 20: Comprehensive Documentation (Beginner-Focused):**
    *   **README.md:** Create a detailed README.md with:
        *   Project description and goals.
        *   **Clear Installation Instructions:** Step-by-step guide using `npm install`, environment variable setup for API keys, and Playwright installation.
        *   **Quick Start Guide:**  Simple example of using `test-client.js` to interact with the server.
        *   **Capabilities Overview:** Explain the provided resources (`github-pr`) and tools (`web-search`, `browser-open`, `repo-query`).
        *   **Troubleshooting Guide:** Common issues and solutions.
        *   **Contribution Guide:** Encourage community contributions.
    *   **Code Comments:** Add clear and concise comments throughout the codebase.

2.  **Step 21: Implement Robust Error Handling:**
    *   Refine error handling in all resource and tool modules to return MCP-compliant error responses with descriptive messages.
    *   Use `try...catch` blocks and throw appropriate errors.

3.  **Step 22: Implement Structured Logging:**
    *   Integrate a logging library (e.g., `pino` or `winston`).
    *   Log requests, responses, errors, and important server events with appropriate log levels.
    *   Use JSON format for logs for easier analysis.

4.  **Step 23: Basic Input Validation:**
    *   Implement basic input validation in request handlers to check for required parameters and data types.
    *   Consider using schema validation from MCP SDK for more robust validation in the future.

5.  **Step 24: Testing Strategy Expansion:**
    *   Write basic unit tests for individual tool and resource handlers.
    *   Expand `test-client.js` to include more comprehensive integration tests for different scenarios and edge cases.

**Phase 7: Future Enhancements (Power & Flexibility)**

1.  **Step 25: HTTP/SSE Transport Implementation:**
    *   Add support for HTTP/SSE transport using `HttpServerTransport` or `SseServerTransport` from the MCP SDK.
    *   Set up an HTTP server (using Node.js `http` or `express`).
    *   Provide instructions on how to run the server with HTTP/SSE transport.

2.  **Step 26: Advanced Schema Validation:**
    *   Implement full schema validation using the MCP SDK's schema capabilities for all requests and responses.
    *   Define schemas in separate `.json` files in `schemas/` directory.

3.  **Step 27: Security Enhancements:**
    *   **TLS for HTTP/SSE:** Configure HTTPS for HTTP/SSE transport.
    *   **Authentication:** Implement a basic authentication mechanism (e.g., API keys) for remote access via HTTP/SSE.
    *   **Rate Limiting:**  Implement rate limiting middleware for HTTP/SSE transport to prevent abuse.

4.  **Step 28: Advanced Repository Context (Indexing):**
    *   Enhance `repo-query` tool with repository indexing for deeper context-aware answers.
    *   Explore code parsing libraries and potentially vector databases for efficient code indexing and semantic search (as discussed in `cursor-tools-implementation.md`).

5.  **Step 29: Implement Remaining `cursor-tools browser` Features:**
    *   Implement `browser-act`, `browser-observe`, and `browser-extract` tools, following the pattern of `browser-open`.

6.  **Step 30: Health Check Endpoint:**
    *   Implement a basic health check endpoint (e.g., `/healthz` for HTTP/SSE).

7.  **Step 31: Deployment Considerations Documentation:**
    *   Add a section in `README.md` on basic deployment considerations (Docker, cloud platforms).

**IV. Technology Stack:**

*   **Language:** JavaScript (Node.js)
*   **MCP SDK:** `@modelcontextprotocol/sdk` (Node.js)
*   **HTTP Client:** `node-fetch` (or `axios`)
*   **Browser Automation:** `playwright`
*   **AI APIs:** Perplexity AI API, Google Gemini API
*   **Logging:** (e.g., `pino`, `winston`)
*   **Testing:** (e.g., `jest`, `mocha`)

**V.  Beginner-Friendliness Features Summary:**

*   **`stdio` Transport First:** Simplifies initial setup and testing.
*   **Detailed Step-by-Step Guide:**  Phased implementation plan with granular steps.
*   **Clear Installation Instructions:**  Emphasis on npm, environment variables, and Playwright setup.
*   **Quick Start Example:** `test-client.js` for immediate interaction.
*   **Comprehensive README.md:**  Well-structured documentation with troubleshooting and examples.
*   **Modular Design:**  Allows for gradual learning and feature adoption.
*   **Simple Examples:** Start with basic resources and tools to illustrate core concepts.

**VI. Power & Flexibility Features Summary:**

*   **Extensible Architecture:** Modular design for easy addition of new capabilities.
*   **HTTP/SSE Transport Support:** Enables remote access and scalability.
*   **Schema Validation:** Ensures API contract and data integrity.
*   **Robust Error Handling & Logging:**  Production-ready server characteristics.
*   **Security Best Practices Integration:**  Protects server and data.
*   **Advanced Features Planned:** Repository indexing, full browser automation suite, health checks, deployment considerations.

This implementation plan provides a structured roadmap for building a beginner-friendly yet powerful MCP server. By following these phases and steps, and continuously referring to the research and best practices, we can create a valuable tool that effectively integrates AI assistance into development workflows. Remember to prioritize clear communication, documentation, and iterative development throughout the process.
</file>

<file path="local-research/mcp-installation-research.md">
Querying Perplexity AI using sonar-pro for: Research on Claude Anthropic's Model Context Protocol implementation, installation process, and user onboarding. Also find the top 5 most starred MCP servers on GitHub and their installation processes. Focus on user experience and ease of installation.
Claude's Model Context Protocol (MCP) enables integration between AI assistants and external data sources/tools. Key aspects of implementation and installation:

1. Install Claude Desktop app[1][2]
2. Edit Claude Desktop config file to add MCP servers[1][2]
3. Restart Claude app[6]

User onboarding steps:
1. Download Claude Desktop
2. Add Filesystem MCP server to config
3. Restart Claude
4. Test functionality[6]

Top 5 most starred MCP servers on GitHub (as of February 2025):

1. filesystem-mcp: File system access
Installation: `npm install @modelcontextprotocol/server-filesystem`

2. github-mcp: GitHub integration 
Installation: `npm install @modelcontextprotocol/server-github`

3. slack-mcp: Slack integration
Installation: `npm install @modelcontextprotocol/server-slack`

4. postgres-mcp: PostgreSQL database access
Installation: `npm install @modelcontextprotocol/server-postgres`

5. brave-search-mcp: Brave Search integration
Installation: `npm install @modelcontextprotocol/server-brave-search`

User experience is generally straightforward, with most servers installable via npm. Claude Desktop provides a GUI for enabling installed servers[1][2][6].
</file>

<file path="local-research/mcp-plan.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, let's develop a comprehensive plan for building an MCP server.

## Model Context Protocol (MCP) Server Development Plan

**Introduction:**

The Model Context Protocol (MCP) is emerging as a crucial standard for enabling seamless communication between Large Language Model (LLM) applications and external resources and tools. By building an MCP server, we can provide AI agents with structured access to valuable context, enhancing their capabilities within IDEs and other environments. This plan outlines the steps for developing an MCP server that is designed to be both approachable for beginners and robust enough to handle complex interactions.

**I. Architecture Decisions:**

Based on our research, we will adopt the following architectural principles:

*   **Client-Server Model:** We will adhere to the standard MCP client-server architecture. Our server will act as a provider of resources and tools, responding to requests from MCP clients (like AI IDE extensions or agents).
*   **Protocol Layer (MCP SDK):** We will leverage the official MCP SDK (likely the Node.js SDK based on the research example) to handle the underlying protocol complexities, message framing, and schema validation. This ensures compliance and simplifies development.
*   **Transport Layer (Initial: stdio, Future: HTTP/SSE):**
    *   **stdio (Standard Input/Output):**  We will initially implement the `stdio` transport. This is ideal for local development, testing, and scenarios where the MCP client and server run on the same machine. `stdio` simplifies setup and debugging for beginners.
    *   **HTTP/SSE (Server-Sent Events):**  For future expansion and remote access, we will plan for supporting HTTP/SSE. This will enable the server to be hosted independently and accessed by clients over a network.
*   **Modular Design:** The server will be designed with modularity in mind. This means separating concerns into distinct modules, such as:
    *   **Core Server Logic:** Handling MCP protocol interactions, request routing, and capability management.
    *   **Resource Providers:** Modules responsible for fetching and managing specific types of resources (e.g., file system resources, database resources, API data).
    *   **Tool Providers:** Modules implementing specific tools or actions that the server can expose.
    *   **Configuration & Management:**  Handling server configuration, logging, and potentially health checks.
*   **Statelessness:**  We will aim for a stateless server design as much as possible. This improves scalability and simplifies management. Session-specific data should be avoided or handled externally (e.g., by the client or a separate data store) if absolutely necessary.

**II. Implementation Steps:**

Here are the step-by-step instructions to build the MCP server:

1.  **Project Setup:**
    *   **Initialize Node.js Project:**
        ```bash
        mkdir mcp-server
        cd mcp-server
        npm init -y
        ```
    *   **Install MCP SDK:**
        ```bash
        npm install @modelcontextprotocol/sdk
        ```
    *   **(Optional) Install Playwright for potential future browser-based tools:**
        ```bash
        npm install playwright
        ```

2.  **Basic Server Structure (e.g., `server.js`):**
    ```javascript
    // server.js
    import { Server } from "@modelcontextprotocol/sdk/server/index.js";
    import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
    // Import Schemas for requests and responses (as needed - will be defined later)
    // Example schema import (replace with actual schemas):
    // import { ListResourcesRequestSchema, ListResourcesResponseSchema } from './schemas.js';

    async function main() {
        const server = new Server({
            name: "beginner-friendly-mcp-server",
            version: "0.1.0",
            description: "A beginner-friendly MCP server example."
        }, {
            capabilities: {
                resources: { // Define resource capabilities here},
                tools: {      // Define tool capabilities here}
                // prompts: {     // Define prompt capabilities here - optional for initial version}
            }
        });

        // Example Request Handler (for ListResources - adapt based on your schemas)
        // server.setRequestHandler(ListResourcesRequestSchema, async (request) => {
        //     // ... your resource listing logic ...
        //     return { resources: [] }; // Replace with actual resources
        // });


        const transport = new StdioServerTransport();
        await server.connect(transport);
        console.log("MCP Server started using stdio transport.");
    }

    main().catch(console.error);
    ```

3.  **Define Capabilities (Resources and Tools):**
    *   **Start Simple:** For a beginner-friendly approach, begin with a very basic resource and tool. For example:
        *   **Resource:**  A "greeting" resource that returns a simple greeting message.
        *   **Tool:** A "reverse-string" tool that reverses a given string.
    *   **Define Schemas (if needed):**  For more complex interactions, you'll need to define schemas using the MCP SDK's schema definition capabilities. For simple examples, you might be able to start without explicit schemas and use basic JavaScript objects for requests and responses initially for rapid prototyping, but strongly consider adding them for type safety and robustness as you progress.
    *   **Example Capability Definitions (in `server.js` - within `capabilities`):**
        ```javascript
        capabilities: {
            resources: {
                'greeting': { // Resource name
                    list: {  // Capability: listing resources of this type
                        // Optionally define request schema here if needed
                        responseSchema: { // Define response schema
                            type: 'object',
                            properties: {
                                resources: {
                                    type: 'array',
                                    items: {
                                        type: 'object',
                                        properties: {
                                            uri: { type: 'string', description: 'Unique URI for the greeting resource' },
                                            message: { type: 'string', description: 'The greeting message' }
                                        },
                                        required: ['uri', 'message']
                                    }
                                },
                                required: ['resources']
                            }
                        }
                    },
                    read: { // Capability: reading a specific resource
                        requestSchema: { // Define request schema (e.g., for resource URI)
                            type: 'object',
                            properties: {
                                uri: { type: 'string', description: 'URI of the greeting resource to read' }
                            },
                            required: ['uri']
                        },
                        responseSchema: { // Define response schema
                            type: 'object',
                            properties: {
                                resource: {
                                    type: 'object',
                                    properties: {
                                        uri: { type: 'string' },
                                        message: { type: 'string' }
                                    },
                                    required: ['uri', 'message']
                                }
                            },
                            required: ['resource']
                        }
                    }
                }
            },
            tools: {
                'reverseString': { // Tool name
                    execute: { // Capability: executing the tool
                        requestSchema: { // Define request schema (input for the tool)
                            type: 'object',
                            properties: {
                                text: { type: 'string', description: 'Text to reverse' }
                            },
                            required: ['text']
                        },
                        responseSchema: { // Define response schema (output of the tool)
                            type: 'object',
                            properties: {
                                reversedText: { type: 'string', description: 'Reversed text' }
                            },
                            required: ['reversedText']
                        }
                    }
                }
            }
        }
        ```

4.  **Implement Request Handlers:**
    *   **`ListResources` Handler (for "greeting" resource):**
        ```javascript
        server.setRequestHandler('greeting/list', async () => {
            return {
                resources: [
                    { uri: 'greeting://default', message: 'Hello from MCP Server!' },
                    { uri: 'greeting://custom', message: 'Greetings, user!' }
                ]
            };
        });
        ```
    *   **`ReadResource` Handler (for "greeting" resource):**
        ```javascript
        server.setRequestHandler('greeting/read', async (request) => {
            const { uri } = request;
            let message = '';
            if (uri === 'greeting://default') {
                message = 'Hello from MCP Server!';
            } else if (uri === 'greeting://custom') {
                message = 'Greetings, user!';
            } else {
                throw new Error(`Resource URI not found: ${uri}`); // Error handling
            }
            return {
                resource: { uri, message }
            };
        });
        ```
    *   **`ExecuteTool` Handler (for "reverseString" tool):**
        ```javascript
        server.setRequestHandler('reverseString/execute', async (request) => {
            const { text } = request;
            const reversedText = text.split('').reverse().join('');
            return {
                reversedText: reversedText
            };
        });
        ```

5.  **Testing the Server:**
    *   **Using `cursor-tools` (as a basic client):** You can use `cursor-tools` to interact with your MCP server if it supports `stdio`.  However, `cursor-tools` is primarily designed to *use* tools, not act as a generic MCP client *to* a server you're building. For basic testing, you might need to use a more direct MCP client library or write a simple test script.
    *   **Simple Test Script (Node.js):** Create a file (e.g., `test-client.js`) to send requests to your server via `stdio`.  (Example would be more involved and might be a separate task to detail).
    *   **Manual Testing (using MCP Client SDK directly):** Write a small Node.js script that uses the `@modelcontextprotocol/sdk/client` to connect to your server and send requests. This gives you more direct control for testing.

6.  **Error Handling and Logging:**
    *   **Graceful Error Handling:** Implement `try...catch` blocks in your request handlers to catch errors and return informative error responses (as defined by MCP error handling conventions).
    *   **Basic Logging:** Use `console.log` or a more robust logging library (like `winston` or `pino`) to log server events, requests, responses, and errors. This is crucial for debugging and monitoring.

7.  **Documentation (for Beginners):**
    *   **README.md:** Create a `README.md` file in your project root. Include:
        *   Project description (beginner-friendly MCP server).
        *   Setup instructions (Node.js and dependencies).
        *   Running instructions (`node server.js`).
        *   Examples of how to interact with the server (even basic curl examples if using HTTP/SSE later, or instructions for a simple test client).
        *   Explanation of the provided resources and tools.
    *   **Code Comments:** Add clear and concise comments in your code to explain the logic, especially in request handlers and capability definitions.

8.  **Iterative Refinement and Expansion:**
    *   **Add More Resources and Tools:** Gradually expand the server by adding more useful resources and tools. Think about what kind of context or actions would be valuable for AI agents in an IDE or other applications.
    *   **Implement HTTP/SSE Transport:**  Once the `stdio` version is working, add support for HTTP/SSE transport. This will involve using `HttpServerTransport` or `SseServerTransport` from the MCP SDK and setting up an HTTP server (using Node.js `http` or a framework like `express`).
    *   **Security Enhancements:** Implement security best practices as outlined in the research (TLS, authentication, input validation, rate limiting). Start with input validation and consider adding authentication later if needed for remote access.
    *   **Configuration Management:** Externalize configuration (e.g., using environment variables or a configuration file) for server settings, resource locations, etc.
    *   **Health Checks:** Implement a health check endpoint to allow monitoring of server availability.
    *   **Performance Profiling:**  Profile the server's performance and optimize as needed, especially if you are dealing with complex resources or tools.


**III. Best Practices:**

*   **Security:**
    *   **Input Validation:**  Thoroughly validate all incoming requests to prevent injection attacks and ensure data integrity.
    *   **TLS for Remote Connections (HTTP/SSE):**  Enforce TLS (HTTPS) for all remote connections to protect data in transit.
    *   **Authentication (for Remote Access):**  Implement authentication mechanisms if your server will be accessed remotely and needs to control access.
    *   **Rate Limiting:** Implement rate limiting to prevent abuse and ensure server stability.
    *   **Logging Security Events:** Log security-relevant events for auditing and intrusion detection.
*   **Versioning and Backwards Compatibility:**
    *   **Semantic Versioning:** Use semantic versioning for your server (e.g., `0.1.0`, `1.0.0`, `1.1.0`).
    *   **Backwards Compatibility:** Strive to maintain backwards compatibility when making changes. When breaking changes are necessary, introduce them in new versions and consider providing migration paths.
    *   **API Versioning (if needed):** For more complex servers with evolving APIs, consider API versioning (e.g., `/v1/resources`, `/v2/resources`).
*   **Scaling:**
    *   **Horizontal Scaling (for HTTP/SSE):** Design the server to be horizontally scalable. This means you should be able to run multiple instances of the server behind a load balancer to handle increased load. Statelessness helps with horizontal scaling.
    *   **Autoscaling (Future Consideration):** For production deployments, consider autoscaling to dynamically adjust the number of server instances based on demand.
    *   **Meaningful Load Metrics:** Monitor relevant metrics (request rate, latency, resource usage) to understand server load and identify scaling needs.
*   **State Management:**
    *   **Stateless Server (Recommended):** Aim for a stateless server design. Avoid storing session-specific data within the server process.
    *   **External Data Stores:** If persistent data is required, use external databases or caching mechanisms rather than relying on server-side session state.

**IV. Beginner-Friendly Features:**

*   **Simple `stdio` Transport:** Start with `stdio` for easy local testing and development without needing to configure network settings.
*   **Minimalistic Examples:** Provide simple, easy-to-understand examples of resources and tools.
*   **Clear Documentation:** Focus on clear and concise documentation, especially in the `README.md`, to guide beginners through setup, running, and basic usage.
*   **Step-by-Step Guide:**  The implementation steps outlined above are designed to be a step-by-step guide for building the server incrementally.
*   **Focus on Core Concepts:** Initially, focus on the core MCP concepts of resources, tools, and request handling, without overwhelming beginners with advanced features.

**V. Powerful Features (Future Enhancements):**

*   **Extensible Resource and Tool System:** Design the server to be easily extensible, allowing developers to add new resource providers and tools as needed. Use a plugin-based architecture or modular design to facilitate this.
*   **Support for Multiple Transport Layers:**  Supporting both `stdio` and HTTP/SSE provides flexibility for different deployment scenarios (local vs. remote).
*   **Robust Error Handling and Logging:**  Comprehensive error handling and logging are essential for production-ready servers.
*   **Schema Validation:**  Enforce schema validation for requests and responses to ensure data integrity and type safety (using the MCP SDK's schema capabilities).
*   **Security Features:**  Implement robust security features as described in best practices to protect the server and its data.
*   **Integration with AI IDEs:**  As the MCP ecosystem matures, aim for seamless integration with popular AI IDEs by providing resources and tools that are relevant to code editing, analysis, and generation workflows.


**Conclusion:**

This plan provides a roadmap for building a beginner-friendly yet powerful MCP server. By starting with a simple architecture, focusing on core concepts, and iteratively adding features and best practices, we can create a valuable tool for enabling AI agents with contextual awareness. The initial focus on `stdio` transport and basic resources/tools makes it approachable for beginners, while the planned expansions and best practices ensure the server can evolve into a robust and scalable solution. Remember to prioritize clear documentation and incremental development to make the process manageable and successful.
</file>

<file path="local-research/mcp-research.md">
Querying Perplexity AI using sonar-pro for: Detailed research on Model Context Protocol (MCP) server architecture, implementation best practices, and guidelines for generating project artifacts and IDE rules. Include specific details about server design, rule generation, and integration with AI IDEs.
The Model Context Protocol (MCP) is an open standard for communication between LLM applications and external data sources/tools[1][4]. Key aspects of MCP server architecture and implementation include:

Architecture:
- Client-server model with hosts (LLM apps), clients (maintain 1:1 connections), and servers (provide context/tools)[1]
- Protocol layer handles message framing and communication patterns[1]
- Transport layer supports stdio (local) and HTTP/SSE (remote) communication[1]

Claude's MCP Implementation:
- Anthropic implements MCP in Claude through a standardized interface for accessing external tools and context
- Installation is handled through the Claude API client libraries (Python, Node.js, etc.)
- Users don't need to install MCP separately - it's built into the Claude SDK
- Claude's implementation focuses on security and validation of tool/context access
- Provides built-in support for common tools like web search, file operations, and code analysis

Popular MCP Server Implementations (by GitHub stars):

1. cursor-tools (2.3k stars)
   - Installation: `npm install -g cursor-tools`
   - Simple CLI-based installation and usage
   - Excellent documentation and examples
   - Focus on IDE integration and developer tools

2. mcp-server (1.8k stars)
   - Installation: `npm install @mcp/server`
   - Modular architecture with plugin support
   - Comprehensive security features
   - Built-in monitoring and scaling support

3. anthropic-mcp (1.5k stars)
   - Installation: `pip install anthropic-mcp`
   - Official Anthropic MCP reference implementation
   - Extensive documentation and tutorials
   - Strong focus on security and validation

4. mcp-toolkit (1.2k stars)
   - Installation: `npm install mcp-toolkit`
   - Batteries-included approach with many tools
   - Easy-to-use API and configuration
   - Active community and regular updates

5. mcp-core (900 stars)
   - Installation: `npm install mcp-core`
   - Minimal, lightweight implementation
   - Focus on performance and stability
   - Excellent for learning and customization

Best Practices for Easy Installation:
- Provide clear installation instructions in README
- Use standard package managers (npm, pip)
- Include quick start guides and examples
- Automate dependency installation
- Provide configuration templates
- Include troubleshooting guides

Server implementation:
```javascript
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

const server = new Server({
  name: "example-server",
  version: "1.0.0"
}, {
  capabilities: {
    resources: {}
  }
});

server.setRequestHandler(ListResourcesRequestSchema, async () => {
  return {
    resources: [
      {
        uri: "example://resource",
        name: "Example Resource"
      }
    ]
  };
});

const transport = new StdioServerTransport();
await server.connect(transport);
```

Best practices:
- Use stdio transport for local processes, SSE for remote[1]
- Validate inputs, use type-safe schemas, handle errors gracefully[1]
- Implement timeouts and progress reporting for long operations[1]
- Use TLS for remote connections, validate origins, implement authentication[1]
- Log protocol events, implement health checks, profile performance[1]

For generating project artifacts and IDE rules:
- MCP servers can provide resources (data), tools (actions), and prompts (templates)[4][6]
- Servers expose functionality through endpoints like resources/list, resources/read[6]
- AI IDEs like IntelliJ IDEA use MCP to access project structure and code context[6]

Integration with AI IDEs:
- Implement MCP servers to expose project artifacts, code structure, and IDE functionality[6]
- Use resources to represent files, database records, API responses[6]
- Implement tools for code generation, refactoring, and other IDE actions
- Create prompts for common coding tasks and interactions

Rule generation:
- Define schemas for different artifact types (e.g. code files, models, configs)
- Implement validation logic in MCP server to enforce project rules
- Expose rule checking as MCP tools that can be invoked by AI agents

Example rule implementation:
```javascript
server.setRequestHandler(CheckCodeStyleSchema, async (request) => {
  const { code } = request;
  const violations = linter.checkStyle(code);
  return {
    valid: violations.length === 0,
    violations: violations
  };
});
```
</file>

<file path="local-research/mcp-setup-guide.md">
# Beginner-Friendly MCP Server Setup Guide

This guide will walk you through setting up a basic Model Context Protocol (MCP) server with initial functionality. We'll focus on getting the core server running and implementing basic features.

## Prerequisites

Before starting, ensure you have:
- Node.js (v14 or later) installed
- npm (Node Package Manager) installed
- A code editor (like VS Code)
- Basic familiarity with JavaScript/Node.js

## Phase 1: Initial Project Setup

### Step 1: Create Project Directory and Initialize

1. Open your terminal and create a new directory for your project:
```bash
mkdir beginner-mcp-server
cd beginner-mcp-server
```

2. Initialize a new Node.js project:
```bash
npm init -y
```

3. Install the required dependencies:
```bash
npm install @modelcontextprotocol/sdk node-fetch
```

### Step 2: Create Basic Server Structure

1. Create a new file called `server.js` in your project root:
```javascript
// server.js
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

async function main() {
    // Create server instance
    const server = new Server({
        name: "beginner-mcp-server",
        version: "0.1.0",
        description: "A beginner-friendly MCP server implementation"
    }, {
        capabilities: {
            resources: {},
            tools: {}
        }
    });

    // Create stdio transport
    const transport = new StdioServerTransport();

    // Connect server to transport
    console.log("Starting MCP server...");
    await server.connect(transport);
    console.log("MCP server is running!");
}

main().catch(error => {
    console.error("Server error:", error);
    process.exit(1);
});
```

2. Update `package.json` to enable ES modules:
```json
{
  "type": "module",
  // ... other existing fields ...
}
```

### Step 3: Test Basic Server

1. Run the server:
```bash
node server.js
```

You should see:
```
Starting MCP server...
MCP server is running!
```

## Phase 2: Implementing Basic Resources and Tools

### Step 1: Create Directory Structure

1. Create directories for capabilities:
```bash
mkdir -p capabilities/resources
mkdir -p capabilities/tools
```

### Step 2: Implement Greeting Resource

1. Create `capabilities/resources/greeting.js`:
```javascript
// capabilities/resources/greeting.js

export const greetingResource = {
    name: 'greeting',
    version: '0.1.0',
    description: 'A simple greeting resource',

    // List available greetings
    list: async () => {
        return {
            resources: [
                {
                    uri: "greeting://hello",
                    name: "Hello Greeting"
                },
                {
                    uri: "greeting://hi",
                    name: "Hi Greeting"
                }
            ]
        };
    },

    // Read a specific greeting
    read: async (request) => {
        const { uri } = request;
        
        let greeting;
        switch (uri) {
            case "greeting://hello":
                greeting = "Hello, World!";
                break;
            case "greeting://hi":
                greeting = "Hi there!";
                break;
            default:
                throw new Error(`Unknown greeting URI: ${uri}`);
        }

        return {
            resource: {
                uri,
                message: greeting
            }
        };
    },

    // Define schemas
    listResponseSchema: {
        type: 'object',
        properties: {
            resources: {
                type: 'array',
                items: {
                    type: 'object',
                    properties: {
                        uri: { type: 'string' },
                        name: { type: 'string' }
                    },
                    required: ['uri', 'name']
                }
            }
        },
        required: ['resources']
    },

    readRequestSchema: {
        type: 'object',
        properties: {
            uri: { type: 'string' }
        },
        required: ['uri']
    },

    readResponseSchema: {
        type: 'object',
        properties: {
            resource: {
                type: 'object',
                properties: {
                    uri: { type: 'string' },
                    message: { type: 'string' }
                },
                required: ['uri', 'message']
            }
        },
        required: ['resource']
    }
};
```

### Step 3: Implement Reverse String Tool

1. Create `capabilities/tools/reverse-string.js`:
```javascript
// capabilities/tools/reverse-string.js

export const reverseStringTool = {
    name: 'reverse-string',
    version: '0.1.0',
    description: 'A tool that reverses input strings',

    execute: async (request) => {
        const { text } = request;
        if (!text) {
            throw new Error("Text parameter is required");
        }

        return {
            reversed: text.split('').reverse().join('')
        };
    },

    requestSchema: {
        type: 'object',
        properties: {
            text: { type: 'string' }
        },
        required: ['text']
    },

    responseSchema: {
        type: 'object',
        properties: {
            reversed: { type: 'string' }
        },
        required: ['reversed']
    }
};
```

### Step 4: Update Server to Include New Capabilities

1. Update `server.js` to include the new resource and tool:
```javascript
// server.js
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { greetingResource } from './capabilities/resources/greeting.js';
import { reverseStringTool } from './capabilities/tools/reverse-string.js';

async function main() {
    const server = new Server({
        name: "beginner-mcp-server",
        version: "0.1.0",
        description: "A beginner-friendly MCP server implementation"
    }, {
        capabilities: {
            resources: {
                'greeting': greetingResource
            },
            tools: {
                'reverse-string': reverseStringTool
            }
        }
    });

    const transport = new StdioServerTransport();
    
    console.log("Starting MCP server...");
    await server.connect(transport);
    console.log("MCP server is running!");
}

main().catch(error => {
    console.error("Server error:", error);
    process.exit(1);
});
```

### Step 5: Create Test Client

1. Create `test-client.js` to test the server:
```javascript
// test-client.js
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";

async function main() {
    const transport = new StdioClientTransport();
    const client = new Client();
    
    try {
        await client.connect(transport);
        console.log("Connected to MCP server");

        // Test greeting resource - list
        console.log("\nTesting greeting resource (list):");
        const greetingList = await client.listResources({
            resourceName: 'greeting',
            version: '0.1.0'
        });
        console.log("Available greetings:", greetingList.resource_list.resources);

        // Test greeting resource - read
        console.log("\nTesting greeting resource (read):");
        const greeting = await client.readResource({
            resourceUri: "greeting://hello"
        });
        console.log("Greeting message:", greeting.resource_response.resource.message);

        // Test reverse-string tool
        console.log("\nTesting reverse-string tool:");
        const reversed = await client.executeTool({
            toolName: 'reverse-string',
            version: '0.1.0',
            arguments: {
                text: "Hello, World!"
            }
        });
        console.log("Reversed text:", reversed.tool_response.reversed);

    } catch (error) {
        console.error("Error:", error);
    } finally {
        client.close();
    }
}

main();
```

### Step 6: Test Everything

1. In one terminal, start the server:
```bash
node server.js
```

2. In another terminal, run the test client:
```bash
node test-client.js
```

You should see output like:
```
Connected to MCP server

Testing greeting resource (list):
Available greetings: [
  { uri: 'greeting://hello', name: 'Hello Greeting' },
  { uri: 'greeting://hi', name: 'Hi Greeting' }
]

Testing greeting resource (read):
Greeting message: Hello, World!

Testing reverse-string tool:
Reversed text: !dlroW ,olleH
```

## Next Steps

Now that you have a basic MCP server running with a resource and a tool, you can:

1. Add error handling and logging to make the server more robust
2. Implement more complex resources and tools
3. Add configuration options
4. Explore the other phases in the implementation plan

Remember to:
- Keep your code modular and well-documented
- Test thoroughly as you add new features
- Follow the MCP protocol specifications
- Consider security implications as you expand functionality
</file>

<file path="local-research/mcp-user-experience.md">
Querying Perplexity AI using sonar-pro for: What are the most important considerations for making an MCP server beginner-friendly while maintaining its power and flexibility? Include specific examples of user-friendly APIs and documentation approaches.
Key considerations for beginner-friendly MCP servers:

1. Simple setup and configuration:
- Provide clear step-by-step installation instructions
- Use sensible defaults
- Offer a quickstart guide with minimal configuration[3]

2. Intuitive API design:
- Use descriptive method names
- Implement consistent parameter naming
- Provide type hints and documentation[4]

Example:
```typescript
/**
 * Retrieves user information.
 * @param userId The unique identifier of the user
 * @returns User object containing name, email, and role
 */
async function getUser(userId: string): Promise<User> {
  // Implementation
}
```

3. Comprehensive documentation:
- Include usage examples for common scenarios
- Provide API reference with all available methods
- Explain key concepts and architecture[1]

4. Error handling and feedback:
- Return descriptive error messages
- Implement logging for debugging
- Provide suggestions for resolving common issues[3]

5. Modular design:
- Allow gradual feature adoption
- Implement plugin system for extensibility
- Use dependency injection for flexibility[6]

6. Interactive learning tools:
- Offer an interactive CLI for exploration
- Provide a playground environment
- Include tutorials with step-by-step walkthroughs[2]

7. Community support:
- Maintain active GitHub repository
- Offer discussion forums or chat channels
- Encourage contributions and feedback[5]
</file>

<file path="local-research/typescript-esm-config.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
To properly configure TypeScript for ES modules with Node.js, you need to adjust settings in both your `tsconfig.json` and `package.json` files. Here's a breakdown of the key configurations:

**1. `package.json` Configuration:**

   - **`"type": "module"`**:  This is crucial. Add `"type": "module"` to your `package.json` file. This tells Node.js to treat `.js` files in your project as ES modules.

   ```json
   {
     "name": "your-project",
     "version": "1.0.0",
     "type": "module", //    Important!
     "main": "dist/server.js",
     "scripts": {
       "build": "tsc",
       "start": "node dist/server.js",
       "dev": "ts-node --esm src/server.ts"
     },
     // ... other configurations
   }
   ```

**2. `tsconfig.json` Configuration:**

   Here's a recommended `tsconfig.json` configuration for ES modules in Node.js, based on best practices and the configuration present in the provided files:

   ```json
   {
     "compilerOptions": {
       "target": "ES2020",       // Or a later ECMAScript version that supports ES modules
       "module": "NodeNext",      //    Use "NodeNext" or "ESNext" for ES modules in Node.js
       "moduleResolution": "NodeNext", //   Crucial for Node.js-style module resolution in ES modules
       "outDir": "./dist",        // Output directory for compiled JavaScript files
       "rootDir": "./src",        // Root directory of your TypeScript source files
       "strict": true,            // Enable strict type checking for better code quality
       "esModuleInterop": true,   //    Enable interoperability with CommonJS modules
       "skipLibCheck": true,      // Skip type checking of declaration files (improves build speed)
       "forceConsistentCasingInFileNames": true, // Enforce consistent casing in file names
       "resolveJsonModule": true,  // Allow importing JSON files as modules
       "allowJs": true,           // Allow importing and compiling JavaScript files (if needed)
       "declaration": true        // Generate declaration files (.d.ts) for your library (optional)
     },
     "ts-node": {
       "esm": true,             //   Enable ES module support for ts-node
       "experimentalSpecifiers": true //    Required for some ES module features with ts-node
     },
     "include": ["src/**/*"],   //  Include all files in the 'src' directory
     "exclude": ["node_modules", "dist"] // Exclude 'node_modules' and 'dist' directories
   }
   ```

   **Explanation of Key `compilerOptions`:**

   - **`target`**:  `ES2020` or later is recommended to align with modern Node.js features and ES module support.
   - **`module`**:  **`NodeNext`** or **`ESNext`** are the correct choices for Node.js ES modules. These options ensure that TypeScript emits code that Node.js can directly understand as ES modules.
   - **`moduleResolution`**: **`NodeNext`** or **`Node16`** are crucial.  `NodeNext` is generally preferred for newer Node.js versions.  These settings tell TypeScript to use Node.js's specific module resolution algorithm for ES modules, which is different from CommonJS.
   - **`esModuleInterop`**:  This is important for allowing seamless import of CommonJS modules into your ES module code. It handles default exports and namespaces for compatibility.
   - **`ts-node` section**: The `ts-node` section is used to configure `ts-node` specifically for running TypeScript code directly in development with ES module support.  `"esm": true` and `"experimentalSpecifiers": true` are essential for this.

**3. File Extensions:**

   - **TypeScript Files**: Use `.ts` for your TypeScript files. You can also use `.mts` if you want to explicitly denote a file as a TypeScript ES module, though `.ts` generally works fine when `"type": "module"` is set in `package.json`.
   - **JavaScript Output**: TypeScript will emit `.js` files in your `outDir` (e.g., `dist`).  When Node.js loads these `.js` files, it will treat them as ES modules because of the `"type": "module"` setting in `package.json`.

**4. Building and Running:**

   - **Build**: Compile your TypeScript code using the TypeScript compiler:

     ```bash
     npm run build  #  (or yarn build, pnpm build, depending on your package manager)
     ```
     This will use the `tsc` command defined in your `scripts` in `package.json` (e.g., `"build": "tsc"`). It will generate JavaScript files in your `outDir` (e.g., `dist`).

   - **Run**:  Execute your compiled server (or main entry point) using Node.js:

     ```bash
     npm start       # (or yarn start, pnpm start) - for production (runs compiled code)
     npm run dev     # (or yarn dev, pnpm dev)   - for development (uses ts-node for direct execution)
     ```

     - **`npm start`**:  Runs the compiled JavaScript code in the `dist` folder using `node dist/server.js`. Node.js will treat `dist/server.js` as an ES module due to `"type": "module"` in `package.json`.
     - **`npm run dev`**: Uses `ts-node --esm src/server.ts`.  The `--esm` flag tells `ts-node` to run your TypeScript code as ES modules. The `ts-node` configuration in `tsconfig.json` further ensures ES module compatibility during development.

**Example Project Structure:**

```
mcp-server/
 src/
    server.ts
    ... other TypeScript files ...
 dist/             (Output directory after `npm run build`)
    server.js      (Compiled JavaScript ES module)
 package.json
 tsconfig.json
```

**Key Considerations:**

- **Node.js Version**: Ensure you are using a Node.js version that fully supports ES modules (Node.js 14.x or later is recommended).
- **`ts-node`**:  `ts-node` with the `--esm` flag is very helpful for development as it allows you to run your TypeScript ES modules directly without needing to compile first.
- **Module Resolution**: Understanding `moduleResolution: "NodeNext"` (or `"Node16"`) is critical for correctly resolving modules in a Node.js ES module environment. It closely mirrors how Node.js itself resolves ES modules.
- **Interoperability**: `esModuleInterop: true` is generally recommended for most projects as it simplifies working with both ES modules and CommonJS modules in the same project or when using dependencies that might be in CommonJS format.

By following these configurations, you will have a TypeScript project properly set up to use ES modules with Node.js, both for development and production builds.
</file>

<file path="mcp-server/.eslintrc.json">
{
  "env": {
    "es2022": true,
    "node": true,
    "jest": true
  },
  "extends": [
    "eslint:recommended",
    "plugin:@typescript-eslint/recommended",
    "plugin:prettier/recommended"
  ],
  "parser": "@typescript-eslint/parser",
  "parserOptions": {
    "ecmaVersion": "latest",
    "sourceType": "module"
  },
  "plugins": ["@typescript-eslint"],
  "rules": {
    "@typescript-eslint/explicit-function-return-type": "warn",
    "@typescript-eslint/no-unused-vars": "error",
    "@typescript-eslint/no-explicit-any": "warn",
    "prettier/prettier": "error"
  }
}
</file>

<file path="mcp-server/.prettierrc">
{
  "semi": true,
  "trailingComma": "es5",
  "singleQuote": true,
  "printWidth": 100,
  "tabWidth": 2,
  "useTabs": false
}
</file>

<file path="mcp-server/.repomix-output.txt">
This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-21T02:04:12.074Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
src/capabilities/resources/
src/config/
src/utils/
local-research/implementation-plan.md
local-research/mcp-implementation-research.md
package.json
src/capabilities/tools/web-search.js
src/capabilities/tools/web-search.ts
src/server.js
src/server.ts
src/test-client.js
src/test-client.ts
src/test-setup.js
src/test-setup.mjs
src/test-setup.ts
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="local-research/implementation-plan.md">
Packing repository using repomix...
</file>

<file path="local-research/mcp-implementation-research.md">
Querying Perplexity AI using sonar-pro for: 1. What are the best practices for implementing transport layers in MCP servers? 2. What are the recommended security measures for MCP server implementations? 3. What are the optimal caching and rate limiting strategies for external API calls in MCP servers? 4. What are the recommended testing approaches for MCP server capabilities? 5. What are the best practices for error handling and logging in MCP servers? 6. What are the recommended scalability patterns for MCP server implementations?
1. Best practices for implementing transport layers in MCP servers:
- Use layered architecture with clear separation between client/server, session, and transport layers[1].
- Implement different transports for various use cases: STDIO for in-process communication, SSE for HTTP-based communication[1].
- Handle JSON-RPC message serialization/deserialization in the transport layer[1].
- Ensure proper connection establishment, protocol compatibility checks, and capability negotiation[1].

2. Recommended security measures for MCP server implementations:
- Implement strict input validation and sanitization[4].
- Use command whitelisting and flag validation for CLI-based servers[2].
- Prevent path traversal and shell injection attacks[2].
- Implement execution timeouts and command length limits[2].
- Use TLS encryption for API endpoints, especially in management networks[7].
- Employ access controls and proper authentication mechanisms[7].
- Use IDS/IPS for admin networks to detect anomalies[7].

3. Optimal caching and rate limiting strategies for external API calls:
- Implement token bucket algorithm for rate limiting[3]:
```csharp
builder.Services.AddRateLimiter(rateLimiterOptions => {
  options.TokenLimit = 1000;
  options.ReplenishmentPeriod = TimeSpan.FromHours(1);
  options.TokensPerPeriod = 700;
  options.AutoReplenishment = true;
});
```
- Use sliding window rate limiting for more precise control[9].
- Implement IP-based rate limiting to prevent abuse[9].
- Use distributed caching for scalability.

4. Recommended testing approaches for MCP server capabilities:
- Use the MCP Inspector tool for systematic testing[4].
- Test core features first, then add edge cases[4].
- Verify error handling and check performance[4].
- Implement a systematic approach: test core features, add edge cases, verify error handling, check performance[4].
- Use the Inspector during development for quick iteration[5].

5. Best practices for error handling and logging in MCP servers:
- Implement structured logging with consistent formats, context, and timestamps[5].
- Log stack traces, error context, and track error patterns[5].
- Use server-side logging to stderr for local transports[5].
- Send log message notifications to clients:
```python
server.request_context.session.send_log_message(
  level="info",
  data="Server started successfully"
)
```
- Log important events: initialization, resource access, tool execution, errors, performance metrics[5].

6. Recommended scalability patterns for MCP server implementations:
- Use asynchronous operations for improved concurrency[1].
- Implement proper connection management and cleanup[4].
- Use load balancing for distributing requests[7].
- Employ horizontal scaling by adding more server instances.
- Implement efficient resource management and monitoring[4].
</file>

<file path="package.json">
{
  "name": "mcp-server",
  "version": "1.0.0",
  "description": "A beginner-friendly MCP server implementation",
  "type": "module",
  "main": "dist/server.js",
  "scripts": {
    "build": "tsc",
    "start": "node dist/server.js",
    "dev": "ts-node --esm src/server.ts",
    "test": "node src/test-setup.mjs"
  },
  "keywords": [
    "mcp",
    "server",
    "model-context-protocol"
  ],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "@modelcontextprotocol/sdk": "1.2.0",
    "@octokit/rest": "19.0.13",
    "axios": "1.6.5",
    "dotenv": "16.3.1",
    "playwright": "1.41.2",
    "zod": "^3.24.2"
  },
  "devDependencies": {
    "@types/node": "20.11.5",
    "ts-node": "10.9.2",
    "typescript": "5.3.3"
  }
}
</file>

<file path="src/capabilities/tools/web-search.js">
"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.webSearchTool = void 0;
const axios_1 = __importDefault(require("axios"));
const dotenv_1 = __importDefault(require("dotenv"));
// Load environment variables
dotenv_1.default.config();
const PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions";
const PERPLEXITY_API_KEY = process.env.PERPLEXITY_API_KEY;
exports.webSearchTool = {
    name: 'web-search',
    version: '0.1.0',
    description: 'Performs a web search using Perplexity AI.',
    execute: (request) => __awaiter(void 0, void 0, void 0, function* () {
        var _a, _b, _c, _d;
        if (!PERPLEXITY_API_KEY) {
            throw new Error("Perplexity API key is not set in environment variables (PERPLEXITY_API_KEY)");
        }
        const { query, saveTo } = request;
        if (!query) {
            throw new Error("Search query is required.");
        }
        try {
            console.log(` Performing web search: "${query}"`);
            const response = yield axios_1.default.post(PERPLEXITY_API_URL, {
                model: "pplx-7b-online",
                messages: [{ role: "user", content: query }]
            }, {
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${PERPLEXITY_API_KEY}`
                }
            });
            const searchResults = ((_b = (_a = response.data.choices[0]) === null || _a === void 0 ? void 0 : _a.message) === null || _b === void 0 ? void 0 : _b.content) || "No results found.";
            // If saveTo is specified, save results to file
            if (saveTo) {
                const fs = yield Promise.resolve().then(() => __importStar(require('fs/promises')));
                yield fs.writeFile(saveTo, searchResults, 'utf-8');
                console.log(` Results saved to: ${saveTo}`);
                return { searchResults, savedToFile: saveTo };
            }
            return { searchResults };
        }
        catch (error) {
            console.error(" Error during web search:", error);
            if (axios_1.default.isAxiosError(error)) {
                throw new Error(`Web search failed: ${((_d = (_c = error.response) === null || _c === void 0 ? void 0 : _c.data) === null || _d === void 0 ? void 0 : _d.error) || error.message}`);
            }
            throw new Error(`Web search failed: ${error}`);
        }
    }),
    requestSchema: {
        type: 'object',
        properties: {
            query: {
                type: 'string',
                description: 'The search query.'
            },
            saveTo: {
                type: 'string',
                description: 'Optional file path to save the search results.'
            }
        },
        required: ['query']
    },
    responseSchema: {
        type: 'object',
        properties: {
            searchResults: {
                type: 'string',
                description: 'Web search results.'
            },
            savedToFile: {
                type: 'string',
                description: 'Path to the file where results were saved, if applicable.'
            }
        },
        required: ['searchResults']
    }
};
</file>

<file path="src/capabilities/tools/web-search.ts">
import axios from 'axios';
import dotenv from 'dotenv';
// Load environment variables
dotenv.config();
const PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions";
const PERPLEXITY_API_KEY = process.env.PERPLEXITY_API_KEY;
interface WebSearchRequest {
    query: string;
    saveTo?: string;
}
interface WebSearchResponse {
    searchResults: string;
    savedToFile?: string;
}
export const webSearchTool = {
    name: 'web-search',
    version: '0.1.0',
    description: 'Performs a web search using Perplexity AI.',
    execute: async (request: WebSearchRequest): Promise<WebSearchResponse> => {
        if (!PERPLEXITY_API_KEY) {
            throw new Error("Perplexity API key is not set in environment variables (PERPLEXITY_API_KEY)");
        }
        const { query, saveTo } = request;
        if (!query) {
            throw new Error("Search query is required.");
        }
        try {
            console.log(` Performing web search: "${query}"`);
            const response = await axios.post(PERPLEXITY_API_URL, {
                model: "pplx-7b-online",
                messages: [{ role: "user", content: query }]
            }, {
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${PERPLEXITY_API_KEY}`
                }
            });
            const searchResults = response.data.choices[0]?.message?.content || "No results found.";
            // If saveTo is specified, save results to file
            if (saveTo) {
                const fs = await import('fs/promises');
                await fs.writeFile(saveTo, searchResults, 'utf-8');
                console.log(` Results saved to: ${saveTo}`);
                return { searchResults, savedToFile: saveTo };
            }
            return { searchResults };
        } catch (error) {
            console.error(" Error during web search:", error);
            if (axios.isAxiosError(error)) {
                throw new Error(`Web search failed: ${error.response?.data?.error || error.message}`);
            }
            throw new Error(`Web search failed: ${error}`);
        }
    },
    requestSchema: {
        type: 'object',
        properties: {
            query: { 
                type: 'string', 
                description: 'The search query.' 
            },
            saveTo: { 
                type: 'string', 
                description: 'Optional file path to save the search results.' 
            }
        },
        required: ['query']
    },
    responseSchema: {
        type: 'object',
        properties: {
            searchResults: { 
                type: 'string', 
                description: 'Web search results.' 
            },
            savedToFile: { 
                type: 'string', 
                description: 'Path to the file where results were saved, if applicable.' 
            }
        },
        required: ['searchResults']
    }
};
</file>

<file path="src/server.js">
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("@modelcontextprotocol/sdk/server/index.js");
const stdio_js_1 = require("@modelcontextprotocol/sdk/server/stdio.js");
const web_search_js_1 = require("./capabilities/tools/web-search.js");
function main() {
    return __awaiter(this, void 0, void 0, function* () {
        try {
            console.log("Starting MCP server...");
            const server = new index_js_1.Server({
                name: "cursor-tools-mcp-server",
                version: "0.1.0",
                description: "MCP server mimicking cursor-tools functionalities."
            }, {
                capabilities: {
                    resources: {}, // Resources will be defined here
                    tools: {
                        'web-search': web_search_js_1.webSearchTool
                    }
                }
            });
            const transport = new stdio_js_1.StdioServerTransport();
            console.log("Connecting to transport...");
            yield server.connect(transport);
            console.log(" MCP Server started using stdio transport.");
            console.log("Available tools:");
            console.log("  - web-search: Perform web searches using Perplexity AI");
        }
        catch (error) {
            console.error(" Server failed to start:", error);
            process.exit(1);
        }
    });
}
// Handle process termination
process.on('SIGINT', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
process.on('SIGTERM', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
// Start the server
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="src/server.ts">
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { webSearchTool } from './capabilities/tools/web-search.js';
async function main() {
    try {
        console.log("Starting MCP server...");
        const server = new Server({
            name: "cursor-tools-mcp-server",
            version: "0.1.0",
            description: "MCP server mimicking cursor-tools functionalities."
        }, {
            capabilities: {
                resources: {}, // Resources will be defined here
                tools: {
                    'web-search': webSearchTool
                }
            }
        });
        const transport = new StdioServerTransport();
        console.log("Connecting to transport...");
        await server.connect(transport);
        console.log(" MCP Server started using stdio transport.");
        console.log("Available tools:");
        console.log("  - web-search: Perform web searches using Perplexity AI");
    } catch (error) {
        console.error(" Server failed to start:", error);
        process.exit(1);
    }
}
// Handle process termination
process.on('SIGINT', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
process.on('SIGTERM', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
// Start the server
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="src/test-client.js">
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("@modelcontextprotocol/sdk/client/index.js");
const stdio_js_1 = require("@modelcontextprotocol/sdk/client/stdio.js");
const zod_1 = require("zod");
// Define response schema
const WebSearchResponseSchema = zod_1.z.object({
    result: zod_1.z.object({
        searchResults: zod_1.z.string(),
        savedToFile: zod_1.z.string().optional()
    })
});
function main() {
    return __awaiter(this, void 0, void 0, function* () {
        // Initialize transport with required parameters
        const transport = new stdio_js_1.StdioClientTransport({
            command: 'node',
            args: ['dist/server.js']
        });
        const client = new index_js_1.Client({
            name: "test-client",
            version: "0.1.0"
        }, {
            capabilities: {}
        });
        try {
            console.log("Connecting to MCP server...");
            yield client.connect(transport);
            console.log(" Connected to MCP server\n");
            // Test web search
            console.log("Testing web search tool...");
            const response = yield client.request({
                method: "tool/execute",
                params: {
                    toolName: 'web-search',
                    version: '0.1.0',
                    arguments: {
                        query: "What are the latest developments in AI?",
                        saveTo: "local-research/ai-developments.md"
                    }
                }
            }, WebSearchResponseSchema);
            console.log("\nWeb Search Results:");
            console.log("------------------");
            console.log(response.result.searchResults);
            if (response.result.savedToFile) {
                console.log(`\nResults saved to: ${response.result.savedToFile}`);
            }
        }
        catch (error) {
            console.error(" Error:", error);
        }
        finally {
            console.log("\nClosing client connection...");
            client.close();
        }
    });
}
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="src/test-client.ts">
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import { z } from 'zod';
// Define response schema
const WebSearchResponseSchema = z.object({
    result: z.object({
        searchResults: z.string(),
        savedToFile: z.string().optional()
    })
});
async function main() {
    // Initialize transport with required parameters
    const transport = new StdioClientTransport({
        command: 'node',
        args: ['dist/server.js']
    });
    const client = new Client({
        name: "test-client",
        version: "0.1.0"
    }, {
        capabilities: {}
    });
    try {
        console.log("Connecting to MCP server...");
        await client.connect(transport);
        console.log(" Connected to MCP server\n");
        // Test web search
        console.log("Testing web search tool...");
        const response = await client.request({
            method: "tool/execute",
            params: {
                toolName: 'web-search',
                version: '0.1.0',
                arguments: {
                    query: "What are the latest developments in AI?",
                    saveTo: "local-research/ai-developments.md"
                }
            }
        }, WebSearchResponseSchema);
        console.log("\nWeb Search Results:");
        console.log("------------------");
        console.log(response.result.searchResults);
        if (response.result.savedToFile) {
            console.log(`\nResults saved to: ${response.result.savedToFile}`);
        }
    } catch (error) {
        console.error(" Error:", error);
    } finally {
        console.log("\nClosing client connection...");
        client.close();
    }
}
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="src/test-setup.js">
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("@modelcontextprotocol/sdk/server/index.js");
const playwright_1 = require("playwright");
const rest_1 = require("@octokit/rest");
const axios_1 = __importDefault(require("axios"));
const dotenv_1 = __importDefault(require("dotenv"));
function testSetup() {
    return __awaiter(this, void 0, void 0, function* () {
        try {
            console.log(' Starting dependency verification...\n');
            // Test dotenv first to load environment variables
            dotenv_1.default.config();
            console.log(' dotenv loaded successfully');
            // Test MCP SDK
            const server = new index_js_1.Server({
                name: "test-server",
                version: "1.0.0"
            }, {
                capabilities: {
                    resources: {},
                    tools: {}
                }
            });
            console.log(' MCP SDK initialized successfully');
            // Test Playwright
            console.log('\n Testing browser automation...');
            const browser = yield playwright_1.chromium.launch();
            yield browser.close();
            console.log(' Playwright working correctly');
            // Test Octokit
            console.log('\n Testing GitHub integration...');
            const octokit = new rest_1.Octokit();
            const { status } = yield octokit.rest.meta.root();
            console.log(` Octokit connected successfully (status: ${status})`);
            // Test Axios
            console.log('\n Testing HTTP client...');
            const response = yield axios_1.default.get('https://api.github.com');
            console.log(` Axios working correctly (status: ${response.status})`);
            console.log('\n All dependencies verified successfully!');
        }
        catch (error) {
            console.error('\n Setup test failed:', error);
            process.exit(1);
        }
    });
}
testSetup();
</file>

<file path="src/test-setup.mjs">
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { chromium } from 'playwright';
import { Octokit } from '@octokit/rest';
import axios from 'axios';
import dotenv from 'dotenv';

async function testSetup() {
  try {
    console.log(' Starting dependency verification...\n');

    // Test dotenv first to load environment variables
    dotenv.config();
    console.log(' dotenv loaded successfully');

    // Test MCP SDK
    const server = new Server({
      name: "test-server",
      version: "1.0.0"
    }, {
      capabilities: {
        resources: {},
        tools: {}
      }
    });
    console.log(' MCP SDK initialized successfully');

    // Test Playwright
    console.log('\n Testing browser automation...');
    const browser = await chromium.launch();
    await browser.close();
    console.log(' Playwright working correctly');

    // Test Octokit
    console.log('\n Testing GitHub integration...');
    const octokit = new Octokit();
    const { status } = await octokit.rest.meta.root();
    console.log(` Octokit connected successfully (status: ${status})`);

    // Test Axios
    console.log('\n Testing HTTP client...');
    const response = await axios.get('https://api.github.com');
    console.log(` Axios working correctly (status: ${response.status})`);

    console.log('\n All dependencies verified successfully!');

  } catch (error) {
    console.error('\n Setup test failed:', error);
    process.exit(1);
  }
}

testSetup();
</file>

<file path="src/test-setup.ts">
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { chromium } from 'playwright';
import { Octokit } from '@octokit/rest';
import axios from 'axios';
import dotenv from 'dotenv';
async function testSetup() {
  try {
    console.log(' Starting dependency verification...\n');
    // Test dotenv first to load environment variables
    dotenv.config();
    console.log(' dotenv loaded successfully');
    // Test MCP SDK
    const server = new Server({
      name: "test-server",
      version: "1.0.0"
    }, {
      capabilities: {
        resources: {},
        tools: {}
      }
    });
    console.log(' MCP SDK initialized successfully');
    // Test Playwright
    console.log('\n Testing browser automation...');
    const browser = await chromium.launch();
    await browser.close();
    console.log(' Playwright working correctly');
    // Test Octokit
    console.log('\n Testing GitHub integration...');
    const octokit = new Octokit();
    const { status } = await octokit.rest.meta.root();
    console.log(` Octokit connected successfully (status: ${status})`);
    // Test Axios
    console.log('\n Testing HTTP client...');
    const response = await axios.get('https://api.github.com');
    console.log(` Axios working correctly (status: ${response.status})`);
    console.log('\n All dependencies verified successfully!');
  } catch (error) {
    console.error('\n Setup test failed:', error);
    process.exit(1);
  }
}
testSetup();
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    /* Visit https://aka.ms/tsconfig to read more about this file */

    /* Projects */
    // "incremental": true,                              /* Save .tsbuildinfo files to allow for incremental compilation of projects. */
    // "composite": true,                                /* Enable constraints that allow a TypeScript project to be used with project references. */
    // "tsBuildInfoFile": "./.tsbuildinfo",              /* Specify the path to .tsbuildinfo incremental compilation file. */
    // "disableSourceOfProjectReferenceRedirect": true,  /* Disable preferring source files instead of declaration files when referencing composite projects. */
    // "disableSolutionSearching": true,                 /* Opt a project out of multi-project reference checking when editing. */
    // "disableReferencedProjectLoad": true,             /* Reduce the number of projects loaded automatically by TypeScript. */

    /* Language and Environment */
    "target": "es2016",                                  /* Set the JavaScript language version for emitted JavaScript and include compatible library declarations. */
    // "lib": [],                                        /* Specify a set of bundled library declaration files that describe the target runtime environment. */
    // "jsx": "preserve",                                /* Specify what JSX code is generated. */
    // "experimentalDecorators": true,                   /* Enable experimental support for legacy experimental decorators. */
    // "emitDecoratorMetadata": true,                    /* Emit design-type metadata for decorated declarations in source files. */
    // "jsxFactory": "",                                 /* Specify the JSX factory function used when targeting React JSX emit, e.g. 'React.createElement' or 'h'. */
    // "jsxFragmentFactory": "",                         /* Specify the JSX Fragment reference used for fragments when targeting React JSX emit e.g. 'React.Fragment' or 'Fragment'. */
    // "jsxImportSource": "",                            /* Specify module specifier used to import the JSX factory functions when using 'jsx: react-jsx*'. */
    // "reactNamespace": "",                             /* Specify the object invoked for 'createElement'. This only applies when targeting 'react' JSX emit. */
    // "noLib": true,                                    /* Disable including any library files, including the default lib.d.ts. */
    // "useDefineForClassFields": true,                  /* Emit ECMAScript-standard-compliant class fields. */
    // "moduleDetection": "auto",                        /* Control what method is used to detect module-format JS files. */

    /* Modules */
    "module": "commonjs",                                /* Specify what module code is generated. */
    // "rootDir": "./",                                  /* Specify the root folder within your source files. */
    // "moduleResolution": "node10",                     /* Specify how TypeScript looks up a file from a given module specifier. */
    // "baseUrl": "./",                                  /* Specify the base directory to resolve non-relative module names. */
    // "paths": {},                                      /* Specify a set of entries that re-map imports to additional lookup locations. */
    // "rootDirs": [],                                   /* Allow multiple folders to be treated as one when resolving modules. */
    // "typeRoots": [],                                  /* Specify multiple folders that act like './node_modules/@types'. */
    // "types": [],                                      /* Specify type package names to be included without being referenced in a source file. */
    // "allowUmdGlobalAccess": true,                     /* Allow accessing UMD globals from modules. */
    // "moduleSuffixes": [],                             /* List of file name suffixes to search when resolving a module. */
    // "allowImportingTsExtensions": true,               /* Allow imports to include TypeScript file extensions. Requires '--moduleResolution bundler' and either '--noEmit' or '--emitDeclarationOnly' to be set. */
    // "resolvePackageJsonExports": true,                /* Use the package.json 'exports' field when resolving package imports. */
    // "resolvePackageJsonImports": true,                /* Use the package.json 'imports' field when resolving imports. */
    // "customConditions": [],                           /* Conditions to set in addition to the resolver-specific defaults when resolving imports. */
    // "resolveJsonModule": true,                        /* Enable importing .json files. */
    // "allowArbitraryExtensions": true,                 /* Enable importing files with any extension, provided a declaration file is present. */
    // "noResolve": true,                                /* Disallow 'import's, 'require's or '<reference>'s from expanding the number of files TypeScript should add to a project. */

    /* JavaScript Support */
    // "allowJs": true,                                  /* Allow JavaScript files to be a part of your program. Use the 'checkJS' option to get errors from these files. */
    // "checkJs": true,                                  /* Enable error reporting in type-checked JavaScript files. */
    // "maxNodeModuleJsDepth": 1,                        /* Specify the maximum folder depth used for checking JavaScript files from 'node_modules'. Only applicable with 'allowJs'. */

    /* Emit */
    // "declaration": true,                              /* Generate .d.ts files from TypeScript and JavaScript files in your project. */
    // "declarationMap": true,                           /* Create sourcemaps for d.ts files. */
    // "emitDeclarationOnly": true,                      /* Only output d.ts files and not JavaScript files. */
    // "sourceMap": true,                                /* Create source map files for emitted JavaScript files. */
    // "inlineSourceMap": true,                          /* Include sourcemap files inside the emitted JavaScript. */
    // "outFile": "./",                                  /* Specify a file that bundles all outputs into one JavaScript file. If 'declaration' is true, also designates a file that bundles all .d.ts output. */
    // "outDir": "./",                                   /* Specify an output folder for all emitted files. */
    // "removeComments": true,                           /* Disable emitting comments. */
    // "noEmit": true,                                   /* Disable emitting files from a compilation. */
    // "importHelpers": true,                            /* Allow importing helper functions from tslib once per project, instead of including them per-file. */
    // "importsNotUsedAsValues": "remove",               /* Specify emit/checking behavior for imports that are only used for types. */
    // "downlevelIteration": true,                       /* Emit more compliant, but verbose and less performant JavaScript for iteration. */
    // "sourceRoot": "",                                 /* Specify the root path for debuggers to find the reference source code. */
    // "mapRoot": "",                                    /* Specify the location where debugger should locate map files instead of generated locations. */
    // "inlineSources": true,                            /* Include source code in the sourcemaps inside the emitted JavaScript. */
    // "emitBOM": true,                                  /* Emit a UTF-8 Byte Order Mark (BOM) in the beginning of output files. */
    // "newLine": "crlf",                                /* Set the newline character for emitting files. */
    // "stripInternal": true,                            /* Disable emitting declarations that have '@internal' in their JSDoc comments. */
    // "noEmitHelpers": true,                            /* Disable generating custom helper functions like '__extends' in compiled output. */
    // "noEmitOnError": true,                            /* Disable emitting files if any type checking errors are reported. */
    // "preserveConstEnums": true,                       /* Disable erasing 'const enum' declarations in generated code. */
    // "declarationDir": "./",                           /* Specify the output directory for generated declaration files. */
    // "preserveValueImports": true,                     /* Preserve unused imported values in the JavaScript output that would otherwise be removed. */

    /* Interop Constraints */
    // "isolatedModules": true,                          /* Ensure that each file can be safely transpiled without relying on other imports. */
    // "verbatimModuleSyntax": true,                     /* Do not transform or elide any imports or exports not marked as type-only, ensuring they are written in the output file's format based on the 'module' setting. */
    // "allowSyntheticDefaultImports": true,             /* Allow 'import x from y' when a module doesn't have a default export. */
    "esModuleInterop": true,                             /* Emit additional JavaScript to ease support for importing CommonJS modules. This enables 'allowSyntheticDefaultImports' for type compatibility. */
    // "preserveSymlinks": true,                         /* Disable resolving symlinks to their realpath. This correlates to the same flag in node. */
    "forceConsistentCasingInFileNames": true,            /* Ensure that casing is correct in imports. */

    /* Type Checking */
    "strict": true,                                      /* Enable all strict type-checking options. */
    // "noImplicitAny": true,                            /* Enable error reporting for expressions and declarations with an implied 'any' type. */
    // "strictNullChecks": true,                         /* When type checking, take into account 'null' and 'undefined'. */
    // "strictFunctionTypes": true,                      /* When assigning functions, check to ensure parameters and the return values are subtype-compatible. */
    // "strictBindCallApply": true,                      /* Check that the arguments for 'bind', 'call', and 'apply' methods match the original function. */
    // "strictPropertyInitialization": true,             /* Check for class properties that are declared but not set in the constructor. */
    // "noImplicitThis": true,                           /* Enable error reporting when 'this' is given the type 'any'. */
    // "useUnknownInCatchVariables": true,               /* Default catch clause variables as 'unknown' instead of 'any'. */
    // "alwaysStrict": true,                             /* Ensure 'use strict' is always emitted. */
    // "noUnusedLocals": true,                           /* Enable error reporting when local variables aren't read. */
    // "noUnusedParameters": true,                       /* Raise an error when a function parameter isn't read. */
    // "exactOptionalPropertyTypes": true,               /* Interpret optional property types as written, rather than adding 'undefined'. */
    // "noImplicitReturns": true,                        /* Enable error reporting for codepaths that do not explicitly return in a function. */
    // "noFallthroughCasesInSwitch": true,               /* Enable error reporting for fallthrough cases in switch statements. */
    // "noUncheckedIndexedAccess": true,                 /* Add 'undefined' to a type when accessed using an index. */
    // "noImplicitOverride": true,                       /* Ensure overriding members in derived classes are marked with an override modifier. */
    // "noPropertyAccessFromIndexSignature": true,       /* Enforces using indexed accessors for keys declared using an indexed type. */
    // "allowUnusedLabels": true,                        /* Disable error reporting for unused labels. */
    // "allowUnreachableCode": true,                     /* Disable error reporting for unreachable code. */

    /* Completeness */
    // "skipDefaultLibCheck": true,                      /* Skip type checking .d.ts files that are included with TypeScript. */
    "skipLibCheck": true                                 /* Skip type checking all .d.ts files. */
  }
}
</file>

</files>
</file>

<file path="mcp-server/jest.config.js">
/** @type {import('jest').Config} */
export default {
  preset: 'ts-jest/presets/default-esm',
  testEnvironment: 'node',
  extensionsToTreatAsEsm: ['.ts'],
  moduleNameMapper: {
    '^@/(.*)$': '<rootDir>/src/$1',
    '^(\\.{1,2}/.*)\\.js$': '$1',
  },
  transform: {
    '^.+\\.tsx?$': [
      'ts-jest',
      {
        useESM: true,
        tsconfig: 'tsconfig.json',
      },
    ],
  },
  setupFiles: ['dotenv/config'],
  testMatch: ['**/__tests__/**/*.test.ts'],
  coverageDirectory: 'coverage',
  collectCoverageFrom: ['src/**/*.{ts,tsx}', '!src/**/*.d.ts'],
  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json', 'node'],
};
</file>

<file path="mcp-server/local-research/implementation-plan.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Based on the research document and best practices, here's a detailed step-by-step implementation plan for the MCP server:

## MCP Server Implementation Plan

This plan outlines the steps to implement an MCP server, focusing on best practices for transport layers, security measures, caching, rate limiting, testing, error handling, logging, and scalability, as researched in `local-research/mcp-implementation-research.md`.

**Phase 1: Project Setup and Core Structure**

1.  **Initialize Project**:
    *   Ensure Node.js and npm (or yarn/pnpm) are installed.
    *   Initialize a new npm project: `npm init -y`
    *   Initialize a TypeScript project: `tsc --init --rootDir src --outDir dist --module commonjs --esModuleInterop --strict --skipLibCheck` (Adjust `module` if ESM is preferred, and update `package.json` accordingly, as currently configured).
    *   Install core dependencies: `@modelcontextprotocol/sdk`, `dotenv`, `axios`, `zod`, `ts-node`, `typescript`.
        ```bash
        npm install @modelcontextprotocol/sdk dotenv axios zod ts-node typescript
        ```

2.  **Directory Structure Setup**:
    *   Create the following directory structure (as already present in the provided files, reinforcing good organization):
        ```
        mcp-server/
         src/
            capabilities/
               resources/
               tools/
            config/
            utils/
         local-research/
         dist/         (Output directory for compiled JavaScript)
         package.json
         tsconfig.json
        ```

3.  **Configuration Management**:
    *   Install `dotenv`: `npm install dotenv`
    *   Create a `.env` file in the root directory to store environment variables (e.g., `PERPLEXITY_API_KEY`).
    *   Configure `dotenv` to load environment variables in server and tool files (already implemented in `web-search.ts`).

4.  **Basic Server Structure**:
    *   Create `src/server.ts` (or `src/server.js` for JavaScript) as the main server entry point.
    *   Implement the basic server setup using `@modelcontextprotocol/sdk/server` (as in `src/server.ts`):
        ```typescript
        import { Server } from "@modelcontextprotocol/sdk/server/index.js";
        import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

        async function main() {
            try {
                console.log("Starting MCP server...");
                const server = new Server({
                    name: "your-mcp-server-name",
                    version: "0.1.0",
                    description: "Description of your MCP server."
                }, {
                    capabilities: {
                        resources: {},
                        tools: {}
                    }
                });
                const transport = new StdioServerTransport();
                await server.connect(transport);
                console.log(" MCP Server started using stdio transport.");
            } catch (error) {
                console.error(" Server failed to start:", error);
                process.exit(1);
            }
        }

        main().catch(console.error);
        ```

**Phase 2: Transport Layer Implementation (STDIO)**

1.  **STDIO Transport**:
    *   Utilize `StdioServerTransport` from `@modelcontextprotocol/sdk/server/stdio.js` for initial transport layer implementation. This is suitable for local development and simplifies initial setup as it uses standard input/output streams (as already implemented in `src/server.ts`).
    *   Ensure the server connects to the transport using `server.connect(transport)`.
    *   Verify basic communication by sending a simple request from a client (see Phase 5 for testing).

2.  **Future Transport Considerations (Research Point 1)**:
    *   **Layered Architecture**: Keep in mind the layered architecture principle for future transport implementations (client/server, session, transport layers).  The MCP SDK inherently supports this separation.
    *   **Alternative Transports**: For future enhancements, consider:
        *   **SSE (Server-Sent Events)** for HTTP-based communication if web-based clients are needed.
        *   **WebSockets** for persistent bidirectional communication if more interactive features are required.
        *   **TCP Sockets** for potentially higher performance in specific network environments if needed later.

**Phase 3: Capability Implementation - `web-search` Tool**

1.  **Implement `web-search` Tool (Research Point 4)**:
    *   Create `src/capabilities/tools/web-search.ts` (or `.js`).
    *   Implement the `webSearchTool` as defined in `src/capabilities/tools/web-search.ts`, leveraging the Perplexity AI API.
    *   **API Key Handling**: Ensure secure handling of `PERPLEXITY_API_KEY` using environment variables (as implemented).
    *   **Request and Response Schemas**: Utilize `requestSchema` and `responseSchema` to define and validate inputs and outputs using Zod (as implemented). This is crucial for input validation (Security Point 2.1).

2.  **Integrate Tool with Server**:
    *   Register the `webSearchTool` in the `tools` capability section of the `Server` constructor in `src/server.ts` (as implemented):
        ```typescript
        tools: {
            'web-search': webSearchTool
        }
        ```

**Phase 4: Security Measures Implementation (Research Point 2)**

1.  **Input Validation and Sanitization (Research Point 2.1)**:
    *   **Schema Validation**: Enforce input validation using the `requestSchema` defined for each tool. The MCP SDK handles schema validation automatically.
    *   **Data Sanitization**: If necessary for specific tool logic (though less critical for web search output), sanitize inputs to prevent injection attacks. For now, focus on robust schema validation.

2.  **API Key Security (Research Point 2.6)**:
    *   **Environment Variables**: Store `PERPLEXITY_API_KEY` and other sensitive credentials in environment variables, not directly in the code (as implemented).
    *   **`.gitignore`**: Ensure `.env` is added to `.gitignore` to prevent accidental commits of API keys to version control.

3.  **Rate Limiting (Research Point 3)**:
    *   **Basic Rate Limiting for Perplexity API**: Implement a basic rate limiting mechanism to avoid exceeding Perplexity AI API limits. A simple token bucket approach can be initially used within the `web-search` tool execution:
        ```typescript
        // Example (simplified token bucket - needs proper state management in a real scenario)
        let tokens = 100; // Initial tokens
        const replenishRate = 700/3600; // Tokens per second (700 per hour)

        async execute: async (request: WebSearchRequest): Promise<WebSearchResponse> => {
            // ... API key check ...
            if (tokens < 1) {
                throw new Error("Rate limit exceeded. Please try again later."); // Or implement queuing/delay
            }
            tokens -= 1;
            setTimeout(() => { tokens = Math.min(100, tokens + replenishRate * 1); }, 1000); // Replenish tokens
            // ... Perplexity API call ...
        }
        ```
        *   **More Advanced Rate Limiting**: For production, consider using a more robust rate limiting library or middleware, especially if you expose APIs to multiple users or services. Explore options like token bucket or sliding window algorithms with libraries that handle concurrency and storage.

4.  **Command Whitelisting and Flag Validation (Research Point 2.2) (Less relevant for this server but good to note for future CLI tools)**:
    *   If implementing tools that execute system commands in the future, use command whitelisting and flag validation to prevent command injection vulnerabilities. This is less applicable for the `web-search` tool but important for general security.

5.  **TLS Encryption and Access Controls (Research Point 2.5 & 2.7)**:
    *   **TLS**: If exposing the MCP server over a network (e.g., using HTTP transport), enforce TLS (HTTPS) for all API endpoints, especially for management interfaces. This is less relevant for stdio but critical for network deployments.
    *   **Access Controls**: Implement proper authentication and authorization mechanisms if the server needs to be accessed by authenticated users or services in the future.

**Phase 5: Testing (Research Point 4)**

1.  **Unit Tests**:
    *   Write unit tests for individual tools and utility functions to ensure they function correctly in isolation. Use a testing framework like Jest or Mocha if needed for more complex testing scenarios later. For now, basic testing through `test-client` is sufficient to start.

2.  **Integration Tests**:
    *   Create integration tests to verify the interaction between the MCP server and client. `src/test-client.ts` (and `.js`) serves as a basic integration test client.
    *   **Test `web-search` Tool**: The existing `src/test-client.ts` effectively tests the `web-search` tool by sending a request and validating the response against `WebSearchResponseSchema`. Expand this test client to cover more scenarios (e.g., error cases, different queries).
    *   **MCP Inspector (Research Point 4.1 & 4.4)**: Explore the MCP Inspector tool (if available and applicable to your SDK version) for more systematic testing of MCP capabilities and protocol compliance.

3.  **Testing Approaches (Research Point 4.3 & 4.4)**:
    *   **Core Features First**: Focus testing on core functionalities like tool execution and basic communication.
    *   **Edge Cases**: Gradually add tests for edge cases, error conditions, and boundary values for tool parameters.
    *   **Error Handling**: Specifically test error handling paths to ensure the server and tools gracefully handle errors and provide informative messages.
    *   **Performance Testing (Future)**: Consider basic performance testing later if performance becomes a concern, especially for API-intensive tools.

**Phase 6: Error Handling and Logging (Research Point 5)**

1.  **Structured Logging (Research Point 5.1)**:
    *   Implement structured logging using `console.log` for now, but plan to transition to a more robust logging library (like `winston` or `pino`) for production.
    *   Log in a consistent JSON format for easier parsing and analysis in the future if needed. Include context, timestamps, and log levels (info, warning, error).

2.  **Log Relevant Events (Research Point 5.5)**:
    *   Log server startup and shutdown events.
    *   Log tool execution requests, including tool name and parameters.
    *   Log errors and exceptions, including stack traces where appropriate (as done in `web-search.ts`).
    *   Log important resource access events if you add resource capabilities later.
    *   Consider logging performance metrics in the future if needed.

3.  **Server-Side Logging to `stderr` (Research Point 5.3)**:
    *   For stdio transport, logging errors and server-side events to `stderr` is a good practice for local transports. `console.error` naturally directs output to `stderr`.

4.  **Client Log Messages (Research Point 5.4) (Consider for future transports)**:
    *   For transports beyond stdio (like SSE or WebSockets), consider implementing the ability for the server to send log messages back to the client through MCP protocol mechanisms if client-side logging is desired. For stdio, client can observe server logs directly.

**Phase 7: Scalability Considerations (Research Point 6)**

1.  **Asynchronous Operations (Research Point 6.1)**:
    *   Utilize asynchronous operations (`async/await`) throughout the server and tool implementations to handle concurrent requests efficiently (already implemented in `web-search.ts` and server setup).

2.  **Connection Management (Research Point 6.2)**:
    *   The `@modelcontextprotocol/sdk` handles connection management for you in terms of MCP protocol. Ensure proper resource cleanup in your tool implementations if they manage external resources, though less critical for the current `web-search` tool.

3.  **Scalability Patterns (Research Point 6.6) (Future Considerations)**:
    *   **Load Balancing**: If you anticipate high request loads in the future and move beyond stdio transport, consider load balancing strategies to distribute requests across multiple server instances.
    *   **Horizontal Scaling**: Plan for horizontal scaling by designing the server to be stateless so you can easily add more server instances behind a load balancer as demand grows.
    *   **Resource Management and Monitoring (Research Point 6.3 & 6.5)**:  As you add more capabilities and complexity, monitor resource usage (CPU, memory, network) and implement efficient resource management practices in your tools and server.

**Phase 8: Documentation and Refinement**

1.  **Code Documentation**:
    *   Add comments to your code to explain the purpose of functions, classes, and complex logic.
    *   Generate API documentation using tools like TypeDoc if you intend to expose APIs beyond the MCP protocol itself.

2.  **README.md**:
    *   Create a `README.md` file in the project root to document:
        *   Project description and purpose.
        *   Setup instructions (environment variables, dependencies).
        *   How to run the server and test client.
        *   Available tools and their usage.
        *   Scalability and security considerations.

3.  **Continuous Refinement**:
    *   Continuously review and refine the implementation based on testing, feedback, and evolving requirements.
    *   Stay updated with best practices in MCP server development and security.

This detailed plan provides a roadmap for implementing your MCP server, incorporating research-backed best practices and focusing on security and scalability from the outset. Start with Phase 1 and progressively implement each phase, testing and refining as you go.
</file>

<file path="mcp-server/local-research/mcp-implementation-research.md">
Querying Perplexity AI using sonar-pro for: 1. What are the best practices for implementing transport layers in MCP servers? 2. What are the recommended security measures for MCP server implementations? 3. What are the optimal caching and rate limiting strategies for external API calls in MCP servers? 4. What are the recommended testing approaches for MCP server capabilities? 5. What are the best practices for error handling and logging in MCP servers? 6. What are the recommended scalability patterns for MCP server implementations?
1. Best practices for implementing transport layers in MCP servers:
- Use layered architecture with clear separation between client/server, session, and transport layers[1].
- Implement different transports for various use cases: STDIO for in-process communication, SSE for HTTP-based communication[1].
- Handle JSON-RPC message serialization/deserialization in the transport layer[1].
- Ensure proper connection establishment, protocol compatibility checks, and capability negotiation[1].

2. Recommended security measures for MCP server implementations:
- Implement strict input validation and sanitization[4].
- Use command whitelisting and flag validation for CLI-based servers[2].
- Prevent path traversal and shell injection attacks[2].
- Implement execution timeouts and command length limits[2].
- Use TLS encryption for API endpoints, especially in management networks[7].
- Employ access controls and proper authentication mechanisms[7].
- Use IDS/IPS for admin networks to detect anomalies[7].

3. Optimal caching and rate limiting strategies for external API calls:
- Implement token bucket algorithm for rate limiting[3]:
```csharp
builder.Services.AddRateLimiter(rateLimiterOptions => {
  options.TokenLimit = 1000;
  options.ReplenishmentPeriod = TimeSpan.FromHours(1);
  options.TokensPerPeriod = 700;
  options.AutoReplenishment = true;
});
```
- Use sliding window rate limiting for more precise control[9].
- Implement IP-based rate limiting to prevent abuse[9].
- Use distributed caching for scalability.

4. Recommended testing approaches for MCP server capabilities:
- Use the MCP Inspector tool for systematic testing[4].
- Test core features first, then add edge cases[4].
- Verify error handling and check performance[4].
- Implement a systematic approach: test core features, add edge cases, verify error handling, check performance[4].
- Use the Inspector during development for quick iteration[5].

5. Best practices for error handling and logging in MCP servers:
- Implement structured logging with consistent formats, context, and timestamps[5].
- Log stack traces, error context, and track error patterns[5].
- Use server-side logging to stderr for local transports[5].
- Send log message notifications to clients:
```python
server.request_context.session.send_log_message(
  level="info",
  data="Server started successfully"
)
```
- Log important events: initialization, resource access, tool execution, errors, performance metrics[5].

6. Recommended scalability patterns for MCP server implementations:
- Use asynchronous operations for improved concurrency[1].
- Implement proper connection management and cleanup[4].
- Use load balancing for distributing requests[7].
- Employ horizontal scaling by adding more server instances.
- Implement efficient resource management and monitoring[4].
</file>

<file path="mcp-server/local-research/typescript-esm-research.md">
Querying Perplexity AI using sonar-pro for: TypeScript ES modules configuration best practices with Node.js, focusing on moduleResolution, file extensions, and package.json settings
To configure TypeScript ES modules with Node.js, follow these best practices:

1. Set `"type": "module"` in package.json to treat .js files as ES modules[1][6].

2. Use `.mts` extension for TypeScript ES module files and `.cts` for CommonJS files[3][8].

3. Configure tsconfig.json:

```json
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ES2020",
    "moduleResolution": "node16",
    "outDir": "dist",
    "esModuleInterop": true
  }
}
```

4. Set `moduleResolution` to "node16" or "nodenext" for modern Node.js versions[2][7].

5. Use `--experimental-modules` flag when running Node.js[1].

6. For package exports, use the "exports" field in package.json:

```json
{
  "exports": {
    ".": {
      "import": "./dist/index.js",
      "require": "./dist/index.cjs"
    }
  }
}
```

7. Compile TypeScript files using:

```
tsc -p tsconfig.json
```

8. Run the compiled JS files with:

```
node --experimental-modules dist/index.js
```

These practices ensure proper ES module support in TypeScript projects with Node.js[1][2][3][6][7][8].
</file>

<file path="mcp-server/package.json">
{
  "name": "mcp-server",
  "version": "1.0.0",
  "description": "A beginner-friendly MCP server implementation",
  "type": "module",
  "main": "dist/server.js",
  "scripts": {
    "clean": "rimraf dist",
    "build": "npm run clean && tsc",
    "start": "node dist/server.js",
    "dev": "ts-node --esm src/server.ts",
    "test": "cross-env DOTENV_CONFIG_PATH=.env.test NODE_OPTIONS=--experimental-vm-modules jest --no-cache",
    "lint": "eslint . --ext .ts",
    "lint:fix": "eslint . --ext .ts --fix",
    "prepare": "husky install"
  },
  "keywords": [
    "mcp",
    "server",
    "model-context-protocol"
  ],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "@google/generative-ai": "^0.22.0",
    "@modelcontextprotocol/sdk": "1.2.0",
    "@octokit/rest": "19.0.13",
    "axios": "1.6.5",
    "dotenv": "16.3.1",
    "playwright": "1.41.2",
    "zod": "^3.24.2"
  },
  "devDependencies": {
    "@types/jest": "^29.5.11",
    "@types/node": "20.11.5",
    "@typescript-eslint/eslint-plugin": "^6.19.1",
    "@typescript-eslint/parser": "^6.19.1",
    "cross-env": "^7.0.3",
    "eslint": "^8.56.0",
    "eslint-config-prettier": "^9.1.0",
    "eslint-plugin-prettier": "^5.1.3",
    "husky": "^8.0.3",
    "jest": "^29.7.0",
    "prettier": "^3.2.4",
    "rimraf": "^5.0.5",
    "ts-jest": "^29.1.2",
    "ts-node": "10.9.2",
    "typescript": "5.3.3"
  }
}
</file>

<file path="mcp-server/src/capabilities/tools/__tests__/web-search.test.ts">
import { jest } from "@jest/globals"; import { webSearchTool } from "../web-search.js"; import { config } from "../../../config/index.js"; import axios from "axios"; import { z } from "zod"; jest.mock("axios"); const mockedAxios = jest.mocked(axios); jest.mock("../../../config/index.js", () => ({ config: { env: "test", perplexityApiKey: undefined, logLevel: "info" } })); jest.mock("../../../utils/logger.js", () => ({ logger: { info: jest.fn(), warn: jest.fn(), error: jest.fn(), debug: jest.fn() } })); describe("Web Search Tool", () => { beforeEach(() => { jest.clearAllMocks(); }); describe("when PERPLEXITY_API_KEY is not provided", () => { it("should return mock results in test environment", async () => { const request = { query: "test query" }; const result = await webSearchTool.execute(request); expect(result).toEqual({ searchResults: "Mock search results for testing" }); expect(mockedAxios.post).not.toHaveBeenCalled(); }); }); describe("when PERPLEXITY_API_KEY is provided", () => { beforeEach(() => { (config as any).perplexityApiKey = "test-api-key"; }); it("should make API call and return results", async () => { const mockResponse = { data: { choices: [{ message: { content: "API search results" } }] } }; mockedAxios.post.mockResolvedValueOnce(mockResponse); const request = { query: "test query" }; const result = await webSearchTool.execute(request); expect(result).toEqual({ searchResults: "API search results" }); expect(mockedAxios.post).toHaveBeenCalledWith(expect.any(String), expect.objectContaining({ messages: [{ role: "user", content: "test query" }] }), expect.objectContaining({ headers: { "Authorization": "Bearer test-api-key" } })); }); it("should handle API errors gracefully", async () => { const mockError = { response: { data: { error: "API Error" } } }; mockedAxios.post.mockRejectedValueOnce(mockError); const request = { query: "test query" }; await expect(webSearchTool.execute(request)).rejects.toThrow("Web search failed: API Error"); }); it("should validate request schema", async () => { const invalidRequest = { query: "" }; await expect(webSearchTool.execute(invalidRequest)).rejects.toThrow("Search query is required"); }); it("should handle saving results to file when requested", async () => { const mockResponse = { data: { choices: [{ message: { content: "API search results" } }] } }; mockedAxios.post.mockResolvedValueOnce(mockResponse); const request = { query: "test query", saveToFile: true }; const result = await webSearchTool.execute(request); expect(result).toMatchObject({ searchResults: "API search results", savedToFile: expect.stringContaining("web-search-") }); }); }); });
</file>

<file path="mcp-server/src/capabilities/tools/web-search.js">
"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.webSearchTool = void 0;
const axios_1 = __importDefault(require("axios"));
const dotenv_1 = __importDefault(require("dotenv"));
// Load environment variables
dotenv_1.default.config();
const PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions";
const PERPLEXITY_API_KEY = process.env.PERPLEXITY_API_KEY;
exports.webSearchTool = {
    name: 'web-search',
    version: '0.1.0',
    description: 'Performs a web search using Perplexity AI.',
    execute: (request) => __awaiter(void 0, void 0, void 0, function* () {
        var _a, _b, _c, _d;
        if (!PERPLEXITY_API_KEY) {
            throw new Error("Perplexity API key is not set in environment variables (PERPLEXITY_API_KEY)");
        }
        const { query, saveTo } = request;
        if (!query) {
            throw new Error("Search query is required.");
        }
        try {
            console.log(` Performing web search: "${query}"`);
            const response = yield axios_1.default.post(PERPLEXITY_API_URL, {
                model: "pplx-7b-online",
                messages: [{ role: "user", content: query }]
            }, {
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${PERPLEXITY_API_KEY}`
                }
            });
            const searchResults = ((_b = (_a = response.data.choices[0]) === null || _a === void 0 ? void 0 : _a.message) === null || _b === void 0 ? void 0 : _b.content) || "No results found.";
            // If saveTo is specified, save results to file
            if (saveTo) {
                const fs = yield Promise.resolve().then(() => __importStar(require('fs/promises')));
                yield fs.writeFile(saveTo, searchResults, 'utf-8');
                console.log(` Results saved to: ${saveTo}`);
                return { searchResults, savedToFile: saveTo };
            }
            return { searchResults };
        }
        catch (error) {
            console.error(" Error during web search:", error);
            if (axios_1.default.isAxiosError(error)) {
                throw new Error(`Web search failed: ${((_d = (_c = error.response) === null || _c === void 0 ? void 0 : _c.data) === null || _d === void 0 ? void 0 : _d.error) || error.message}`);
            }
            throw new Error(`Web search failed: ${error}`);
        }
    }),
    requestSchema: {
        type: 'object',
        properties: {
            query: {
                type: 'string',
                description: 'The search query.'
            },
            saveTo: {
                type: 'string',
                description: 'Optional file path to save the search results.'
            }
        },
        required: ['query']
    },
    responseSchema: {
        type: 'object',
        properties: {
            searchResults: {
                type: 'string',
                description: 'Web search results.'
            },
            savedToFile: {
                type: 'string',
                description: 'Path to the file where results were saved, if applicable.'
            }
        },
        required: ['searchResults']
    }
};
</file>

<file path="mcp-server/src/capabilities/tools/web-search.ts">
import axios from 'axios';
import { z } from 'zod';
import { config } from '../../config/index.js';
import { logger } from '../../utils/logger.js';
import dotenv from 'dotenv';
// Load environment variables
dotenv.config();
const PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions";
const PERPLEXITY_API_KEY = process.env.PERPLEXITY_API_KEY;
interface WebSearchRequest {
    query: string;
    saveTo?: string;
}
interface WebSearchResponse {
    searchResults: string;
    savedToFile?: string;
}
export const webSearchTool = {
    name: 'web-search',
    version: '0.1.0',
    description: 'Performs a web search using Perplexity AI.',
    execute: async (request: WebSearchRequest): Promise<WebSearchResponse> => {
        if (!PERPLEXITY_API_KEY) {
            throw new Error("Perplexity API key is not set in environment variables (PERPLEXITY_API_KEY)");
        }
        const { query, saveTo } = request;
        if (!query) {
            throw new Error("Search query is required.");
        }
        try {
            console.log(` Performing web search: "${query}"`);
            const response = await axios.post(PERPLEXITY_API_URL, {
                model: "pplx-7b-online",
                messages: [{ role: "user", content: query }]
            }, {
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${PERPLEXITY_API_KEY}`
                }
            });
            const searchResults = response.data.choices[0]?.message?.content || "No results found.";
            // If saveTo is specified, save results to file
            if (saveTo) {
                const fs = await import('fs/promises');
                await fs.writeFile(saveTo, searchResults, 'utf-8');
                console.log(` Results saved to: ${saveTo}`);
                return { searchResults, savedToFile: saveTo };
            }
            return { searchResults };
        } catch (error) {
            console.error(" Error during web search:", error);
            if (axios.isAxiosError(error)) {
                throw new Error(`Web search failed: ${error.response?.data?.error || error.message}`);
            }
            throw new Error(`Web search failed: ${error}`);
        }
    },
    requestSchema: {
        type: 'object',
        properties: {
            query: { 
                type: 'string', 
                description: 'The search query.' 
            },
            saveTo: { 
                type: 'string', 
                description: 'Optional file path to save the search results.' 
            }
        },
        required: ['query']
    },
    responseSchema: {
        type: 'object',
        properties: {
            searchResults: { 
                type: 'string', 
                description: 'Web search results.' 
            },
            savedToFile: { 
                type: 'string', 
                description: 'Path to the file where results were saved, if applicable.' 
            }
        },
        required: ['searchResults']
    }
};
</file>

<file path="mcp-server/src/config/index.js">
"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.environment = exports.config = exports.ServerConfigSchema = void 0;
const zod_1 = require("zod");
const dotenv_1 = __importDefault(require("dotenv"));
// Load environment variables
dotenv_1.default.config();
// Define environment variable schema
const EnvSchema = zod_1.z.object({
    NODE_ENV: zod_1.z.enum(['development', 'production', 'test']).default('development'),
    LOG_LEVEL: zod_1.z.enum(['debug', 'info', 'warn', 'error']).default('info'),
    PERPLEXITY_API_KEY: zod_1.z.string(),
    PORT: zod_1.z.string().optional(),
    HOST: zod_1.z.string().optional()
});
// Define server configuration schema
exports.ServerConfigSchema = zod_1.z.object({
    name: zod_1.z.string(),
    version: zod_1.z.string(),
    description: zod_1.z.string(),
    logLevel: zod_1.z.enum(['debug', 'info', 'warn', 'error']).default('info'),
    env: zod_1.z.enum(['development', 'production', 'test']).default('development'),
    port: zod_1.z.number().optional(),
    host: zod_1.z.string().optional()
});
// Parse and validate environment variables
const env = EnvSchema.parse(process.env);
// Export validated configuration
exports.config = {
    name: "cursor-tools-mcp-server",
    version: "0.1.0",
    description: "MCP server mimicking cursor-tools functionalities.",
    logLevel: env.LOG_LEVEL,
    env: env.NODE_ENV,
    port: env.PORT ? parseInt(env.PORT, 10) : undefined,
    host: env.HOST,
    perplexityApiKey: env.PERPLEXITY_API_KEY
};
// Export environment variables
exports.environment = env;
</file>

<file path="mcp-server/src/config/index.ts">
import { z } from 'zod';
import dotenv from 'dotenv';
// Load environment variables
dotenv.config();
// Define environment variable schema
const EnvSchema = z.object({
    NODE_ENV: z.enum(['development', 'production', 'test']).default('development'),
    LOG_LEVEL: z.enum(['debug', 'info', 'warn', 'error']).default('info'),
    PERPLEXITY_API_KEY: z.string().optional(),
    GEMINI_API_KEY: z.string(),
    PORT: z.string().optional(),
    HOST: z.string().optional()
});
// Define server configuration schema
export const ServerConfigSchema = z.object({
    name: z.string(),
    version: z.string(),
    description: z.string(),
    logLevel: z.enum(['debug', 'info', 'warn', 'error']).default('info'),
    env: z.enum(['development', 'production', 'test']).default('development'),
    port: z.number().optional(),
    host: z.string().optional()
});
// Parse and validate environment variables
const env = EnvSchema.parse(process.env);
// Export validated configuration
export const config = {
    name: "cursor-tools-mcp-server",
    version: "0.1.0",
    description: "MCP server mimicking cursor-tools functionalities.",
    logLevel: env.LOG_LEVEL,
    env: env.NODE_ENV,
    port: env.PORT ? parseInt(env.PORT, 10) : undefined,
    host: env.HOST,
    perplexityApiKey: env.PERPLEXITY_API_KEY,
    geminiApiKey: env.GEMINI_API_KEY
};
// Export environment variables
export const environment = env;
</file>

<file path="mcp-server/src/gemini/__tests__/service.test.ts">
import { jest } from '@jest/globals';
import { GeminiService, RepositoryAnalysisRequest } from '../service.js';
import { genAI, geminiConfig } from '../config.js';
import { logger } from '../../utils/logger.js';
// Mock the logger
jest.mock('../../utils/logger.js', () => ({
  logger: {
    error: jest.fn(),
    warn: jest.fn(),
    debug: jest.fn(),
  },
}));
// Create mock function
const mockGenerateContent = jest.fn();
// Mock the Gemini API
jest.mock('@google/generative-ai', () => ({
  GoogleGenerativeAI: jest.fn().mockImplementation(() => ({
    getGenerativeModel: jest.fn().mockReturnValue({
      generateContent: mockGenerateContent,
    }),
  })),
}));
jest.mock('../config.js', () => ({
  genAI: {
    getGenerativeModel: jest.fn().mockReturnValue({
      generateContent: mockGenerateContent,
    }),
  },
  geminiConfig: {
    model: 'gemini-pro',
    temperature: 0.7,
    topK: 40,
    topP: 0.95,
    maxOutputTokens: 2048,
  },
}));
describe('GeminiService', () => {
  let service: GeminiService;
  beforeEach(() => {
    jest.clearAllMocks();
    service = new GeminiService();
  });
  describe('analyzeRepository', () => {
    const mockRequest: RepositoryAnalysisRequest = {
      repoPath: '/test/repo',
      query: 'Analyze code quality',
    };
    it('should successfully analyze repository with all sections', async () => {
      const mockAnalysis = `
        Analysis:
        The repository has a good structure and follows best practices.
        Suggestions:
        1. Add more tests
        2. Improve documentation
        Issues:
        * Some code duplication found
        * Missing error handling in critical sections
      `;
      mockGenerateContent.mockImplementation(() =>
        Promise.resolve({
          response: {
            text: () => mockAnalysis,
          },
        })
      );
      const result = await service.analyzeRepository(mockRequest);
      expect(result.analysis).toBe(mockAnalysis);
      expect(result.suggestions).toEqual([
        'Add more tests',
        'Improve documentation',
      ]);
      expect(result.issues).toEqual([
        'Some code duplication found',
        'Missing error handling in critical sections',
      ]);
      expect(result.error).toBeUndefined();
      expect(mockGenerateContent).toHaveBeenCalledWith(expect.any(String));
    });
    it('should handle rate limiting and retry', async () => {
      const rateLimitError = new Error('RATE_LIMIT');
      const successResponse = {
        response: {
          text: () => 'Success after retry',
        },
      };
      mockGenerateContent
        .mockImplementationOnce(() => Promise.reject(rateLimitError))
        .mockImplementationOnce(() => Promise.resolve(successResponse));
      const result = await service.analyzeRepository(mockRequest);
      expect(result.analysis).toBe('Success after retry');
      expect(mockGenerateContent).toHaveBeenCalledTimes(2);
      expect(logger.warn).toHaveBeenCalledWith(
        expect.stringContaining('Attempt 1 failed'),
        expect.any(Object)
      );
    });
    it('should handle errors gracefully', async () => {
      const mockError = new Error('API error');
      mockGenerateContent.mockImplementation(() => Promise.reject(mockError));
      const result = await service.analyzeRepository(mockRequest);
      expect(result.analysis).toBe('');
      expect(result.error).toBe('API error');
      expect(result.suggestions).toBeUndefined();
      expect(logger.error).toHaveBeenCalledWith(
        'Error analyzing repository:',
        expect.objectContaining({
          error: mockError,
          request: mockRequest,
        })
      );
    });
    it('should handle malformed response gracefully', async () => {
      const malformedResponse = `
        Invalid format
        No clear sections
        Random text
      `;
      mockGenerateContent.mockImplementation(() =>
        Promise.resolve({
          response: {
            text: () => malformedResponse,
          },
        })
      );
      const result = await service.analyzeRepository(mockRequest);
      expect(result.analysis).toBe(malformedResponse);
      expect(result.suggestions).toEqual([]);
      expect(result.issues).toEqual([]);
    });
    it('should include context in analysis when provided', async () => {
      const requestWithContext: RepositoryAnalysisRequest = {
        ...mockRequest,
        context: 'TypeScript project with React',
      };
      mockGenerateContent.mockImplementation((prompt: any) => {
        expect(prompt).toContain('TypeScript project with React');
        return Promise.resolve({
          response: {
            text: () => 'Analysis with context',
          },
        });
      });
      await service.analyzeRepository(requestWithContext);
      expect(mockGenerateContent).toHaveBeenCalledWith(expect.any(String));
      const prompt = mockGenerateContent.mock.calls[0][0] as string;
      expect(prompt).toContain('Additional context: TypeScript project with React');
    });
    it('should respect rate limiting', async () => {
      jest.useFakeTimers();
      const requests = Array(5).fill(mockRequest);
      mockGenerateContent.mockImplementation(() =>
        Promise.resolve({
          response: {
            text: () => 'Test response',
          },
        })
      );
      // Start all requests concurrently
      const promises = requests.map(req => service.analyzeRepository(req));
      // Fast-forward time by 100ms after each request
      for (let i = 0; i < requests.length; i++) {
        jest.advanceTimersByTime(100);
        await Promise.resolve(); // Let the promises resolve
      }
      await Promise.all(promises);
      expect(mockGenerateContent).toHaveBeenCalledTimes(5);
      expect(logger.debug).toHaveBeenCalledWith(
        expect.stringContaining('Rate limit reached'),
        expect.any(Object)
      );
      jest.useRealTimers();
    });
  });
});
</file>

<file path="mcp-server/src/gemini/config.ts">
import { GoogleGenerativeAI } from '@google/generative-ai';
import dotenv from 'dotenv';
dotenv.config();
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
if (!GEMINI_API_KEY) {
  throw new Error('GEMINI_API_KEY environment variable is not set');
}
export const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
export const geminiConfig = {
  model: 'gemini-pro',
  temperature: 0.7,
  topK: 40,
  topP: 0.95,
  maxOutputTokens: 2048,
};
</file>

<file path="mcp-server/src/gemini/service.ts">
import { genAI, geminiConfig } from './config.js';
import { withRetry } from '../utils/retry.js';
import { logger } from '../utils/logger.js';
import { z } from 'zod';
export interface RepositoryAnalysisRequest {
  repoPath: string;
  query: string;
  context?: string;
}
export interface RepositoryAnalysisResponse {
  analysis: string;
  suggestions?: string[];
  issues?: string[];
  error?: string;
}
// Response schema for validation
const AnalysisResponseSchema = z.object({
  analysis: z.string(),
  suggestions: z.array(z.string()).optional(),
  issues: z.array(z.string()).optional(),
});
export class GeminiServiceError extends Error {
  constructor(message: string, public readonly cause?: Error) {
    super(message);
    this.name = 'GeminiServiceError';
  }
}
export class GeminiService {
  private model = genAI.getGenerativeModel(geminiConfig);
  private rateLimiter = {
    tokens: 10,
    maxTokens: 10,
    lastRefill: Date.now(),
    refillRate: 1000, // 1 token per second
  };
  private async acquireToken(): Promise<void> {
    const now = Date.now();
    const timePassed = now - this.rateLimiter.lastRefill;
    const tokensToAdd = Math.floor(timePassed / this.rateLimiter.refillRate);
    if (tokensToAdd > 0) {
      this.rateLimiter.tokens = Math.min(
        this.rateLimiter.maxTokens,
        this.rateLimiter.tokens + tokensToAdd
      );
      this.rateLimiter.lastRefill = now;
    }
    if (this.rateLimiter.tokens <= 0) {
      const waitTime = this.rateLimiter.refillRate;
      logger.debug(`Rate limit reached, waiting ${waitTime}ms`);
      await new Promise(resolve => setTimeout(resolve, waitTime));
      return this.acquireToken();
    }
    this.rateLimiter.tokens--;
  }
  async analyzeRepository(request: RepositoryAnalysisRequest): Promise<RepositoryAnalysisResponse> {
    try {
      await this.acquireToken();
      const operation = async () => {
        const prompt = this.buildAnalysisPrompt(request);
        const result = await this.model.generateContent(prompt);
        const response = await result.response;
        const text = response.text();
        return {
          analysis: text,
          ...this.parseAnalysisResponse(text),
        };
      };
      return await withRetry(operation, {
        maxAttempts: 3,
        retryableErrors: ['RATE_LIMIT', 'RESOURCE_EXHAUSTED'],
      });
    } catch (error) {
      logger.error('Error analyzing repository:', { error, request });
      if (error instanceof GeminiServiceError) {
        throw error;
      }
      return {
        analysis: '',
        error: error instanceof Error ? error.message : 'Unknown error occurred',
      };
    }
  }
  private buildAnalysisPrompt(request: RepositoryAnalysisRequest): string {
    const contextInfo = request.context ? `\nAdditional context: ${request.context}` : '';
    return `
      Analyze the following repository:
      Path: ${request.repoPath}
      Query: ${request.query}${contextInfo}
      Please provide your response in the following format:
      Analysis:
      [Detailed analysis of the repository structure and code patterns]
      Suggestions:
      1. [First suggestion]
      2. [Second suggestion]
      ...
      Issues:
      * [First issue]
      * [Second issue]
      ...
      Ensure each section is clearly marked and suggestions/issues are properly formatted with numbers or bullet points.
    `.trim();
  }
  private parseAnalysisResponse(text: string): { suggestions: string[]; issues: string[] } {
    const sections = {
      suggestions: [] as string[],
      issues: [] as string[],
    };
    const lines = text.split('\n');
    let currentSection: keyof typeof sections | null = null;
    for (const line of lines) {
      const trimmedLine = line.trim();
      // Determine section
      if (trimmedLine.toLowerCase().includes('suggestion')) {
        currentSection = 'suggestions';
        continue;
      } else if (trimmedLine.toLowerCase().includes('issue')) {
        currentSection = 'issues';
        continue;
      }
      // Process line if in a valid section
      if (currentSection && trimmedLine) {
        const match = trimmedLine.match(/^(?:\d+\.|[-*])\s*(.+)$/);
        if (match) {
          sections[currentSection].push(match[1].trim());
        }
      }
      // Exit section on empty line
      if (currentSection && !trimmedLine) {
        currentSection = null;
      }
    }
    return sections;
  }
}
</file>

<file path="mcp-server/src/server.js">
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("@modelcontextprotocol/sdk/server/index.js");
const stdio_js_1 = require("@modelcontextprotocol/sdk/server/stdio.js");
const web_search_js_1 = require("./capabilities/tools/web-search.js");
function main() {
    return __awaiter(this, void 0, void 0, function* () {
        try {
            console.log("Starting MCP server...");
            const server = new index_js_1.Server({
                name: "cursor-tools-mcp-server",
                version: "0.1.0",
                description: "MCP server mimicking cursor-tools functionalities."
            }, {
                capabilities: {
                    resources: {}, // Resources will be defined here
                    tools: {
                        'web-search': web_search_js_1.webSearchTool
                    }
                }
            });
            const transport = new stdio_js_1.StdioServerTransport();
            console.log("Connecting to transport...");
            yield server.connect(transport);
            console.log(" MCP Server started using stdio transport.");
            console.log("Available tools:");
            console.log("  - web-search: Perform web searches using Perplexity AI");
        }
        catch (error) {
            console.error(" Server failed to start:", error);
            process.exit(1);
        }
    });
}
// Handle process termination
process.on('SIGINT', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
process.on('SIGTERM', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
// Start the server
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="mcp-server/src/server.ts">
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { webSearchTool } from './capabilities/tools/web-search.js';
import { config, ServerConfigSchema } from './config/index.js';
import { logger } from './utils/logger.js';
import { z } from 'zod';
async function main() {
    try {
        console.log("Starting MCP server...");
        const server = new Server({
            name: "cursor-tools-mcp-server",
            version: "0.1.0",
            description: "MCP server mimicking cursor-tools functionalities."
        }, {
            capabilities: {
                resources: {}, // Resources will be defined here
                tools: {
                    'web-search': webSearchTool
                }
            }
        });
        const transport = new StdioServerTransport();
        console.log("Connecting to transport...");
        await server.connect(transport);
        console.log(" MCP Server started using stdio transport.");
        console.log("Available tools:");
        console.log("  - web-search: Perform web searches using Perplexity AI");
    } catch (error) {
        console.error(" Server failed to start:", error);
        process.exit(1);
    }
}
// Handle process termination
process.on('SIGINT', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
process.on('SIGTERM', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
// Start the server
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="mcp-server/src/test-client.js">
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("@modelcontextprotocol/sdk/client/index.js");
const stdio_js_1 = require("@modelcontextprotocol/sdk/client/stdio.js");
const zod_1 = require("zod");
// Define response schema
const WebSearchResponseSchema = zod_1.z.object({
    result: zod_1.z.object({
        searchResults: zod_1.z.string(),
        savedToFile: zod_1.z.string().optional()
    })
});
function main() {
    return __awaiter(this, void 0, void 0, function* () {
        // Initialize transport with required parameters
        const transport = new stdio_js_1.StdioClientTransport({
            command: 'node',
            args: ['dist/server.js']
        });
        const client = new index_js_1.Client({
            name: "test-client",
            version: "0.1.0"
        }, {
            capabilities: {}
        });
        try {
            console.log("Connecting to MCP server...");
            yield client.connect(transport);
            console.log(" Connected to MCP server\n");
            // Test web search
            console.log("Testing web search tool...");
            const response = yield client.request({
                method: "tool/execute",
                params: {
                    toolName: 'web-search',
                    version: '0.1.0',
                    arguments: {
                        query: "What are the latest developments in AI?",
                        saveTo: "local-research/ai-developments.md"
                    }
                }
            }, WebSearchResponseSchema);
            console.log("\nWeb Search Results:");
            console.log("------------------");
            console.log(response.result.searchResults);
            if (response.result.savedToFile) {
                console.log(`\nResults saved to: ${response.result.savedToFile}`);
            }
        }
        catch (error) {
            console.error(" Error:", error);
        }
        finally {
            console.log("\nClosing client connection...");
            client.close();
        }
    });
}
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="mcp-server/src/test-client.ts">
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import { z } from 'zod';
import { spawn } from 'child_process';
import { logger } from './utils/logger.js';
import { config } from './config/index.js';
// Define response schema
const WebSearchResponseSchema = z.object({
    result: z.object({
        searchResults: z.string(),
        savedToFile: z.string().optional()
    })
});
async function main() {
    // Initialize transport with required parameters
    const transport = new StdioClientTransport({
        command: 'node',
        args: ['dist/server.js']
    });
    const client = new Client({
        name: "test-client",
        version: "0.1.0"
    }, {
        capabilities: {}
    });
    try {
        console.log("Connecting to MCP server...");
        await client.connect(transport);
        console.log(" Connected to MCP server\n");
        // Test web search
        console.log("Testing web search tool...");
        const response = await client.request({
            method: "tool/execute",
            params: {
                toolName: 'web-search',
                version: '0.1.0',
                arguments: {
                    query: "What are the latest developments in AI?",
                    saveTo: "local-research/ai-developments.md"
                }
            }
        }, WebSearchResponseSchema);
        console.log("\nWeb Search Results:");
        console.log("------------------");
        console.log(response.result.searchResults);
        if (response.result.savedToFile) {
            console.log(`\nResults saved to: ${response.result.savedToFile}`);
        }
    } catch (error) {
        console.error(" Error:", error);
    } finally {
        console.log("\nClosing client connection...");
        client.close();
    }
}
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="mcp-server/src/test-setup.js">
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("@modelcontextprotocol/sdk/server/index.js");
const playwright_1 = require("playwright");
const rest_1 = require("@octokit/rest");
const axios_1 = __importDefault(require("axios"));
const dotenv_1 = __importDefault(require("dotenv"));
function testSetup() {
    return __awaiter(this, void 0, void 0, function* () {
        try {
            console.log(' Starting dependency verification...\n');
            // Test dotenv first to load environment variables
            dotenv_1.default.config();
            console.log(' dotenv loaded successfully');
            // Test MCP SDK
            const server = new index_js_1.Server({
                name: "test-server",
                version: "1.0.0"
            }, {
                capabilities: {
                    resources: {},
                    tools: {}
                }
            });
            console.log(' MCP SDK initialized successfully');
            // Test Playwright
            console.log('\n Testing browser automation...');
            const browser = yield playwright_1.chromium.launch();
            yield browser.close();
            console.log(' Playwright working correctly');
            // Test Octokit
            console.log('\n Testing GitHub integration...');
            const octokit = new rest_1.Octokit();
            const { status } = yield octokit.rest.meta.root();
            console.log(` Octokit connected successfully (status: ${status})`);
            // Test Axios
            console.log('\n Testing HTTP client...');
            const response = yield axios_1.default.get('https://api.github.com');
            console.log(` Axios working correctly (status: ${response.status})`);
            console.log('\n All dependencies verified successfully!');
        }
        catch (error) {
            console.error('\n Setup test failed:', error);
            process.exit(1);
        }
    });
}
testSetup();
</file>

<file path="mcp-server/src/test-setup.ts">
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { chromium } from 'playwright';
import { Octokit } from '@octokit/rest';
import axios from 'axios';
import dotenv from 'dotenv';
async function testSetup() {
  try {
    console.log(' Starting dependency verification...\n');
    // Test dotenv first to load environment variables
    dotenv.config();
    console.log(' dotenv loaded successfully');
    // Test MCP SDK
    const server = new Server({
      name: "test-server",
      version: "1.0.0"
    }, {
      capabilities: {
        resources: {},
        tools: {}
      }
    });
    console.log(' MCP SDK initialized successfully');
    // Test Playwright
    console.log('\n Testing browser automation...');
    const browser = await chromium.launch();
    await browser.close();
    console.log(' Playwright working correctly');
    // Test Octokit
    console.log('\n Testing GitHub integration...');
    const octokit = new Octokit();
    const { status } = await octokit.rest.meta.root();
    console.log(` Octokit connected successfully (status: ${status})`);
    // Test Axios
    console.log('\n Testing HTTP client...');
    const response = await axios.get('https://api.github.com');
    console.log(` Axios working correctly (status: ${response.status})`);
    console.log('\n All dependencies verified successfully!');
  } catch (error) {
    console.error('\n Setup test failed:', error);
    process.exit(1);
  }
}
testSetup();
</file>

<file path="mcp-server/src/utils/logger.js">
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.logger = void 0;
const index_js_1 = require("../config/index.js");
// Define log levels and their numeric values
const LogLevels = {
    debug: 0,
    info: 1,
    warn: 2,
    error: 3
};
class Logger {
    constructor(logLevel = 'info') {
        this.currentLogLevel = logLevel;
    }
    shouldLog(level) {
        return LogLevels[level] >= LogLevels[this.currentLogLevel];
    }
    formatMessage(level, message, context) {
        return {
            level,
            message,
            timestamp: new Date().toISOString(),
            context
        };
    }
    log(level, message, context) {
        if (!this.shouldLog(level))
            return;
        const logMessage = this.formatMessage(level, message, context);
        const output = JSON.stringify(logMessage);
        switch (level) {
            case 'error':
                console.error(output);
                break;
            case 'warn':
                console.warn(output);
                break;
            default:
                console.log(output);
        }
    }
    debug(message, context) {
        this.log('debug', message, context);
    }
    info(message, context) {
        this.log('info', message, context);
    }
    warn(message, context) {
        this.log('warn', message, context);
    }
    error(message, context) {
        this.log('error', message, context);
    }
}
// Create and export singleton instance
exports.logger = new Logger(index_js_1.config.logLevel);
</file>

<file path="mcp-server/src/utils/logger.ts">
import { config } from '../config/index.js';
// Define log levels and their numeric values
const LogLevels = {
    debug: 0,
    info: 1,
    warn: 2,
    error: 3
} as const;
type LogLevel = keyof typeof LogLevels;
interface LogMessage {
    level: LogLevel;
    message: string;
    timestamp: string;
    context?: Record<string, unknown>;
}
class Logger {
    private currentLogLevel: LogLevel;
    constructor(logLevel: LogLevel = 'info') {
        this.currentLogLevel = logLevel;
    }
    private shouldLog(level: LogLevel): boolean {
        return LogLevels[level] >= LogLevels[this.currentLogLevel];
    }
    private formatMessage(level: LogLevel, message: string, context?: Record<string, unknown>): LogMessage {
        return {
            level,
            message,
            timestamp: new Date().toISOString(),
            context
        };
    }
    private log(level: LogLevel, message: string, context?: Record<string, unknown>) {
        if (!this.shouldLog(level)) return;
        const logMessage = this.formatMessage(level, message, context);
        const output = JSON.stringify(logMessage);
        switch (level) {
            case 'error':
                console.error(output);
                break;
            case 'warn':
                console.warn(output);
                break;
            default:
                console.log(output);
        }
    }
    debug(message: string, context?: Record<string, unknown>) {
        this.log('debug', message, context);
    }
    info(message: string, context?: Record<string, unknown>) {
        this.log('info', message, context);
    }
    warn(message: string, context?: Record<string, unknown>) {
        this.log('warn', message, context);
    }
    error(message: string, context?: Record<string, unknown>) {
        this.log('error', message, context);
    }
}
// Create and export singleton instance
export const logger = new Logger(config.logLevel);
</file>

<file path="mcp-server/src/utils/retry.ts">
import { logger } from './logger.js';
export interface RetryOptions {
  maxAttempts: number;
  initialDelay: number;
  maxDelay: number;
  backoffFactor: number;
  retryableErrors?: Array<string | RegExp>;
}
export const defaultRetryOptions: RetryOptions = {
  maxAttempts: 3,
  initialDelay: 1000,
  maxDelay: 10000,
  backoffFactor: 2,
  retryableErrors: [
    'ECONNRESET',
    'ETIMEDOUT',
    'ECONNREFUSED',
    'RATE_LIMIT',
    /^5\d{2}$/,  // 5XX errors
    'socket hang up',
  ],
};
export class RetryError extends Error {
  constructor(
    message: string,
    public readonly attempts: number,
    public readonly lastError: Error
  ) {
    super(message);
    this.name = 'RetryError';
  }
}
export async function withRetry<T>(
  operation: () => Promise<T>,
  options: Partial<RetryOptions> = {}
): Promise<T> {
  const retryOptions = { ...defaultRetryOptions, ...options };
  let lastError: Error | null = null;
  let delay = retryOptions.initialDelay;
  for (let attempt = 1; attempt <= retryOptions.maxAttempts; attempt++) {
    try {
      return await operation();
    } catch (error) {
      lastError = error as Error;
      if (attempt === retryOptions.maxAttempts) {
        throw new RetryError(
          `Operation failed after ${attempt} attempts`,
          attempt,
          lastError
        );
      }
      const shouldRetry = retryOptions.retryableErrors?.some(pattern => {
        if (pattern instanceof RegExp) {
          return pattern.test(lastError?.message || '');
        }
        return lastError?.message?.includes(pattern);
      });
      if (!shouldRetry) {
        throw lastError;
      }
      logger.warn(`Attempt ${attempt} failed, retrying in ${delay}ms`, {
        error: lastError.message,
        attempt,
        nextDelay: delay,
      });
      await new Promise(resolve => setTimeout(resolve, delay));
      delay = Math.min(delay * retryOptions.backoffFactor, retryOptions.maxDelay);
    }
  }
  throw new RetryError(
    'Retry operation failed unexpectedly',
    retryOptions.maxAttempts,
    lastError!
  );
}
</file>

<file path="mcp-server/tsconfig.json">
{
  "compilerOptions": {
    /* Visit https://aka.ms/tsconfig to read more about this file */

    /* Projects */
    // "incremental": true,                              /* Save .tsbuildinfo files to allow for incremental compilation of projects. */
    // "composite": true,                                /* Enable constraints that allow a TypeScript project to be used with project references. */
    // "tsBuildInfoFile": "./.tsbuildinfo",              /* Specify the path to .tsbuildinfo incremental compilation file. */
    // "disableSourceOfProjectReferenceRedirect": true,  /* Disable preferring source files instead of declaration files when referencing composite projects. */
    // "disableSolutionSearching": true,                 /* Opt a project out of multi-project reference checking when editing. */
    // "disableReferencedProjectLoad": true,             /* Reduce the number of projects loaded automatically by TypeScript. */

    /* Language and Environment */
    "target": "ES2022",
    // "lib": [],                                        /* Specify a set of bundled library declaration files that describe the target runtime environment. */
    // "jsx": "preserve",                                /* Specify what JSX code is generated. */
    // "experimentalDecorators": true,                   /* Enable experimental support for legacy experimental decorators. */
    // "emitDecoratorMetadata": true,                    /* Emit design-type metadata for decorated declarations in source files. */
    // "jsxFactory": "",                                 /* Specify the JSX factory function used when targeting React JSX emit, e.g. 'React.createElement' or 'h'. */
    // "jsxFragmentFactory": "",                         /* Specify the JSX Fragment reference used for fragments when targeting React JSX emit e.g. 'React.Fragment' or 'Fragment'. */
    // "jsxImportSource": "",                            /* Specify module specifier used to import the JSX factory functions when using 'jsx: react-jsx*'. */
    // "reactNamespace": "",                             /* Specify the object invoked for 'createElement'. This only applies when targeting 'react' JSX emit. */
    // "noLib": true,                                    /* Disable including any library files, including the default lib.d.ts. */
    // "useDefineForClassFields": true,                  /* Emit ECMAScript-standard-compliant class fields. */
    // "moduleDetection": "auto",                        /* Control what method is used to detect module-format JS files. */

    /* Modules */
    "module": "NodeNext",
    "rootDir": "./src",
    "moduleResolution": "NodeNext",
    "baseUrl": ".",
    "paths": {
      "@/*": ["src/*"]
    },
    // "rootDirs": [],                                   /* Allow multiple folders to be treated as one when resolving modules. */
    // "typeRoots": [],                                  /* Specify multiple folders that act like './node_modules/@types'. */
    "types": ["node", "jest"],
    // "allowUmdGlobalAccess": true,                     /* Allow accessing UMD globals from modules. */
    // "moduleSuffixes": [],                             /* List of file name suffixes to search when resolving a module. */
    // "allowImportingTsExtensions": true,               /* Allow imports to include TypeScript file extensions. Requires '--moduleResolution bundler' and either '--noEmit' or '--emitDeclarationOnly' to be set. */
    // "resolvePackageJsonExports": true,                /* Use the package.json 'exports' field when resolving package imports. */
    // "resolvePackageJsonImports": true,                /* Use the package.json 'imports' field when resolving imports. */
    // "customConditions": [],                           /* Conditions to set in addition to the resolver-specific defaults when resolving imports. */
    "resolveJsonModule": true,
    // "allowArbitraryExtensions": true,                 /* Enable importing files with any extension, provided a declaration file is present. */
    // "noResolve": true,                                /* Disallow 'import's, 'require's or '<reference>'s from expanding the number of files TypeScript should add to a project. */

    /* JavaScript Support */
    "allowJs": true,
    // "checkJs": true,                                  /* Enable error reporting in type-checked JavaScript files. */
    // "maxNodeModuleJsDepth": 1,                        /* Specify the maximum folder depth used for checking JavaScript files from 'node_modules'. Only applicable with 'allowJs'. */

    /* Emit */
    // "declaration": true,                              /* Generate .d.ts files from TypeScript and JavaScript files in your project. */
    // "declarationMap": true,                           /* Create sourcemaps for d.ts files. */
    // "emitDeclarationOnly": true,                      /* Only output d.ts files and not JavaScript files. */
    // "sourceMap": true,                                /* Create source map files for emitted JavaScript files. */
    // "inlineSourceMap": true,                          /* Include sourcemap files inside the emitted JavaScript. */
    // "outFile": "./",                                  /* Specify a file that bundles all outputs into one JavaScript file. If 'declaration' is true, also designates a file that bundles all .d.ts output. */
    "outDir": "./dist",
    // "removeComments": true,                           /* Disable emitting comments. */
    // "noEmit": true,                                   /* Disable emitting files from a compilation. */
    // "importHelpers": true,                            /* Allow importing helper functions from tslib once per project, instead of including them per-file. */
    // "importsNotUsedAsValues": "remove",               /* Specify emit/checking behavior for imports that are only used for types. */
    // "downlevelIteration": true,                       /* Emit more compliant, but verbose and less performant JavaScript for iteration. */
    // "sourceRoot": "",                                 /* Specify the root path for debuggers to find the reference source code. */
    // "mapRoot": "",                                    /* Specify the location where debugger should locate map files instead of generated locations. */
    // "inlineSources": true,                            /* Include source code in the sourcemaps inside the emitted JavaScript. */
    // "emitBOM": true,                                  /* Emit a UTF-8 Byte Order Mark (BOM) in the beginning of output files. */
    // "newLine": "crlf",                                /* Set the newline character for emitting files. */
    // "stripInternal": true,                            /* Disable emitting declarations that have '@internal' in their JSDoc comments. */
    // "noEmitHelpers": true,                            /* Disable generating custom helper functions like '__extends' in compiled output. */
    // "noEmitOnError": true,                            /* Disable emitting files if any type checking errors are reported. */
    // "preserveConstEnums": true,                       /* Disable erasing 'const enum' declarations in generated code. */
    // "declarationDir": "./",                           /* Specify the output directory for generated declaration files. */
    // "preserveValueImports": true,                     /* Preserve unused imported values in the JavaScript output that would otherwise be removed. */

    /* Interop Constraints */
    "isolatedModules": true,
    // "verbatimModuleSyntax": true,                     /* Do not transform or elide any imports or exports not marked as type-only, ensuring they are written in the output file's format based on the 'module' setting. */
    // "allowSyntheticDefaultImports": true,             /* Allow 'import x from y' when a module doesn't have a default export. */
    "esModuleInterop": true,
    // "preserveSymlinks": true,                         /* Disable resolving symlinks to their realpath. This correlates to the same flag in node. */
    "forceConsistentCasingInFileNames": true,

    /* Type Checking */
    "strict": true,
    // "noImplicitAny": true,                            /* Enable error reporting for expressions and declarations with an implied 'any' type. */
    // "strictNullChecks": true,                         /* When type checking, take into account 'null' and 'undefined'. */
    // "strictFunctionTypes": true,                      /* When assigning functions, check to ensure parameters and the return values are subtype-compatible. */
    // "strictBindCallApply": true,                      /* Check that the arguments for 'bind', 'call', and 'apply' methods match the original function. */
    // "strictPropertyInitialization": true,             /* Check for class properties that are declared but not set in the constructor. */
    // "noImplicitThis": true,                           /* Enable error reporting when 'this' is given the type 'any'. */
    // "useUnknownInCatchVariables": true,               /* Default catch clause variables as 'unknown' instead of 'any'. */
    // "alwaysStrict": true,                             /* Ensure 'use strict' is always emitted. */
    // "noUnusedLocals": true,                           /* Enable error reporting when local variables aren't read. */
    // "noUnusedParameters": true,                       /* Raise an error when a function parameter isn't read. */
    // "exactOptionalPropertyTypes": true,               /* Interpret optional property types as written, rather than adding 'undefined'. */
    // "noImplicitReturns": true,                        /* Enable error reporting for codepaths that do not explicitly return in a function. */
    // "noFallthroughCasesInSwitch": true,               /* Enable error reporting for fallthrough cases in switch statements. */
    // "noUncheckedIndexedAccess": true,                 /* Add 'undefined' to a type when accessed using an index. */
    // "noImplicitOverride": true,                       /* Ensure overriding members in derived classes are marked with an override modifier. */
    // "noPropertyAccessFromIndexSignature": true,       /* Enforces using indexed accessors for keys declared using an indexed type. */
    // "allowUnusedLabels": true,                        /* Disable error reporting for unused labels. */
    // "allowUnreachableCode": true,                     /* Disable error reporting for unreachable code. */

    /* Completeness */
    // "skipDefaultLibCheck": true,                      /* Skip type checking .d.ts files that are included with TypeScript. */
    "skipLibCheck": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
</file>

<file path="package.json">
{
  "name": "developer-tools",
  "version": "1.0.0",
  "description": "A comprehensive suite of development tools including MCP server implementation",
  "type": "module",
  "main": "dist/server.js",
  "exports": {
    ".": {
      "import": "./dist/server.js",
      "types": "./dist/server.d.ts"
    }
  },
  "scripts": {
    "build": "tsc",
    "start": "node dist/server.js",
    "dev": "ts-node --esm src/server.ts",
    "test:client": "node dist/test-client.js",
    "test": "node --experimental-vm-modules node_modules/jest/bin/jest.js",
    "test:watch": "node --experimental-vm-modules node_modules/jest/bin/jest.js --watch",
    "test:coverage": "node --experimental-vm-modules node_modules/jest/bin/jest.js --coverage",
    "lint": "eslint . --ext .ts",
    "lint:fix": "eslint . --ext .ts --fix",
    "format": "prettier --write \"src/**/*.ts\"",
    "prepare": "husky install"
  },
  "keywords": [
    "mcp",
    "development-tools",
    "typescript",
    "ai-tools"
  ],
  "author": "freshtechbro",
  "license": "MIT",
  "dependencies": {
    "@modelcontextprotocol/sdk": "1.2.0",
    "@octokit/rest": "19.0.13",
    "axios": "1.6.5",
    "dotenv": "16.3.1",
    "playwright": "1.41.2",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/jest": "^29.5.11",
    "@types/node": "20.11.5",
    "@typescript-eslint/eslint-plugin": "^6.19.1",
    "@typescript-eslint/parser": "^6.19.1",
    "eslint": "^8.56.0",
    "eslint-config-prettier": "^9.1.0",
    "eslint-plugin-prettier": "^5.1.3",
    "husky": "^8.0.3",
    "jest": "^29.7.0",
    "lint-staged": "^15.2.0",
    "prettier": "^3.2.4",
    "ts-jest": "^29.1.2",
    "ts-node": "10.9.2",
    "typescript": "5.3.3",
    "cursor-tools": "latest"
  },
  "lint-staged": {
    "*.ts": [
      "eslint --fix",
      "prettier --write"
    ]
  }
}
</file>

<file path="README.md">
# Developer Tools

A comprehensive suite of development tools including an MCP (Model Context Protocol) server implementation and various utilities for enhancing developer productivity.

##  Features

- **MCP Server Implementation**: A TypeScript-based server implementing the Model Context Protocol
- **Web Search Integration**: Powered by Perplexity AI
- **Repository Analysis**: Using Google's Gemini AI
- **Browser Automation**: For web interaction and testing
- **Comprehensive Documentation**: Including research and implementation guides

##  Prerequisites

- Node.js (v16 or higher)
- npm or yarn
- TypeScript knowledge for development

##  Installation

1. Clone the repository:
```bash
git clone https://github.com/freshtechbro/developer-tools.git
cd developer-tools
```

2. Install dependencies:
```bash
npm install
```

3. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your actual API keys and configuration
```

##  Configuration

The following environment variables are required:

- `PERPLEXITY_API_KEY`: Your Perplexity AI API key
- `GOOGLE_API_KEY`: Your Google API key for Gemini
- `NODE_ENV`: Development environment (development/production/test)
- `LOG_LEVEL`: Logging level (debug/info/warn/error)
- `PORT`: Server port (default: 3000)
- `HOST`: Server host (default: localhost)

##  Usage

1. Start the MCP server:
```bash
npm run start
```

2. For development with hot-reload:
```bash
npm run dev
```

3. Build the project:
```bash
npm run build
```

##  Documentation

Detailed documentation is available in the `local-research` directory:

- `mcp-setup-guide.md`: Complete setup instructions
- `dependencies-installation-guide.md`: Dependency management guide
- `typescript-esm-config.md`: TypeScript and ESM configuration details
- Additional implementation and research documents

##  Testing

Run the test suite:
```bash
npm test
```

##  Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

##  License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

##  Security

- Environment variables and sensitive data are never committed to the repository
- API keys should be kept secure and not shared
- See `.env.example` for required environment variables
- Branch protection rules are in place for the main branch

##  Acknowledgments

- Model Context Protocol team for the SDK
- Perplexity AI for search capabilities
- Google Gemini for AI features
</file>

<file path="src/capabilities/tools/__tests__/web-search.test.ts">
import { jest } from '@jest/globals';
import { webSearchTool } from '../web-search.js';
import { config } from '../../../config/index.js';
import axios from 'axios';
// Mock axios
jest.mock('axios', () => ({
    post: jest.fn(),
    isAxiosError: jest.fn()
}));
// Mock config
jest.mock('../../../config/index.js', () => ({
    config: {
        env: 'test',
        perplexityApiKey: undefined,
        logLevel: 'info'
    }
}));
// Mock logger
jest.mock('../../../utils/logger.js', () => ({
    logger: {
        info: jest.fn(),
        warn: jest.fn(),
        error: jest.fn(),
        debug: jest.fn()
    }
}));
describe('Web Search Tool', () => {
    beforeEach(() => {
        jest.clearAllMocks();
    });
    describe('when PERPLEXITY_API_KEY is not provided', () => {
        it('should return mock results in test environment', async () => {
            const request = { query: 'test query' };
            const result = await webSearchTool.execute(request);
            expect(result).toEqual({ searchResults: 'Mock search results for testing' });
            expect(axios.post).not.toHaveBeenCalled();
        });
    });
    describe('when PERPLEXITY_API_KEY is provided', () => {
        beforeEach(() => {
            (config as any).perplexityApiKey = 'test-api-key';
        });
        it('should make API call and return results', async () => {
            const mockResponse = {
                data: {
                    choices: [{ message: { content: 'API search results' } }]
                }
            };
            (axios.post as jest.Mock).mockResolvedValueOnce(mockResponse);
            const request = { query: 'test query' };
            const result = await webSearchTool.execute(request);
            expect(result).toEqual({ searchResults: 'API search results' });
            expect(axios.post).toHaveBeenCalledWith(
                expect.any(String),
                expect.objectContaining({
                    messages: [{ role: 'user', content: 'test query' }]
                }),
                expect.objectContaining({
                    headers: { 'Authorization': 'Bearer test-api-key' }
                })
            );
        });
        it('should handle API errors gracefully', async () => {
            const mockError = { response: { data: { error: 'API Error' } } };
            (axios.post as jest.Mock).mockRejectedValueOnce(mockError);
            (axios.isAxiosError as jest.Mock).mockReturnValue(true);
            const request = { query: 'test query' };
            await expect(webSearchTool.execute(request)).rejects.toThrow('Web search failed: API Error');
        });
        it('should validate request schema', async () => {
            const invalidRequest = { query: '' };
            await expect(webSearchTool.execute(invalidRequest)).rejects.toThrow('Search query is required');
        });
        it('should handle saving results to file when requested', async () => {
            const mockResponse = {
                data: {
                    choices: [{ message: { content: 'API search results' } }]
                }
            };
            (axios.post as jest.Mock).mockResolvedValueOnce(mockResponse);
            const request = { query: 'test query', saveToFile: true };
            const result = await webSearchTool.execute(request);
            expect(result).toMatchObject({
                searchResults: 'API search results',
                savedToFile: expect.stringContaining('web-search-')
            });
        });
    });
});
</file>

<file path="src/capabilities/tools/repo-analysis.ts">
import { z } from 'zod';
import axios from 'axios';
import * as fs from 'fs/promises';
import * as path from 'path';
import type { Tool } from '../../types/tool.js';
import { config } from '../../config/index.js';
import { logger } from '../../utils/logger.js';
// Schema for repository analysis request
const repoAnalysisRequestSchema = z.object({
  query: z.string().describe('The analysis query or question about the repository'),
  analysisType: z.enum(['code', 'documentation', 'both']).default('both')
    .describe('Type of analysis to perform'),
  targetPath: z.string().optional()
    .describe('Specific path or file to analyze. If not provided, analyzes the entire repository'),
  maxDepth: z.number().optional().default(3)
    .describe('Maximum directory depth for analysis'),
});
// Schema for repository analysis response
const repoAnalysisResponseSchema = z.object({
  analysis: z.string().describe('The analysis results from Gemini'),
  codeInsights: z.object({
    architecture: z.array(z.string()).optional(),
    dependencies: z.array(z.string()).optional(),
    patterns: z.array(z.string()).optional(),
  }).optional(),
  documentationInsights: z.object({
    coverage: z.number().optional(),
    quality: z.string().optional(),
    recommendations: z.array(z.string()).optional(),
  }).optional(),
});
// Cache interface for storing analysis results
interface AnalysisCache {
  timestamp: number;
  result: z.infer<typeof repoAnalysisResponseSchema>;
}
const analysisCache = new Map<string, AnalysisCache>();
const CACHE_TTL = 1000 * 60 * 60; // 1 hour
export const repoAnalysisTool: Tool = {
  name: 'repo-analysis',
  version: '0.1.0',
  description: 'Analyzes repository code and documentation using Google Gemini',
  execute: async (request: unknown) => {
    const parsedRequest = repoAnalysisRequestSchema.parse(request);
    const cacheKey = JSON.stringify({
      query: parsedRequest.query,
      analysisType: parsedRequest.analysisType,
      targetPath: parsedRequest.targetPath,
    });
    // Check cache first
    const cachedResult = analysisCache.get(cacheKey);
    if (cachedResult && Date.now() - cachedResult.timestamp < CACHE_TTL) {
      return cachedResult.result;
    }
    try {
      // Get repository content based on targetPath and maxDepth
      const repoContent = await getRepositoryContent(
        parsedRequest.targetPath || '.',
        parsedRequest.maxDepth
      );
      // Call Gemini API for analysis
      const analysis = await analyzeWithGemini(
        parsedRequest.query,
        repoContent,
        parsedRequest.analysisType
      );
      // Parse and structure the response
      const response = repoAnalysisResponseSchema.parse({
        analysis: analysis.mainAnalysis,
        codeInsights: analysis.codeInsights,
        documentationInsights: analysis.documentationInsights,
      });
      // Cache the result
      analysisCache.set(cacheKey, {
        timestamp: Date.now(),
        result: response,
      });
      return response;
    } catch (error) {
      console.error('Error in repo analysis:', error);
      if (error instanceof Error) {
        throw new Error(`Repository analysis failed: ${error.message}`);
      } else {
        throw new Error('Repository analysis failed: Unknown error');
      }
    }
  },
  requestSchema: repoAnalysisRequestSchema,
  responseSchema: repoAnalysisResponseSchema,
};
async function getRepositoryContent(
  targetPath: string,
  maxDepth: number,
  currentDepth = 0
): Promise<string[]> {
  const contents: string[] = [];
  try {
    const stats = await fs.stat(targetPath);
    if (stats.isFile()) {
      const content = await fs.readFile(targetPath, 'utf-8');
      contents.push(`File: ${targetPath}\n${content}`);
    } else if (stats.isDirectory() && currentDepth < maxDepth) {
      const files = await fs.readdir(targetPath);
      for (const file of files) {
        if (file.startsWith('.') || file === 'node_modules') continue;
        const fullPath = path.join(targetPath, file);
        const subContents = await getRepositoryContent(
          fullPath,
          maxDepth,
          currentDepth + 1
        );
        contents.push(...subContents);
      }
    }
  } catch (error) {
    console.error(`Error reading ${targetPath}:`, error);
  }
  return contents;
}
interface GeminiAnalysis {
  mainAnalysis: string;
  codeInsights?: {
    architecture?: string[];
    dependencies?: string[];
    patterns?: string[];
  };
  documentationInsights?: {
    coverage?: number;
    quality?: string;
    recommendations?: string[];
  };
}
async function analyzeWithGemini(
  query: string,
  repoContent: string[],
  analysisType: 'code' | 'documentation' | 'both'
): Promise<GeminiAnalysis> {
  if (!config.googleApiKey) {
    const error = new Error('Google API Key not found in environment variables (GOOGLE_API_KEY)');
    logger.error('API key missing', { tool: 'repo-analysis' });
    throw error;
  }
  const prompt = `Analyze the following repository content and answer this query: ${query}
Analysis type: ${analysisType}
Repository content:
${repoContent.join('\n\n')}
Please provide:
1. Main analysis addressing the query
2. Code insights (architecture, dependencies, patterns)
3. Documentation insights (coverage, quality, recommendations)`;
  try {
    logger.info('Calling Gemini API for analysis', { query, analysisType });
    const response = await axios.post(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${config.googleApiKey}`,
      {
        contents: [{
          parts: [{
            text: prompt
          }]
        }]
      }
    );
    // Parse Gemini response and structure it
    const geminiText = response.data.candidates[0].content.parts[0].text;
    logger.debug('Received response from Gemini API');
    // TODO: Implement proper parsing of Gemini's response to extract structured insights
    // For now, return a simplified version
    return {
      mainAnalysis: geminiText,
      codeInsights: {
        architecture: ['To be implemented'],
        dependencies: ['To be implemented'],
        patterns: ['To be implemented'],
      },
      documentationInsights: {
        coverage: 0,
        quality: 'To be implemented',
        recommendations: ['To be implemented'],
      },
    };
  } catch (error) {
    logger.error('Error calling Gemini API', {
      error: error instanceof Error ? error.message : String(error),
      query,
      analysisType
    });
    if (axios.isAxiosError(error)) {
      const errorMessage = error.response?.data?.error || error.message;
      logger.error('Axios error details', {
        status: error.response?.status,
        data: error.response?.data
      });
      throw new Error(`Failed to analyze repository with Gemini: ${errorMessage}`);
    }
    throw new Error(`Failed to analyze repository with Gemini: ${error instanceof Error ? error.message : String(error)}`);
  }
}
</file>

<file path="src/capabilities/tools/web-search.ts">
import axios from 'axios';
import { z } from 'zod';
import { config } from '../../config/index.js';
import { logger } from '../../utils/logger.js';
import type { Tool } from '../../types/tool.js';
const PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions";
const PERPLEXITY_MODEL = "codellama-34b-instruct";
// Define request and response schemas
const WebSearchRequestSchema = z.object({
    query: z.string().min(1, "Search query cannot be empty"),
    saveToFile: z.boolean().optional().default(false)
});
const WebSearchResponseSchema = z.object({
    searchResults: z.string(),
    savedToFile: z.string().optional()
});
type WebSearchRequest = z.infer<typeof WebSearchRequestSchema>;
type WebSearchResponse = z.infer<typeof WebSearchResponseSchema>;
export const webSearchTool: Tool = {
    name: 'web-search',
    version: '0.1.0',
    description: 'Performs a web search using Perplexity AI.',
    execute: async (request: unknown): Promise<unknown> => {
        // Validate request first
        const { query, saveToFile } = WebSearchRequestSchema.parse(request);
        if (!query.trim()) {
            throw new Error("Search query cannot be empty");
        }
        // Handle test environment
        if (config.env === 'test' && !config.perplexityApiKey) {
            logger.warn("Perplexity API key not set in test environment, returning mock response", { tool: 'web-search' });
            return WebSearchResponseSchema.parse({ 
                searchResults: "Mock search results for testing" 
            });
        }
        // Check for API key in non-test environment
        if (!config.perplexityApiKey) {
            const error = new Error("Perplexity API key not set");
            logger.error("API key missing", { tool: 'web-search' });
            throw error;
        }
        try {
            logger.info("Performing web search", { query });
            const response = await axios.post(PERPLEXITY_API_URL, {
                model: PERPLEXITY_MODEL,
                messages: [{ role: "user", content: query }],
                max_tokens: 150
            }, {
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${config.perplexityApiKey}`
                },
                timeout: 10000 // 10 second timeout
            });
            if (!response.data?.choices?.[0]?.message?.content) {
                logger.warn("Unexpected API response format", { 
                    responseData: response.data,
                    query 
                });
                throw new Error("Invalid response format from Perplexity API");
            }
            const searchResults = response.data.choices[0].message.content;
            // If saveToFile is true, save results to file
            if (saveToFile) {
                try {
                    const savePath = `local-research/web-search-${Date.now()}.md`;
                    logger.debug("Saving search results to file", { path: savePath });
                    const fs = await import('fs/promises');
                    await fs.mkdir('local-research', { recursive: true });
                    await fs.writeFile(savePath, searchResults, 'utf-8');
                    logger.info("Search results saved successfully", { path: savePath });
                    return WebSearchResponseSchema.parse({ searchResults, savedToFile: savePath });
                } catch (fsError) {
                    logger.error("Failed to save search results to file", {
                        error: fsError instanceof Error ? fsError.message : String(fsError),
                        query
                    });
                    // Return results without saved file on error
                    return WebSearchResponseSchema.parse({ searchResults });
                }
            }
            return WebSearchResponseSchema.parse({ searchResults });
        } catch (error) {
            logger.error("Web search failed", {
                error: error instanceof Error ? error.message : String(error),
                query,
                stack: error instanceof Error ? error.stack : undefined
            });
            if (axios.isAxiosError(error)) {
                const status = error.response?.status;
                const errorMessage = error.response?.data?.error || error.message;
                logger.error("Axios error details", {
                    status,
                    data: error.response?.data,
                    config: error.config
                });
                if (status === 401 || status === 403) {
                    throw new Error("Invalid or expired API key");
                } else if (status === 429) {
                    throw new Error("Rate limit exceeded");
                }
                throw new Error(`Web search failed: ${errorMessage}`);
            }
            if (error instanceof z.ZodError) {
                throw new Error(`Validation error: ${error.errors[0]?.message || 'Invalid data format'}`);
            }
            throw new Error(`Web search failed: ${error instanceof Error ? error.message : String(error)}`);
        }
    },
    requestSchema: WebSearchRequestSchema,
    responseSchema: WebSearchResponseSchema
};
</file>

<file path="src/config/index.ts">
import { z } from 'zod';
import dotenv from 'dotenv';
// Load environment variables
dotenv.config();
// Define environment variable schema
const EnvSchema = z.object({
    NODE_ENV: z.enum(['development', 'production', 'test']).default('development'),
    LOG_LEVEL: z.enum(['debug', 'info', 'warn', 'error']).default('info'),
    PERPLEXITY_API_KEY: z.string().optional(),
    GOOGLE_API_KEY: z.string(),
    PORT: z.string().optional(),
    HOST: z.string().optional()
});
// Define server configuration schema
export const ServerConfigSchema = z.object({
    name: z.string(),
    version: z.string(),
    description: z.string(),
    logLevel: z.enum(['debug', 'info', 'warn', 'error']).default('info'),
    env: z.enum(['development', 'production', 'test']).default('development'),
    port: z.number().optional(),
    host: z.string().optional()
});
// Parse and validate environment variables
const env = EnvSchema.parse(process.env);
// Export validated configuration
export const config = {
    name: "cursor-tools-mcp-server",
    version: "0.1.0",
    description: "MCP server mimicking cursor-tools functionalities.",
    logLevel: env.LOG_LEVEL,
    env: env.NODE_ENV,
    port: env.PORT ? parseInt(env.PORT, 10) : undefined,
    host: env.HOST,
    perplexityApiKey: env.PERPLEXITY_API_KEY,
    googleApiKey: env.GOOGLE_API_KEY
};
// Export environment variables
export const environment = env;
</file>

<file path="src/server.ts">
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { webSearchTool } from './capabilities/tools/web-search.js';
import { repoAnalysisTool } from './capabilities/tools/repo-analysis.js';
import { config, ServerConfigSchema } from './config/index.js';
import { logger } from './utils/logger.js';
import { z } from 'zod';
// Define health check schema
const HealthCheckSchema = z.object({
    status: z.enum(['healthy', 'unhealthy']),
    uptime: z.number(),
    timestamp: z.string(),
    version: z.string()
});
// Define tool execution request schema
const ToolExecuteRequestSchema = z.object({
    method: z.literal('tool/execute'),
    params: z.object({
        toolName: z.string(),
        version: z.string(),
        arguments: z.record(z.unknown())
    })
});
// Define tool interface
interface Tool {
    name: string;
    version: string;
    description: string;
    execute: (request: unknown) => Promise<unknown>;
    requestSchema: z.ZodType;
    responseSchema: z.ZodType;
}
async function main() {
    try {
        logger.info("Starting MCP server...", { config });
        // Validate server configuration
        const validatedConfig = ServerConfigSchema.parse(config);
        // Create tools map
        const tools: Record<string, Tool> = {
            'web-search': webSearchTool,
            'repo-analysis': repoAnalysisTool,
            'health-check': {
                name: 'health-check',
                version: '0.1.0',
                description: 'Check server health status',
                execute: async () => {
                    const health = {
                        status: 'healthy',
                        uptime: process.uptime(),
                        timestamp: new Date().toISOString(),
                        version: validatedConfig.version
                    };
                    return HealthCheckSchema.parse(health);
                },
                requestSchema: z.object({}),
                responseSchema: HealthCheckSchema
            }
        };
        const server = new Server(validatedConfig, {
            capabilities: {
                resources: {}, // Resources will be defined here
                tools
            }
        });
        // Register tool execution handler
        server.setRequestHandler(ToolExecuteRequestSchema, async (request) => {
            const { toolName, version, arguments: args } = request.params;
            // Find the requested tool
            const tool = tools[toolName];
            if (!tool) {
                throw new Error(`Tool '${toolName}' not found`);
            }
            // Execute the tool
            return { result: await tool.execute(args) };
        });
        const transport = new StdioServerTransport();
        // Set up error handlers
        process.on('uncaughtException', (error) => {
            logger.error("Uncaught Exception", { error: error.message, stack: error.stack });
            process.exit(1);
        });
        process.on('unhandledRejection', (reason, promise) => {
            logger.error("Unhandled Rejection", { reason, promise });
            process.exit(1);
        });
        // Handle process termination
        process.on('SIGINT', () => {
            logger.info("Shutting down MCP server...");
            process.exit(0);
        });
        process.on('SIGTERM', () => {
            logger.info("Shutting down MCP server...");
            process.exit(0);
        });
        logger.debug("Connecting to transport...");
        await server.connect(transport);
        logger.info("MCP Server started successfully", {
            transport: "stdio",
            tools: Object.keys(tools)
        });
    } catch (error) {
        logger.error("Server failed to start", { 
            error: error instanceof Error ? error.message : String(error),
            stack: error instanceof Error ? error.stack : undefined
        });
        process.exit(1);
    }
}
// Start the server
main().catch((error) => {
    logger.error("Fatal error", { 
        error: error instanceof Error ? error.message : String(error),
        stack: error instanceof Error ? error.stack : undefined
    });
    process.exit(1);
});
</file>

<file path="src/test-client.ts">
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import { z } from 'zod';
import { spawn } from 'child_process';
import { logger } from './utils/logger.js';
import { config } from './config/index.js';
// Define response schemas
const WebSearchResponseSchema = z.object({
    result: z.object({
        searchResults: z.string(),
        savedToFile: z.string().optional()
    })
});
const RepoAnalysisResponseSchema = z.object({
    result: z.object({
        analysis: z.string(),
        codeInsights: z.object({
            architecture: z.array(z.string()).optional(),
            dependencies: z.array(z.string()).optional(),
            patterns: z.array(z.string()).optional(),
        }).optional(),
        documentationInsights: z.object({
            coverage: z.number().optional(),
            quality: z.string().optional(),
            recommendations: z.array(z.string()).optional(),
        }).optional(),
    })
});
const HealthCheckResponseSchema = z.object({
    result: z.object({
        status: z.enum(['healthy', 'unhealthy']),
        uptime: z.number(),
        timestamp: z.string(),
        version: z.string()
    })
});
async function main() {
    // Initialize transport with required parameters
    const transport = new StdioClientTransport({
        command: 'node',
        args: ['dist/server.js']
    });
    const client = new Client({
        name: "test-client",
        version: "0.1.0"
    }, {
        capabilities: {}
    });
    try {
        logger.info("Connecting to MCP server...");
        await client.connect(transport);
        logger.info("Connected to MCP server");
        // Test health check
        logger.info("Testing health check tool...");
        const healthResponse = await client.request({
            method: "tool/execute",
            params: {
                toolName: 'health-check',
                version: '0.1.0',
                arguments: {}
            }
        }, HealthCheckResponseSchema);
        logger.info("Health check response:", healthResponse);
        // Test web search
        logger.info("Testing web search tool...");
        const webSearchResponse = await client.request({
            method: "tool/execute",
            params: {
                toolName: 'web-search',
                version: '0.1.0',
                arguments: {
                    query: "What is MCP (Model Context Protocol)?",
                    saveToFile: true
                }
            }
        }, WebSearchResponseSchema);
        logger.info("Web search response:", webSearchResponse);
        // Test repository analysis
        logger.info("Testing repository analysis tool...");
        const repoAnalysisResponse = await client.request({
            method: "tool/execute",
            params: {
                toolName: 'repo-analysis',
                version: '0.1.0',
                arguments: {
                    query: "What is the architecture of this project?",
                    analysisType: "both",
                    maxDepth: 2
                }
            }
        }, RepoAnalysisResponseSchema);
        logger.info("Repository analysis response:", repoAnalysisResponse);
    } catch (error) {
        if (error instanceof Error) {
            logger.error("Error occurred", { error: error.message });
        } else {
            logger.error("Unknown error occurred", { error: String(error) });
        }
    } finally {
        client.close();
    }
}
main().catch((error) => {
    if (error instanceof Error) {
        logger.error("Fatal error occurred", { error: error.message });
    } else {
        logger.error("Unknown fatal error occurred", { error: String(error) });
    }
    process.exit(1);
});
</file>

<file path="src/test-setup.ts">
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { chromium } from 'playwright';
import { Octokit } from '@octokit/rest';
import axios from 'axios';
import dotenv from 'dotenv';
async function testSetup() {
  try {
    console.log(' Starting dependency verification...\n');
    // Test dotenv first to load environment variables
    dotenv.config();
    console.log(' dotenv loaded successfully');
    // Test MCP SDK
    const server = new Server({
      name: "test-server",
      version: "1.0.0"
    }, {
      capabilities: {
        resources: {},
        tools: {}
      }
    });
    console.log(' MCP SDK initialized successfully');
    // Test Playwright
    console.log('\n Testing browser automation...');
    const browser = await chromium.launch();
    await browser.close();
    console.log(' Playwright working correctly');
    // Test Octokit
    console.log('\n Testing GitHub integration...');
    const octokit = new Octokit();
    const { status } = await octokit.rest.meta.root();
    console.log(` Octokit connected successfully (status: ${status})`);
    // Test Axios
    console.log('\n Testing HTTP client...');
    const response = await axios.get('https://api.github.com');
    console.log(` Axios working correctly (status: ${response.status})`);
    console.log('\n All dependencies verified successfully!');
  } catch (error) {
    console.error('\n Setup test failed:', error);
    process.exit(1);
  }
}
testSetup();
</file>

<file path="src/test/setup.ts">
import { config } from '../config/index.js';
import { jest } from '@jest/globals';
// Mock process.env
process.env.NODE_ENV = 'test';
process.env.PERPLEXITY_API_KEY = undefined;
// Reset all mocks before each test
beforeEach(() => {
  jest.clearAllMocks();
});
// Ensure config is in test mode
jest.mock('../config/index.js', () => ({
  config: {
    env: 'test',
    perplexityApiKey: undefined,
    logLevel: 'info'
  }
}));
</file>

<file path="src/types/tool.ts">
import { z } from 'zod';
export interface Tool {
    name: string;
    version: string;
    description: string;
    execute: (request: unknown) => Promise<unknown>;
    requestSchema: z.ZodType;
    responseSchema: z.ZodType;
}
</file>

<file path="src/utils/logger.ts">
import { config } from '../config/index.js';
// Define log levels and their numeric values
const LogLevels = {
    debug: 0,
    info: 1,
    warn: 2,
    error: 3
} as const;
type LogLevel = keyof typeof LogLevels;
interface LogMessage {
    level: LogLevel;
    message: string;
    timestamp: string;
    context?: Record<string, unknown>;
}
class Logger {
    private currentLogLevel: LogLevel;
    constructor(logLevel: LogLevel = 'info') {
        this.currentLogLevel = logLevel;
    }
    private shouldLog(level: LogLevel): boolean {
        return LogLevels[level] >= LogLevels[this.currentLogLevel];
    }
    private formatMessage(level: LogLevel, message: string, context?: Record<string, unknown>): LogMessage {
        return {
            level,
            message,
            timestamp: new Date().toISOString(),
            context
        };
    }
    private log(level: LogLevel, message: string, context?: Record<string, unknown>) {
        if (!this.shouldLog(level)) return;
        const logMessage = this.formatMessage(level, message, context);
        const output = JSON.stringify(logMessage);
        switch (level) {
            case 'error':
                console.error(output);
                break;
            case 'warn':
                console.warn(output);
                break;
            default:
                console.log(output);
        }
    }
    debug(message: string, context?: Record<string, unknown>) {
        this.log('debug', message, context);
    }
    info(message: string, context?: Record<string, unknown>) {
        this.log('info', message, context);
    }
    warn(message: string, context?: Record<string, unknown>) {
        this.log('warn', message, context);
    }
    error(message: string, context?: Record<string, unknown>) {
        this.log('error', message, context);
    }
}
// Export singleton instance
export const logger = new Logger(config.logLevel);
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "allowJs": true,
    "declaration": true,
    "isolatedModules": true,
    "allowSyntheticDefaultImports": true,
    "verbatimModuleSyntax": true,
    "sourceMap": true,
    "baseUrl": ".",
    "paths": {
      "*": ["node_modules/*"]
    }
  },
  "ts-node": {
    "esm": true,
    "experimentalSpecifiers": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
</file>

<file path="wiki-home.md">
# Developer Tools Wiki

Welcome to the Developer Tools wiki! This wiki contains detailed documentation about the project's architecture, components, and usage guides.

## Navigation

* [Getting Started](Getting-Started)
* [Architecture Overview](Architecture-Overview)
* [API Documentation](API-Documentation)
* [Development Guide](Development-Guide)
* [Deployment Guide](Deployment-Guide)
* [Troubleshooting](Troubleshooting)

## Quick Links

* [MCP Server Documentation](MCP-Server)
* [Web Search Integration](Web-Search)
* [Repository Analysis](Repository-Analysis)
* [Browser Automation](Browser-Automation)

## Contributing

* [Development Setup](Development-Setup)
* [Coding Standards](Coding-Standards)
* [Testing Guidelines](Testing-Guidelines)
* [Pull Request Process](Pull-Request-Process)

## Support

* [FAQ](FAQ)
* [Known Issues](Known-Issues)
* [Release Notes](Release-Notes)

## Additional Resources

* [External Dependencies](External-Dependencies)
* [Security Guidelines](Security-Guidelines)
* [Performance Optimization](Performance-Optimization)

---
**Note**: This wiki is under active development. If you find any issues or have suggestions for improvement, please feel free to contribute or raise an issue in the main repository.
</file>

</files>
