This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-28T17:30:47.305Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
mcp-server/src/capabilities/resources/
mcp-server/src/test/
src/resources/__tests__/__mocks__/
.eslintrc.json
.gitignore
.prettierrc
1
dependencies.md
docs/web-search-tool.md
how --name-only 0a2bc6cd30a666675e3a3477427bd0b6de333d3f
how --name-only 0a2bc6cd30a666675e3a3477427bd0b6de333d3f ÔÅº Select-String -Pattern ÔÄ¢^[A-Za-z]ÔÄ¢ ÔÅº Select-Object -Skip 5
jest.config.js
LICENSE
local-research/codebase-analysis.md
local-research/cursor-tools-analysis.md
local-research/cursor-tools-implementation.md
local-research/dependencies-installation-guide.md
local-research/dependencies-research.md
local-research/grok-enhancements
local-research/http-sse-transport-implementation-plan.md
local-research/jest-fs-mocking-best-practices.md
local-research/jest-fs-mocking-gemini.md
local-research/mcp-clarifications.md
local-research/mcp-detailed-steps.md
local-research/mcp-final-recommendations.md
local-research/mcp-final-review.md
local-research/mcp-implementation-plan.md
local-research/mcp-installation-research.md
local-research/mcp-plan.md
local-research/mcp-research.md
local-research/mcp-setup-guide.md
local-research/mcp-user-experience.md
local-research/typescript-esm-config.md
mcp-server/.eslintrc.json
mcp-server/.prettierrc
mcp-server/.repomix-output.txt
mcp-server/jest.config.js
mcp-server/local-research/implementation-plan.md
mcp-server/local-research/mcp-implementation-research.md
mcp-server/local-research/typescript-esm-research.md
mcp-server/package.json
mcp-server/src/capabilities/tools/__tests__/web-search.test.ts
mcp-server/src/capabilities/tools/web-search.js
mcp-server/src/capabilities/tools/web-search.ts
mcp-server/src/config/index.js
mcp-server/src/config/index.ts
mcp-server/src/gemini/__tests__/service.test.ts
mcp-server/src/gemini/config.ts
mcp-server/src/gemini/service.ts
mcp-server/src/server.js
mcp-server/src/server.ts
mcp-server/src/test-client.js
mcp-server/src/test-client.ts
mcp-server/src/test-setup.js
mcp-server/src/test-setup.ts
mcp-server/src/utils/logger.js
mcp-server/src/utils/logger.ts
mcp-server/src/utils/retry.ts
mcp-server/tsconfig.json
package.json
public/index.html
public/mcp-client.js
public/README.md
README.md
src/capabilities/tools/__tests__/web-search.test.ts
src/capabilities/tools/browser-automation.ts
src/capabilities/tools/repo-analysis.ts
src/capabilities/tools/web-search.ts
src/config/index.ts
src/resources/__tests__/github-pr.resource.test.ts
src/resources/github-pr.resource.ts
src/resources/search-history.resource.ts
src/routes/search-history.routes.ts
src/server.ts
src/services/__mocks__/file-storage.service.js
src/services/__tests__/gemini.service.test.ts
src/services/__tests__/perplexity.service.test.ts
src/services/browser.service.ts
src/services/file-storage.service.ts
src/services/gemini.service.ts
src/services/perplexity.service.ts
src/services/README.md
src/test-client.ts
src/test-setup.ts
src/test/jest.setup.ts
src/transports/http.ts
src/transports/sse.ts
src/types/tool.ts
src/utils/__mocks__/logger.js
src/utils/__mocks__/rate-limiter.js
src/utils/__tests__/rate-limiter.test.ts
src/utils/logger.ts
src/utils/rate-limiter.ts
src/web-interface.ts
tsconfig.json
wiki-home.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".eslintrc.json">
{
  "env": {
    "node": true,
    "es2021": true
  },
  "extends": [
    "eslint:recommended",
    "plugin:@typescript-eslint/recommended",
    "plugin:prettier/recommended"
  ],
  "parser": "@typescript-eslint/parser",
  "parserOptions": {
    "ecmaVersion": "latest",
    "sourceType": "module"
  },
  "plugins": [
    "@typescript-eslint"
  ],
  "rules": {
    "@typescript-eslint/explicit-function-return-type": "warn",
    "@typescript-eslint/no-unused-vars": ["error", { "argsIgnorePattern": "^_" }],
    "@typescript-eslint/no-explicit-any": "error",
    "no-console": ["warn", { "allow": ["warn", "error"] }]
  }
}
</file>

<file path=".gitignore">
# Dependencies
node_modules/
package-lock.json

# Environment variables and secrets
.env
.env.*
!.env.example
.cursorrules


# Build outputs
dist/
build/
*.tsbuildinfo

# Logs and traces
logs/
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
trace/

# IDE and editor files
.idea/
.vscode/
*.swp
*.swo
*~

# Operating System
.DS_Store
Thumbs.db

# Test coverage
coverage/

# Temporary files
tmp/
temp/
</file>

<file path=".prettierrc">
{
  "semi": true,
  "trailingComma": "es5",
  "singleQuote": true,
  "printWidth": 100,
  "tabWidth": 2,
  "useTabs": false,
  "endOfLine": "auto"
}
</file>

<file path="1">
* [32mmaster[m 0a2bc6c [[34morigin/master[m] Major project enhancements: Implement services layer, update tools, add REST API, and improve docs
</file>

<file path="dependencies.md">
# MCP Server Dependencies

This document lists all dependencies required to build the MCP server, including their versions, purposes, and documentation links.

## Core Dependencies

### Model Context Protocol SDK
- **Package**: `@modelcontextprotocol/sdk`
- **Version**: 1.2.0
- **Purpose**: Core SDK for implementing the Model Context Protocol
- **Documentation**: [MCP SDK Documentation](https://modelcontextprotocol.github.io/sdk/)
- **Installation**: `npm install @modelcontextprotocol/sdk@1.2.0`

### Perplexity API (Web Search)
- **Package**: `perplexity-api`
- **Version**: 1.1.2
- **Purpose**: Integration with Perplexity AI for web search functionality
- **Documentation**: [Perplexity API Documentation](https://docs.perplexity.ai/)
- **Installation**: `npm install perplexity-api@1.1.2`
- **Note**: Requires API key from Perplexity

### GitHub API Client
- **Package**: `@octokit/rest`
- **Version**: 19.0.13
- **Purpose**: GitHub API integration for repository management
- **Documentation**: [Octokit REST Documentation](https://octokit.github.io/rest.js/)
- **Installation**: `npm install @octokit/rest@19.0.13`
- **Note**: Requires GitHub Personal Access Token

### Browser Automation
- **Package**: `playwright`
- **Version**: 1.41.2
- **Purpose**: Browser automation for web interaction and testing
- **Documentation**: [Playwright Documentation](https://playwright.dev/docs/api/class-playwright)
- **Installation**: `npm install playwright@1.41.2`

### HTTP Client
- **Package**: `axios`
- **Version**: 1.6.5
- **Purpose**: Making HTTP requests to external APIs
- **Documentation**: [Axios Documentation](https://axios-http.com/docs/intro)
- **Installation**: `npm install axios@1.6.5`

### Environment Variables
- **Package**: `dotenv`
- **Version**: 16.3.1
- **Purpose**: Loading environment variables from .env files
- **Documentation**: [dotenv Documentation](https://github.com/motdotla/dotenv#readme)
- **Installation**: `npm install dotenv@16.3.1`

## Development Dependencies

### TypeScript
- **Package**: `typescript`
- **Version**: 5.3.3
- **Purpose**: Static typing and modern JavaScript features
- **Documentation**: [TypeScript Documentation](https://www.typescriptlang.org/docs/)
- **Installation**: `npm install --save-dev typescript@5.3.3`

### TypeScript Node
- **Package**: `ts-node`
- **Version**: 10.9.2
- **Purpose**: Running TypeScript files directly
- **Documentation**: [ts-node Documentation](https://typestrong.org/ts-node/docs/)
- **Installation**: `npm install --save-dev ts-node@10.9.2`

### Node.js Types
- **Package**: `@types/node`
- **Version**: 20.11.5
- **Purpose**: TypeScript type definitions for Node.js
- **Documentation**: [Node.js Types Package](https://www.npmjs.com/package/@types/node)
- **Installation**: `npm install --save-dev @types/node@20.11.5`

## Quick Install Commands

### Production Dependencies
```bash
npm install @modelcontextprotocol/sdk@1.2.0 perplexity-api@1.1.2 @octokit/rest@19.0.13 playwright@1.41.2 axios@1.6.5 dotenv@16.3.1
```

### Development Dependencies
```bash
npm install --save-dev typescript@5.3.3 ts-node@10.9.2 @types/node@20.11.5
```

## Environment Variables Required

Create a `.env` file in your project root with the following variables:
```env
# Required for web search functionality
PERPLEXITY_API_KEY=your_perplexity_api_key

# Required for GitHub integration (optional if only using public repos)
GITHUB_TOKEN=your_github_token

# Optional configuration
NODE_ENV=development
LOG_LEVEL=info
```

## Post-Installation Steps

1. **Initialize TypeScript Configuration**
   ```bash
   npx tsc --init
   ```

2. **Install Playwright Browsers**
   ```bash
   npx playwright install
   ```

3. **Create tsconfig.json**
   ```json
   {
     "compilerOptions": {
       "target": "ES2020",
       "module": "ESNext",
       "moduleResolution": "node",
       "esModuleInterop": true,
       "strict": true,
       "outDir": "./dist",
       "rootDir": "./src",
       "declaration": true
     },
     "include": ["src/**/*"],
     "exclude": ["node_modules", "dist"]
   }
   ```

## Version Management

- All dependencies use semantic versioning (MAJOR.MINOR.PATCH)
- Regular updates recommended for security patches
- Major version updates should be carefully tested for breaking changes

## Security Notes

- Keep API keys and tokens secure in `.env` file
- Add `.env` to `.gitignore`
- Regularly update dependencies for security patches
- Review security advisories for all dependencies

## Support and Resources

- MCP SDK Issues: [GitHub Issues](https://github.com/modelcontextprotocol/sdk/issues)
- Perplexity API Support: [Documentation](https://docs.perplexity.ai/support)
- Playwright Help: [Discord Community](https://playwright.dev/community/discord)
- TypeScript Questions: [Stack Overflow](https://stackoverflow.com/questions/tagged/typescript)
</file>

<file path="docs/web-search-tool.md">
# Web Search Tool Documentation

## Overview
The web search tool provides a way to perform web searches using the Perplexity AI API. It supports both production and test environments, with graceful fallbacks for testing scenarios.

## Configuration

### Environment Variables
- `PERPLEXITY_API_KEY` (optional in test environment): Your Perplexity AI API key
- `NODE_ENV`: The current environment ('development', 'production', or 'test')

### Test Environment
In test environment:
- If `PERPLEXITY_API_KEY` is not provided, the tool returns mock results
- If `PERPLEXITY_API_KEY` is provided, real API calls are made

## Usage

### Basic Search
```typescript
const result = await webSearchTool.execute({
    query: "Your search query"
});
```

### Save Results to File
```typescript
const result = await webSearchTool.execute({
    query: "Your search query",
    saveToFile: true
});
```

## Request Schema
```typescript
{
    query: string;      // Required, non-empty string
    saveToFile: boolean; // Optional, defaults to false
}
```

## Response Schema
```typescript
{
    searchResults: string;
    savedToFile?: string; // Present only when saveToFile is true
}
```

## Error Handling

The tool handles various error scenarios:

1. Configuration Errors:
   - Missing API key (in non-test environment)
   - Invalid API key

2. Request Validation:
   - Empty query
   - Invalid request format

3. API Errors:
   - Rate limiting (429)
   - Authentication errors (401/403)
   - Invalid response format
   - Network timeouts (10s default)

4. File System Errors:
   - Failed to create directory
   - Failed to write file
   - File system permissions

## Testing

The tool includes comprehensive tests covering:
- Mock response behavior
- API integration
- Error handling
- File saving functionality

See `__tests__/web-search.test.ts` for test examples.

## Logging

All operations are logged using the application logger:
- Info: Search operations
- Debug: File operations
- Warn: API response issues
- Error: Failed operations

## Best Practices

1. Always handle potential errors when using the tool
2. Use appropriate timeouts for your use case
3. Monitor rate limiting in production
4. Consider implementing retry logic for transient failures
5. Keep queries focused and specific for better results
</file>

<file path="how --name-only 0a2bc6cd30a666675e3a3477427bd0b6de333d3f">
[33mcommit 0a2bc6cd30a666675e3a3477427bd0b6de333d3f[m[33m ([m[1;36mHEAD[m[33m -> [m[1;32mmaster[m[33m, [m[1;31morigin/master[m[33m)[m
Author: FreshTechBro <oladotun.olatunji@gmail.com>
Date:   Tue Feb 25 12:52:15 2025 -0600

    Major project enhancements: Implement services layer, update tools, add REST API, and improve docs

 .cursor/rules/architecturemode.mdc                 |   24 [32m+[m
 .cursor/rules/plannermode.mdc                      |   11 [32m+[m
 .env.example                                       |    4 [32m+[m
 .repomix-output.txt                                | 2465 [32m++++++++++++++++++[m[31m--[m
 README.md                                          |  120 [32m+[m[31m-[m
 docs/web-search-tool.md                            |   97 [32m+[m
 jest.config.js                                     |    8 [32m+[m[31m-[m
 local-research/codebase-analysis.md                |  155 [32m++[m
 mcp-server/.env.example                            |    9 [32m+[m
 mcp-server/.eslintrc.json                          |   24 [32m+[m
 mcp-server/.gitignore                              |  Bin [31m66[m -> [32m142[m bytes
 mcp-server/.husky/pre-commit                       |    4 [32m+[m
 mcp-server/.prettierrc                             |    8 [32m+[m
 mcp-server/jest.config.js                          |   24 [32m+[m
 mcp-server/package.json                            |   17 [32m+[m[31m-[m
 .../tools/__tests__/web-search.test.ts             |    1 [32m+[m
 mcp-server/src/config/index.ts                     |    6 [32m+[m[31m-[m
 mcp-server/src/gemini/__tests__/service.test.ts    |  209 [32m++[m
 mcp-server/src/gemini/config.ts                    |   20 [32m+[m
 mcp-server/src/gemini/service.ts                   |  163 [32m++[m
 mcp-server/src/utils/retry.ts                      |   86 [32m+[m
 mcp-server/tsconfig.json                           |   36 [32m+[m[31m-[m
 package.json                                       |   18 [32m+[m[31m-[m
 .../tools/__tests__/web-search.test.ts             |  104 [32m+[m
 src/capabilities/tools/browser-automation.ts       |  183 [32m++[m
 src/capabilities/tools/repo-analysis.ts            |  407 [32m++++[m
 src/capabilities/tools/web-search.ts               |   96 [32m+[m[31m-[m
 src/config/index.ts                                |   25 [32m+[m[31m-[m
 src/resources/search-history.resource.ts           |  202 [32m++[m
 src/routes/search-history.routes.ts                |  246 [32m++[m
 src/server.ts                                      |   51 [32m+[m[31m-[m
 src/services/README.md                             |   38 [32m+[m
 src/services/browser.service.ts                    |  362 [32m+++[m
 src/services/file-storage.service.ts               |  139 [32m++[m
 src/services/gemini.service.ts                     |  127 [32m+[m
 src/services/perplexity.service.ts                 |  125 [32m+[m
 src/test-client.ts                                 |   64 [32m+[m[31m-[m
 src/test/setup.ts                                  |   20 [32m+[m
 src/types/tool.ts                                  |   10 [32m+[m
 tsconfig.json                                      |   12 [32m+[m[31m-[m
 40 files changed, 5435 insertions(+), 285 deletions(-)
</file>

<file path="how --name-only 0a2bc6cd30a666675e3a3477427bd0b6de333d3f ÔÅº Select-String -Pattern ÔÄ¢^[A-Za-z]ÔÄ¢ ÔÅº Select-Object -Skip 5">
[33mcommit 0a2bc6cd30a666675e3a3477427bd0b6de333d3f[m[33m ([m[1;36mHEAD[m[33m -> [m[1;32mmaster[m[33m, [m[1;31morigin/master[m[33m)[m
Author: FreshTechBro <oladotun.olatunji@gmail.com>
Date:   Tue Feb 25 12:52:15 2025 -0600

    Major project enhancements: Implement services layer, update tools, add REST API, and improve docs

A	.cursor/rules/architecturemode.mdc
A	.cursor/rules/plannermode.mdc
M	.env.example
M	.repomix-output.txt
M	README.md
A	docs/web-search-tool.md
M	jest.config.js
A	local-research/codebase-analysis.md
A	mcp-server/.env.example
A	mcp-server/.eslintrc.json
M	mcp-server/.gitignore
A	mcp-server/.husky/pre-commit
A	mcp-server/.prettierrc
A	mcp-server/jest.config.js
M	mcp-server/package.json
A	mcp-server/src/capabilities/tools/__tests__/web-search.test.ts
M	mcp-server/src/config/index.ts
A	mcp-server/src/gemini/__tests__/service.test.ts
A	mcp-server/src/gemini/config.ts
A	mcp-server/src/gemini/service.ts
A	mcp-server/src/utils/retry.ts
M	mcp-server/tsconfig.json
M	package.json
A	src/capabilities/tools/__tests__/web-search.test.ts
A	src/capabilities/tools/browser-automation.ts
A	src/capabilities/tools/repo-analysis.ts
M	src/capabilities/tools/web-search.ts
M	src/config/index.ts
A	src/resources/search-history.resource.ts
A	src/routes/search-history.routes.ts
M	src/server.ts
A	src/services/README.md
A	src/services/browser.service.ts
A	src/services/file-storage.service.ts
A	src/services/gemini.service.ts
A	src/services/perplexity.service.ts
M	src/test-client.ts
A	src/test/setup.ts
A	src/types/tool.ts
M	tsconfig.json
</file>

<file path="jest.config.js">
/** @type {import('ts-jest').JestConfigWithTsJest} */
export default {
  preset: 'ts-jest/presets/default-esm',
  testEnvironment: 'node',
  roots: ['<rootDir>/src'],
  testMatch: ['**/__tests__/**/*.ts', '**/?(*.)+(spec|test).ts'],
  transform: {
    '^.+\\.tsx?$': [
      'ts-jest',
      {
        useESM: true,
        tsconfig: 'tsconfig.json',
        isolatedModules: true,
      },
    ],
  },
  moduleNameMapper: {
    '^(\\.{1,2}/.*)\\.js$': '$1',
  },
  extensionsToTreatAsEsm: ['.ts'],
  testTimeout: 10000,
  // Temporarily commenting out the setup file
  // setupFilesAfterEnv: ['<rootDir>/src/test/jest.setup.ts'],
  coverageDirectory: 'coverage',
  collectCoverageFrom: [
    'src/**/*.ts',
    '!src/**/*.d.ts',
    '!src/**/*.test.ts',
    '!src/**/__tests__/**',
  ],
  coverageThreshold: {
    global: {
      branches: 80,
      functions: 80,
      lines: 80,
      statements: 80,
    },
  },
  transformIgnorePatterns: [
    "node_modules/(?!.*\\.mjs$)"
  ],
  globals: {}
};
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2024 freshtechbro

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="local-research/codebase-analysis.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, let's analyze the implementation of the MCP server and its tools, along with the dependencies.

**1. MCP Server Implementation (`src/server.ts`)**

The `src/server.ts` file serves as the entry point for the MCP server and sets up the core server functionalities. Here's a breakdown of its implementation:

*   **Server Initialization:**
    *   It imports the `Server` class from `@modelcontextprotocol/sdk/server/index.js` and `StdioServerTransport` from `@modelcontextprotocol/sdk/server/stdio.js`.
    *   It initializes a `Server` instance with metadata like `name`, `version`, and `description` from the `config` module.
    *   The `capabilities` option in the `Server` constructor is used to register resources and tools. Currently, it registers `web-search` and `repo-analysis` tools.
*   **Transport Layer:**
    *   It uses `StdioServerTransport` for communication. This transport is suitable for local execution and testing, as it uses standard input and output streams.
    *   The server connects to the transport using `server.connect(transport)`.
*   **Tool Registration:**
    *   The `capabilities.tools` object is used to register the `webSearchTool` and `repoAnalysisTool`. The keys (`'web-search'`, `'repo-analysis'`) are the tool names that clients will use to invoke these tools.
    *   A `health-check` tool is also registered, demonstrating a simple built-in tool for server status monitoring.
*   **Request Handling:**
    *   The server uses `setRequestHandler` to define how to handle incoming requests. It specifically handles requests matching the `ToolExecuteRequestSchema`.
    *   The `ToolExecuteRequestSchema` is defined using `zod` for schema validation, ensuring that incoming requests for tool execution adhere to a specific structure (`method`, `params` including `toolName`, `version`, and `arguments`).
    *   Inside the request handler, it retrieves the `toolName` from the request parameters and looks up the corresponding tool from the `tools` record.
    *   It then executes the `tool.execute(args)` function, passing the arguments from the request. The result of the tool's execution is returned as part of the response.
*   **Error Handling and Process Management:**
    *   **Uncaught Exceptions and Rejections:** The server sets up handlers for `uncaughtException` and `unhandledRejection` to log errors and terminate the process in case of unexpected errors. This is crucial for server stability.
    *   **Process Termination Signals:** Handlers for `SIGINT` and `SIGTERM` signals are set up to gracefully shut down the server upon receiving these signals.
    *   **Startup Error Handling:** The `main` function uses a `try...catch` block to handle potential startup errors and log them before exiting.
*   **Logging:**
    *   The server uses a `logger` module (likely a custom logger as seen in `src/utils/logger.ts`) for logging informational messages, debug messages, and errors. This is essential for monitoring and debugging the server's operation.
*   **Configuration Validation:**
    *   The server validates the configuration using `ServerConfigSchema.parse(config)` from the `config/index.ts` module. This ensures that the server is started with a valid configuration.

**Overall Implementation of MCP Server:**

The server implementation is well-structured and follows good practices:

*   **Modularity:**  It separates the core server logic from the tool implementations.
*   **Schema Validation:**  Uses `zod` for schema validation of requests and responses, ensuring data integrity and type safety.
*   **Error Handling:**  Robust error handling is implemented at multiple levels (request handling, startup, process termination).
*   **Logging:**  Comprehensive logging is integrated for monitoring and debugging.
*   **Configuration:**  Configuration is managed through a dedicated module and validated using schemas.
*   **MCP SDK Usage:** Correctly utilizes the `@modelcontextprotocol/sdk` for server setup and transport management.

**2. Tool Implementations**

Let's analyze the implementations of the `web-search` and `repo-analysis` tools.

**2.1. `web-search` Tool (`src/capabilities/tools/web-search.ts`)**

*   **Purpose:** This tool enables web searching using the Perplexity AI API.
*   **Functionality:**
    *   Takes a `query` string as input. Optionally, it can also take a `saveToFile` boolean flag.
    *   Uses `axios` to make HTTP requests to the Perplexity AI API (`PERPLEXITY_API_URL`).
    *   Authenticates with the Perplexity API using an API key (`PERPLEXITY_API_KEY`) loaded from environment variables via `dotenv`.
    *   Handles different environments (`test`, `production`, etc.) using `config.env`. In the `test` environment, if the API key is not provided, it returns mock results.
    *   Parses the API response to extract the search results from `response.data.choices[0].message.content`.
    *   If `saveToFile` is true, it saves the search results to a markdown file in the `local-research` directory.
    *   Implements error handling for API requests, including specific handling for Axios errors, API key issues (401, 403), and rate limits (429).
    *   Uses `zod` for request (`WebSearchRequestSchema`) and response (`WebSearchResponseSchema`) schema validation, ensuring that the tool receives and returns data in the expected format.
    *   Logs operations using the `logger` module, including search queries, API calls, saving to file, and errors.
*   **Request and Response Schemas:**
    *   `WebSearchRequestSchema`: Defines the expected structure for the tool's request, including `query` (required string) and `saveToFile` (optional boolean).
    *   `WebSearchResponseSchema`: Defines the structure of the tool's response, including `searchResults` (string) and `savedToFile` (optional string, path to saved file).

**2.2. `repo-analysis` Tool (`src/capabilities/tools/repo-analysis.ts`)**

*   **Purpose:** This tool analyzes code and documentation within a repository using Google Gemini.
*   **Functionality:**
    *   Takes a `query` (analysis question), `analysisType` (code, documentation, or both), `targetPath` (optional path to analyze within the repo), and `maxDepth` (directory depth for analysis) as input.
    *   Retrieves repository content using the `getRepositoryContent` function, which recursively reads files up to a specified depth.
    *   Uses `axios` to interact with the Google Gemini API.
    *   Authenticates with the Gemini API using an API key (`config.googleApiKey`).
    *   Caches analysis results in memory (`analysisCache`) to avoid redundant API calls for the same queries within a TTL (Time To Live) period.
    *   Constructs a detailed prompt for the Gemini API, including the query, analysis type, and retrieved repository content.
    *   Attempts to parse and structure the Gemini API response, though the parsing logic is noted as "TODO" in the code, currently returning a simplified structured response with a main analysis and placeholders for code and documentation insights.
    *   Implements error handling for file system operations (`fs.stat`, `fs.readdir`, `fs.readFile`) and Gemini API calls.
    *   Uses `zod` for request (`repoAnalysisRequestSchema`) and response (`repoAnalysisResponseSchema`) schema validation.
    *   Logs operations using the `logger` module, including API calls, cache usage, and errors.
*   **Request and Response Schemas:**
    *   `repoAnalysisRequestSchema`: Defines the request structure, including `query`, `analysisType`, `targetPath`, and `maxDepth`.
    *   `repoAnalysisResponseSchema`: Defines the response structure, including `analysis` (main analysis text), `codeInsights` (optional structured code insights), and `documentationInsights` (optional structured documentation insights).
*   **`getRepositoryContent` Function:**
    *   Recursively traverses a directory structure up to `maxDepth`.
    *   Reads file contents and adds them to a list of strings, prefixed with "File: <filepath>".
    *   Skips directories starting with `.` and `node_modules`.
    *   Includes basic error handling for file system operations.
*   **`analyzeWithGemini` Function:**
    *   Constructs a prompt for the Gemini API based on the query, analysis type, and repository content.
    *   Makes a POST request to the Gemini API endpoint using `axios`.
    *   Handles potential errors during API calls, including Axios errors.
    *   Returns a `GeminiAnalysis` interface object, currently with a simplified structure.

**Overall Tool Implementation:**

Both `web-search` and `repo-analysis` tools demonstrate good implementation practices:

*   **Schema Validation:**  Use `zod` for robust input and output validation.
*   **API Integration:** Properly integrate with external APIs (Perplexity and Gemini) using `axios`.
*   **Error Handling:**  Implement error handling for API calls, file system operations, and validation errors.
*   **Configuration Management:**  Utilize `config` module to access API keys and environment settings.
*   **Logging:**  Employ `logger` for detailed logging of tool operations and errors.
*   **Caching (`repo-analysis`):** Implement a caching mechanism to improve performance and reduce API calls for repository analysis.
*   **Modularity:** Tools are implemented as separate modules, making the codebase organized and maintainable.

**3. Dependency Analysis**

Let's review the dependencies used in the project, as listed in `package.json` and `dependencies.md` (though `dependencies.md` is from a different project version and might be outdated, `package.json` is the source of truth).

**Dependencies (from `package.json`):**

*   **Core MCP SDK:**
    *   `@modelcontextprotocol/sdk: "1.2.0"`: The core SDK for implementing the Model Context Protocol. Essential for building the MCP server and client.
*   **AI API Clients:**
    *   `@google/generative-ai: "^0.22.0"`: Google Generative AI SDK, used for interacting with the Gemini API in the `repo-analysis` tool.
    *   `axios: "1.6.5"`: HTTP client for making requests to Perplexity and Gemini APIs.
*   **Utility Libraries:**
    *   `dotenv: "16.3.1"`: Loads environment variables from `.env` files, used for managing API keys and configuration.
    *   `zod: "^3.24.2"`: Schema validation library, used for defining and validating request and response schemas for tools and server configuration.
*   **Browser Automation (Potentially for future tools, not directly used in analyzed tools but included in project dependencies):**
    *   `playwright: "1.41.2"`: Browser automation library, included in dependencies, suggesting potential future browser-based tools (as indicated in the initial `cursor-tools Integration` description).
*   **GitHub API Client (Potentially for future tools, not directly used in analyzed tools but included in project dependencies):**
    *   `@octokit/rest: "19.0.13"`: GitHub API client, also included, hinting at possible future GitHub integration tools (as also suggested by `cursor-tools Integration`).

**Development Dependencies (from `package.json`):**

*   **TypeScript and related tools:**
    *   `typescript: "5.3.3"`: TypeScript compiler.
    *   `ts-node: "10.9.2"`: Allows running TypeScript files directly in Node.js, useful for development.
    *   `@types/node: "20.11.5"`: TypeScript type definitions for Node.js APIs.
*   **Testing:**
    *   `jest: "^29.7.0"`: JavaScript testing framework.
    *   `@types/jest: "^29.5.11"`: TypeScript type definitions for Jest.
    *   `ts-jest: "^29.1.2"`: TypeScript preprocessor for Jest, allowing testing of TypeScript code directly.
    *   `cross-env: "^7.0.3"`: Cross-platform environment variable setting for test scripts.
*   **Linting and Formatting:**
    *   `eslint`, `@typescript-eslint/*`, `eslint-config-prettier`, `eslint-plugin-prettier`, `prettier`:  For code linting and formatting, ensuring code quality and consistency.
*   **Git Hooks:**
    *   `husky: "^8.0.3"`: Git hooks manager, likely used to run linters and formatters before commits.
    *   `lint-staged: "^15.2.0"`: Runs linters only on staged files for faster feedback.
*   **Utility:**
    *   `rimraf: "^5.0.5"`:  Utility for deleting directories recursively, used in build scripts (`clean` script).
*   **Cursor Tools (for Integration Testing/Example):**
    *   `cursor-tools: "latest"`: Inclusion of `cursor-tools` suggests it might be used for integration testing or as an example of how the MCP server could be used with a client like `cursor-tools`.

**Overall Dependency Analysis:**

The project utilizes a well-chosen set of dependencies:

*   **Essential Dependencies:** Includes the core MCP SDK and necessary libraries for API communication, configuration management, and schema validation.
*   **Development Focused:**  Includes a comprehensive set of development dependencies for TypeScript compilation, testing, linting, and formatting, indicating a focus on code quality and developer experience.
*   **Potential Future Features:** The inclusion of `playwright` and `@octokit/rest` suggests planned expansions to browser automation and GitHub integration functionalities, aligning with the initial feature set of `cursor-tools`.

**Summary of Implementation and Dependencies:**

The MCP server and tools are implemented in a modular, well-structured, and robust manner. They leverage appropriate libraries and follow best practices for error handling, logging, and configuration. The project is set up with a strong focus on code quality, testability, and potential future extensibility. The choice of dependencies is sensible and supports the intended functionalities of the MCP server and its tools.
</file>

<file path="local-research/cursor-tools-analysis.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, let's analyze the `cursor-tools` integration description provided and map its features to an MCP server context.

**Cursor-Tools Architecture and Features Analysis for MCP Replication**

`cursor-tools` appears to be a command-line tool designed to provide AI assistance within a coding environment (like Cursor IDE, presumably, given the name). It leverages various AI models and external tools through a set of commands.  The core architecture seems to be a command dispatcher that routes user commands to specific functionalities, interacting with different services (Perplexity, Gemini, GitHub API, Playwright).

Here's a breakdown of `cursor-tools` features and how they can be viewed from an MCP perspective:

**1. Web Search (`cursor-tools web`)**

*   **Functionality:**  Performs web searches using Perplexity AI and returns answers. Can suggest writing output to a file.
*   **Input:**  Search query (string). Options: `--model`, `--max-tokens`, `--save-to`, `--help`.
*   **Output:**  Search results (text, potentially markdown).
*   **Underlying Tech:** Perplexity AI API.
*   **MCP Mapping:**
    *   **MCP Resource:**  Could be modeled as a `web-search-result` resource type.
        *   `list` capability:  Might not be directly applicable.
        *   `read` capability:  Could take a search query as input and return the search results. The URI could be dynamically generated based on the query (e.g., `web-search-result://<query-hash>`).
    *   **MCP Tool:**  Alternatively, or additionally, a `web-search` tool.
        *   `execute` capability: Takes a search query as input and returns the search results.

**2. Repository Context (`cursor-tools repo`)**

*   **Functionality:**  Provides context-aware answers about the current repository using Google Gemini.
*   **Input:**  Question (string). Options: `--model`, `--max-tokens`, `--save-to`, `--help`.
*   **Output:**  Contextual answer (text).
*   **Underlying Tech:** Google Gemini API, likely with repository content indexing.
*   **MCP Mapping:**
    *   **MCP Resource:**  Perhaps a `repository-context` resource.
        *   `read` capability:  Takes a question as input, provides context-aware answer. URI could be generic like `repository-context://current`.
    *   **MCP Tool:**  A `repository-query` tool might be more appropriate.
        *   `execute` capability: Takes a question as input related to the repository, returns an answer.

**3. Documentation Generation (`cursor-tools doc`)**

*   **Functionality:**  Generates documentation for a repository. Supports local and remote (GitHub) repositories.
*   **Input:** Options: `--output`, `--from-github`.
*   **Output:**  Documentation (markdown, potentially other formats if configurable).
*   **Underlying Tech:** Code parsing and documentation generation logic (potentially leveraging AI for summarization and structuring).
*   **MCP Mapping:**
    *   **MCP Tool:**  Definitely a `generate-documentation` tool.
        *   `execute` capability:  Takes repository location (local path or GitHub URL) and output options as input, returns the generated documentation (or a URI to the generated documentation file).

**4. GitHub Information (`cursor-tools github pr`, `cursor-tools github issue`)**

*   **Functionality:**  Retrieves GitHub PRs and issues, either last 10 or specific by number. Supports specifying a repository via `--from-github`.
*   **Input:**  `pr` or `issue` command, optional number, `--from-github` option.
*   **Output:**  PR/Issue details (text, likely formatted).
*   **Underlying Tech:** GitHub API.
*   **MCP Mapping:**
    *   **MCP Resource:** `github-pull-request` and `github-issue` resource types.
        *   `list` capability (for last 10): Returns a list of PR/Issue summaries.
        *   `read` capability (for specific number): Takes PR/Issue number as input, returns detailed information. URI would be like `github-pull-request://<repo>/<pr-number>`.

**5. Browser Automation (`cursor-tools browser open`, `cursor-tools browser act`, `cursor-tools browser observe`, `cursor-tools browser extract`)**

*   **Functionality:**  Automates browser interactions, captures page content, console logs, network activity, and extracts data. Stateless browser instances. Supports actions through natural language instructions and multi-step workflows.
*   **Input:**  URL, instruction (for `act`, `observe`, `extract`), options: `--html`, `--console`, `--network`, `--screenshot`, `--timeout`, `--viewport`, `--headless`, `--no-headless`, `--connect-to`, `--wait`, `--video`.
*   **Output:**  Page content (HTML), console logs, network activity, screenshots, extracted data (depending on the command and options).
*   **Underlying Tech:** Playwright (browser automation library).
*   **MCP Mapping:**
    *   **MCP Tool:**  A suite of browser automation tools.
        *   `browser-open`: `execute` capability, takes URL and options, returns initial browser state (maybe a session ID if state was managed, but `cursor-tools` is stateless, so likely just success/failure).
        *   `browser-act`: `execute` capability, takes URL, instruction string, and options, performs actions and returns the result of actions (maybe updated page content or action success).
        *   `browser-observe`: `execute` capability, takes URL, instruction, and options, returns observed elements and suggested actions.
        *   `browser-extract`: `execute` capability, takes URL, extraction instruction, and options, returns extracted data.
    *   **MCP Resource:**  Less clear if browser automation is a resource. Maybe a `browser-page` resource, but tools seem more fitting for actions.

**General Command Options (`--model`, `--max-tokens`, `--save-to`, `--help`)**

*   **MCP Mapping:** These are likely server-level configurations or request parameters.
    *   `--model`, `--max-tokens`:  Could be request parameters for tools that use AI models.
    *   `--save-to`: Could be a general output handling feature, maybe less directly MCP related, more about client-side behavior.
    *   `--help`:  Server introspection capabilities in MCP could expose command help (though not explicitly defined in MCP spec, server info can be exposed).


**Replicating Cursor-Tools Features in an MCP Server**

To replicate `cursor-tools` functionality in an MCP server, you would need to:

1.  **Choose a Programming Language:** Node.js is a strong choice because the MCP SDK example is in Node.js, and `cursor-tools` likely uses Node.js as well, given the npm commands for installation.

2.  **Use MCP SDK:** Utilize the `@modelcontextprotocol/sdk` (Node.js version) to handle MCP protocol details, message parsing, schema validation, and transport layers.

3.  **Implement Resource and Tool Providers:** For each `cursor-tools` command category, create corresponding MCP resource and/or tool providers.

    *   **Web Search:** Integrate with Perplexity AI API within a `web-search` tool provider. Handle API calls, result formatting, and schema definition for requests (search query) and responses (search results).
    *   **Repository Context:**  Integrate with Google Gemini API within a `repository-query` tool provider. You'll need to handle repository content access and indexing to provide context. This is likely the most complex part, as it requires understanding the repository structure.  Alternatively, you could simplify this initially to just use Gemini for general code-related questions *without* specific repository context, and then enhance it later.
    *   **Documentation Generation:** Implement a `generate-documentation` tool provider. This would involve code parsing (using libraries for different languages), documentation generation logic (potentially using tools like JSDoc for JavaScript, or similar for other languages, or even AI-based documentation summarization), and handling output formatting.
    *   **GitHub Information:** Create `github-pull-request` and `github-issue` resource providers. Use the GitHub API to fetch PR and issue data. Implement `list` and `read` capabilities according to the MCP resource model.
    *   **Browser Automation:** Implement a suite of browser tools (`browser-open`, `browser-act`, `browser-observe`, `browser-extract`).  Integrate with Playwright within these tool providers.  Carefully consider how to manage the stateless nature of `cursor-tools` browser commands in an MCP context.  Each tool execution might start a new Playwright browser instance.

4.  **Define Schemas:**  Crucially, define MCP schemas for all requests and responses for your resources and tools. This ensures type safety and proper data exchange between the client and server, as per MCP best practices.  Look at the schema examples provided in the `mcp-plan.md` for guidance.

5.  **Transport Layer:** Start with `stdio` transport for initial development and testing, as it's simpler.  Later, add HTTP/SSE transport for network accessibility.

6.  **Error Handling and Logging:** Implement robust error handling in your resource and tool providers. Return MCP-compliant error responses. Implement logging for debugging and monitoring.

7.  **Documentation for your MCP Server:**  Provide clear documentation for your MCP server, explaining the resources and tools it offers, how to use them, and how to set up and run the server.

**Simplified First Steps (Beginner-Friendly Approach):**

To start simpler, you could initially focus on implementing a subset of `cursor-tools` features as MCP resources and tools. For example:

*   **Start with `stdio` transport.**
*   **Implement the `web-search` tool.** This is relatively self-contained and demonstrates tool execution.
*   **Implement the `github-pull-request` resource (just `list` capability initially).**  This shows resource listing and interaction with an external API.
*   **Skip browser automation and repository context initially**, as these are more complex.
*   **Focus on clear schemas and basic error handling.**

By building these core features first, you can get a working MCP server and gradually expand its capabilities to more closely resemble `cursor-tools`.  Remember to prioritize clear, beginner-friendly design and documentation throughout the development process, as emphasized in the research documents.
</file>

<file path="local-research/cursor-tools-implementation.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Here's how we can implement the web search, repo search, and browser automation features from `cursor-tools` in our MCP server, along with dependencies, APIs, and server structure considerations:

**1. Feature Implementation in MCP Server:**

*   **Web Search (`cursor-tools web`)**
    *   **MCP Tool:** Implement this as an MCP tool, let's name it `web-search`.
    *   **Capability:**  It will have an `execute` capability.
    *   **Request Schema:**  The request schema for `execute` will include a `query` parameter (string) for the search term.
    *   **Response Schema:** The response schema will include a `results` parameter (string, or potentially a more structured object) containing the search results. We can initially return plain text results and later enhance it to markdown or a structured format.
    *   **Implementation Logic:** Inside the `execute` handler for the `web-search` tool:
        1.  Take the `query` from the request.
        2.  Use the Perplexity AI API to perform the web search.
        3.  Format the results into the response schema.
        4.  Return the response.

*   **Repository Context Search (`cursor-tools repo`)**
    *   **MCP Tool:** Implement this as an MCP tool, let's name it `repo-query` or `repository-context-query`.
    *   **Capability:** It will have an `execute` capability.
    *   **Request Schema:** The request schema for `execute` will include a `query` parameter (string) for the question about the repository.
    *   **Response Schema:** The response schema will include an `answer` parameter (string) containing the context-aware answer.
    *   **Implementation Logic:** Inside the `execute` handler for the `repo-query` tool:
        1.  Take the `query` from the request.
        2.  **Repository Context Acquisition:** This is the most complex part.  We need to figure out how to get the "repository context."  For a basic implementation, we might initially skip deep repository context and just use Gemini for general code-related questions.  For more advanced context:
            *   **Option 1 (Simplified):**  Assume the MCP server is running within a repository directory.  The "context" is the files within that directory. We could potentially feed the contents of all files in the repository to Gemini for context. This is computationally expensive and might have token limits.
            *   **Option 2 (More realistic, but complex):**  Implement repository indexing. This would involve:
                *   Parsing code files in the repository.
                *   Creating an index of code elements (functions, classes, variables, comments, etc.).
                *   Using this index to provide context to Gemini based on the user's query.  This would likely require a vector database or similar technology for efficient semantic search within the code index.
                *   For now, let's focus on the simplified approach (Option 1) or even just general code questions without *specific* repo context.
        3.  Use the Google Gemini API, providing the user's `query` and the acquired repository context (or just the query for the simplified version).
        4.  Format Gemini's response into the `answer` parameter in the response schema.
        5.  Return the response.

*   **Browser Automation (`cursor-tools browser ...`)**
    *   **MCP Tool Suite:** Implement a suite of MCP tools, mirroring the `cursor-tools browser` commands: `browser-open`, `browser-act`, `browser-observe`, `browser-extract`.
    *   **Capabilities:** Each tool will have an `execute` capability.
    *   **Request Schemas:**
        *   `browser-open/execute`:  Request schema will include `url` (string) and options like `html`, `console`, `network`, `screenshot`, `timeout`, `viewport`, `headless`.
        *   `browser-act/execute`, `browser-observe/execute`, `browser-extract/execute`: Request schema will include `url` (string), `instruction` (string), and options like `html`, `console`, `network`, `screenshot`, `timeout`, `viewport`, `headless`.
    *   **Response Schemas:** The response schemas will depend on the command and options chosen. They could include:
        *   `htmlContent` (string): Page HTML.
        *   `consoleLogs` (array of strings): Browser console logs.
        *   `networkActivity` (object or array): Network request/response data.
        *   `screenshotPath` (string): Path to the saved screenshot.
        *   `extractedData` (object or array): Extracted data from the page.
    *   **Implementation Logic:**  For each browser tool's `execute` handler:
        1.  Take the `url`, `instruction` (if applicable), and options from the request.
        2.  Use Playwright to:
            *   Launch a new browser instance (stateless, as in `cursor-tools`).
            *   Navigate to the `url`.
            *   Perform actions based on the `instruction` (for `act`), observe elements (for `observe`), or extract data (for `extract`).
            *   Capture HTML, console logs, network activity, screenshot as requested by options.
        3.  Format the output (HTML, logs, data, etc.) into the response schema.
        4.  Close the browser instance.
        5.  Return the response.

**2. Key Dependencies and APIs:**

*   **Web Search (`web-search` tool):**
    *   **Dependency:**  An HTTP client library for Node.js (like `node-fetch` or `axios`).
    *   **API:** Perplexity AI API. You'll need an API key from Perplexity AI.

*   **Repository Context Search (`repo-query` tool):**
    *   **Dependency:** An HTTP client library.
    *   **API:** Google Gemini API. You'll need a Google Cloud API key with access to the Gemini API.
    *   **Optional (for advanced context):** Libraries for code parsing and indexing (language-specific parsers, vector database like Pinecone or Weaviate).  Initially, we can skip this complexity.

*   **Browser Automation (`browser-*` tools):**
    *   **Dependency:** `playwright` npm package.  This is essential for browser automation.

*   **MCP Server Core:**
    *   **Dependency:** `@modelcontextprotocol/sdk` (Node.js SDK) - already included in the plan.

**3. Server Structure for Efficient Request Handling:**

To structure the server effectively, we should use a modular approach as outlined in the `mcp-plan.md`.  Here's a suggested structure:

*   **`server.js` (or `index.js`):**
    *   Main server entry point.
    *   Initializes the MCP `Server` instance.
    *   Sets up the `stdio` (and potentially HTTP/SSE) transport.
    *   Registers all resource and tool providers.
    *   Starts the server.

*   **`capabilities/` directory:**
    *   **`resources/` directory (initially empty or for future resources):**  Place resource provider modules here if we decide to implement any MCP resources in the future.  For now, we are focusing on tools.
    *   **`tools/` directory:**
        *   **`web-search.js`:** Module containing the implementation for the `web-search` tool (including the `execute` handler and Perplexity API interaction).
        *   **`repo-query.js`:** Module for the `repo-query` tool (including the `execute` handler and Gemini API interaction, and repository context logic).
        *   **`browser-automation/` directory:**
            *   **`browser-open.js`:** Module for the `browser-open` tool.
            *   **`browser-act.js`:** Module for the `browser-act` tool.
            *   **`browser-observe.js`:** Module for the `browser-observe` tool.
            *   **`browser-extract.js`:** Module for the `browser-extract` tool.
            *   **(Potentially) `browser-utils.js`:**  A utility module for shared Playwright browser setup and teardown logic across browser tools.

*   **`schemas/` directory:**
    *   Define JSON schemas for all requests and responses for resources and tools.  For example:
        *   `web-search-request.json`
        *   `web-search-response.json`
        *   `repo-query-request.json`
        *   `repo-query-response.json`
        *   `browser-open-request.json`
        *   `browser-open-response.json`
        *   ... and so on for other browser tools.

*   **`config/` directory (optional):**
    *   `config.js` or `.env` file to store API keys (Perplexity, Gemini), and other server configuration.  Use environment variables for API keys for security.

**Request Handling Efficiency:**

*   **Asynchronous Operations:** All API calls (Perplexity, Gemini, Playwright) are asynchronous. Use `async/await` throughout the handlers to ensure non-blocking operations. This is crucial for server responsiveness.
*   **Stateless Tool Implementations:** The browser automation tools are designed to be stateless, which simplifies concurrency. Each tool execution starts a new browser instance and closes it.  This inherently helps with handling concurrent requests.
*   **Modular Design:** The modular structure makes it easier to manage and maintain the code, and to potentially optimize individual tool implementations without affecting others.
*   **Error Handling:** Implement robust error handling in each tool handler. Return MCP-compliant error responses to the client. Log errors for debugging.
*   **Resource Management (Playwright):**  Be mindful of Playwright browser instance management, especially if there are many concurrent browser automation requests.  While statelessness helps, consider resource limits if needed in a high-load scenario.

**Simplified First Steps:**

To make this beginner-friendly, start by implementing:

1.  **`web-search` tool:** This is relatively self-contained and good for demonstrating tool execution.
2.  **Basic `repo-query` tool (without deep repository context):**  Focus on just passing the user's query to Gemini for general code/programming questions.  Skip the complex repository indexing for now.
3.  **`browser-open` tool:**  Implement a simple `browser-open` tool to open a URL and maybe capture a screenshot.  This will introduce Playwright integration.

Gradually expand to other browser tools and then consider adding more sophisticated repository context features and resources as you progress. Remember to define schemas for all requests and responses as you build out the functionality for type safety and clarity.
</file>

<file path="local-research/dependencies-installation-guide.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...

# MCP Server Dependencies Installation Guide

This guide provides step-by-step instructions for installing and configuring all dependencies required for the MCP server project.

## Prerequisites

1. **Node.js and npm**
   ```bash
   # Check if Node.js is installed
   node --version  # Should be v14 or later
   npm --version   # Should be v6 or later
   
   # If not installed, download from https://nodejs.org/
   ```

2. **Git**
   ```bash
   # Check if Git is installed
   git --version
   
   # If not installed, download from https://git-scm.com/
   ```

## Project Setup

1. **Create Project Directory**
   ```bash
   mkdir mcp-server
   cd mcp-server
   ```

2. **Initialize Git Repository**
   ```bash
   git init
   ```

3. **Create .gitignore**
   ```bash
   echo "node_modules/
   dist/
   .env
   *.log" > .gitignore
   ```

## Core Dependencies Installation

### 1. Model Context Protocol SDK
```bash
# Install MCP SDK
npm install @modelcontextprotocol/sdk@1.2.0

# Verify installation
npm list @modelcontextprotocol/sdk
```

### 2. Perplexity API
```bash
# Install Perplexity API client
npm install perplexity-api@1.1.2

# Verify installation
npm list perplexity-api
```

### 3. GitHub API Client (Octokit)
```bash
# Install Octokit REST
npm install @octokit/rest@19.0.13

# Verify installation
npm list @octokit/rest
```

### 4. Playwright (Browser Automation)
```bash
# Install Playwright
npm install playwright@1.41.2

# Install browser binaries
npx playwright install

# Install supported browsers (chromium, firefox, webkit)
npx playwright install-deps

# Verify installation
npx playwright --version
```

### 5. Axios (HTTP Client)
```bash
# Install Axios
npm install axios@1.6.5

# Verify installation
npm list axios
```

### 6. Dotenv (Environment Variables)
```bash
# Install dotenv
npm install dotenv@16.3.1

# Verify installation
npm list dotenv

# Create .env file
touch .env
```

## Development Dependencies Installation

### 1. TypeScript
```bash
# Install TypeScript
npm install --save-dev typescript@5.3.3

# Initialize TypeScript configuration
npx tsc --init

# Verify installation
npx tsc --version
```

### 2. TypeScript Node
```bash
# Install ts-node
npm install --save-dev ts-node@10.9.2

# Verify installation
npx ts-node --version
```

### 3. Node.js Types
```bash
# Install Node.js types
npm install --save-dev @types/node@20.11.5

# Verify installation
npm list @types/node
```

## Configuration Files Setup

### 1. TypeScript Configuration (tsconfig.json)
```bash
# Create tsconfig.json with recommended settings
cat > tsconfig.json << EOL
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "moduleResolution": "node",
    "esModuleInterop": true,
    "strict": true,
    "outDir": "./dist",
    "rootDir": "./src",
    "declaration": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
EOL
```

### 2. Environment Variables (.env)
```bash
# Create .env file with required variables
cat > .env << EOL
# Required for web search functionality
PERPLEXITY_API_KEY=your_perplexity_api_key

# Required for GitHub integration
GITHUB_TOKEN=your_github_token

# Optional configuration
NODE_ENV=development
LOG_LEVEL=info
EOL
```

### 3. Package.json Scripts
```bash
# Add useful scripts to package.json
npm pkg set scripts.build="tsc"
npm pkg set scripts.start="node dist/server.js"
npm pkg set scripts.dev="ts-node src/server.ts"
npm pkg set scripts.test="echo \"No tests specified\" && exit 1"
```

## Project Structure Setup
```bash
# Create source directory
mkdir src

# Create directories for capabilities
mkdir -p src/capabilities/resources
mkdir -p src/capabilities/tools

# Create directories for utilities
mkdir -p src/utils
mkdir -p src/config
```

## Verification Steps

1. **Verify All Dependencies**
   ```bash
   npm list
   ```

2. **Verify TypeScript Setup**
   ```bash
   # Create a test TypeScript file
   echo "console.log('TypeScript is working!')" > src/test.ts
   
   # Try compiling it
   npx tsc
   ```

3. **Verify Playwright Setup**
   ```bash
   # Run Playwright test
   npx playwright --version
   ```

## Troubleshooting

### Common Issues and Solutions

1. **Node Version Mismatch**
   ```bash
   # Check Node.js version
   node --version
   
   # If needed, install nvm and switch version
   nvm install 14
   nvm use 14
   ```

2. **Permission Issues**
   ```bash
   # If npm install fails with permission errors
   sudo npm install -g npm@latest  # On Linux/macOS
   # Or run PowerShell as Administrator on Windows
   ```

3. **Playwright Browser Installation Issues**
   ```bash
   # If browser installation fails
   npx playwright install --force
   ```

4. **TypeScript Configuration Issues**
   ```bash
   # Reset TypeScript configuration
   rm tsconfig.json
   npx tsc --init
   ```

### Dependency Version Conflicts

If you encounter version conflicts:
1. Clear npm cache: `npm cache clean --force`
2. Delete node_modules: `rm -rf node_modules`
3. Delete package-lock.json: `rm package-lock.json`
4. Reinstall dependencies: `npm install`

## Post-Installation Verification

Create a simple test file to verify all major dependencies:

```typescript
// src/test-setup.ts
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { chromium } from 'playwright';
import { Octokit } from '@octokit/rest';
import axios from 'axios';
import dotenv from 'dotenv';

async function testSetup() {
  try {
    // Test MCP SDK
    const server = new Server({
      name: "test-server",
      version: "1.0.0"
    }, {
      capabilities: {}
    });
    console.log('‚úÖ MCP SDK working');

    // Test Playwright
    const browser = await chromium.launch();
    await browser.close();
    console.log('‚úÖ Playwright working');

    // Test Octokit
    const octokit = new Octokit();
    console.log('‚úÖ Octokit working');

    // Test Axios
    await axios.get('https://api.github.com');
    console.log('‚úÖ Axios working');

    // Test dotenv
    dotenv.config();
    console.log('‚úÖ dotenv working');

  } catch (error) {
    console.error('‚ùå Setup test failed:', error);
  }
}

testSetup();
```

Run the test:
```bash
npx ts-node src/test-setup.ts
```

## Next Steps

After successful installation:
1. Set up your API keys in `.env`
2. Start implementing your MCP server
3. Run the verification test
4. Begin development using `npm run dev`
</file>

<file path="local-research/dependencies-research.md">
Querying Perplexity AI using sonar-pro for: List all dependencies needed to build an MCP server, including the Model Context Protocol SDK, web search (Perplexity), GitHub integration, browser automation (Playwright), and any utility libraries. For each dependency, provide the latest stable version and documentation URL.
Here's a list of dependencies for building an MCP server with the specified features:

1. @modelcontextprotocol/sdk: v1.2.0
   https://modelcontextprotocol.io/docs/sdk/

2. perplexity-api: v1.1.2
   https://docs.perplexity.ai/

3. @octokit/rest: v19.0.13
   https://octokit.github.io/rest.js/

4. playwright: v1.41.2
   https://playwright.dev/docs/api/class-playwright

5. axios: v1.6.5
   https://axios-http.com/docs/intro

6. dotenv: v16.3.1
   https://github.com/motdotla/dotenv#readme

7. typescript: v5.3.3
   https://www.typescriptlang.org/docs/

8. ts-node: v10.9.2
   https://typestrong.org/ts-node/docs/

9. @types/node: v20.11.5
   https://www.npmjs.com/package/@types/node

These versions are the latest stable as of February 2025. Install using:

```bash
npm install @modelcontextprotocol/sdk@1.2.0 perplexity-api@1.1.2 @octokit/rest@19.0.13 playwright@1.41.2 axios@1.6.5 dotenv@16.3.1
npm install --save-dev typescript@5.3.3 ts-node@10.9.2 @types/node@20.11.5
```

Query: Write a TypeScript code for an MCP server that implements tools for web search using Perplexity API, GitHub repository management, and browser automation with Playwright. Include error handling and proper typing.
</file>

<file path="local-research/grok-enhancements">
# Developer Tools Project - Current Status and Improvements Needed

## Project Status Overview (Updated: July 24, 2023)

This document tracks the progress and remaining tasks for the Developer Tools project that implements an MCP server with various tools and resources.

## Current Implementation Progress

The project has made significant progress in implementing the core architecture and features:

‚úÖ **Core Infrastructure**:
- Basic MCP server setup with stdio transport
- Configuration system with environment variable support
- Logger system for debugging and monitoring
- Error handling infrastructure

‚úÖ **Implemented Tools**:
- `web-search` tool with Perplexity AI integration
- `repo-analysis` tool with Google Gemini integration (partial)
- Browser automation fundamentals

‚úÖ **Implemented Resources**:
- GitHub PR resource (implementation and unit tests in progress)
- File storage service for caching

‚úÖ **Utilities**:
- Rate limiter implementation
- File storage services
- Schema validation with Zod

‚úÖ **Testing Framework**:
- Jest configuration
- Test client for end-to-end testing
- Unit test examples for key components
- GitHub PR resource test improvements

## Implementation Tracker

Use this tracker to monitor remaining implementation tasks:

### Phase 1: Core Infrastructure
- [x] Basic MCP server setup
- [x] Configuration management system
- [x] Logging system
- [x] Error handling
- [ ] HTTP/SSE Transport (30% complete)
- [ ] Simple web interface for interactive testing

### Phase 2: Tool Implementation
- [x] Web search tool (Perplexity AI)
- [x] Repository analysis tool (80% complete)
- [ ] Browser automation tools (50% complete)
  - [ ] Browser open
  - [ ] Browser act
  - [ ] Browser observe
  - [ ] Browser extract
- [ ] Documentation generation tool (20% complete)

### Phase 3: Resource Implementation
- [x] GitHub PR resource (80% complete)
  - [x] List PRs functionality
  - [x] Get PR details
  - [ ] Additional PR operations
- [ ] GitHub issues resource (0% complete)
- [ ] Repository resource (30% complete)

### Phase 4: Testing
- [x] Basic unit tests for web-search
- [x] Unit tests for GitHub PR resource
- [ ] Integration tests for all tools
- [ ] Comprehensive error handling tests
- [ ] Edge case testing
- [ ] Performance testing

### Phase 5: Security & Scalability
- [x] Basic input validation
- [x] Environment variable security
- [ ] TLS support for HTTP transport
- [ ] Authentication for multi-user access
- [ ] Advanced rate limiting across all tools
- [ ] Load balancing planning

### Phase 6: Documentation & User Experience
- [ ] Comprehensive README updates
- [ ] Tool usage documentation
- [ ] API documentation
- [ ] Troubleshooting guide
- [ ] Deployment guide
- [ ] Code comments and inline documentation

## Key Improvements Needed

Based on the current state, these improvements are necessary to complete the project:

1. **HTTP/SSE Transport Enhancement**:
   - Complete implementation of HTTP transport for remote access
   - Add SSE transport for real-time updates
   - Implement proper TLS configuration
   - Create a simple web interface for testing

2. **Rate Limiting Refinement**:
   - Ensure consistent rate limiting across all API-dependent tools
   - Make limits configurable through environment variables
   - Add monitoring and alerting for rate limit issues

3. **Testing Coverage Expansion**:
   - Complete GitHub PR resource tests (in progress)
   - Add tests for all remaining tools and resources
   - Implement integration tests for end-to-end workflows
   - Test error scenarios thoroughly

4. **Security Enhancements**:
   - Add TLS support for all remote connections
   - Implement authentication for multi-user scenarios
   - Enhance input validation across all endpoints
   - Add security headers for HTTP transport

5. **Documentation Expansion**:
   - Complete README with setup and usage instructions
   - Document all tools and resources with examples
   - Add troubleshooting and deployment guides
   - Ensure code comments for maintainability

6. **Advanced Features Implementation**:
   - Complete all browser automation tools
   - Enhance GitHub resource capabilities
   - Add documentation generation features
   - Implement repository analysis improvements

7. **Scalability Improvements**:
   - Ensure stateless design throughout
   - Plan for horizontal scaling
   - Implement efficient resource management
   - Add performance monitoring

8. **Browser Automation Enhancement**:
   - Complete implementation of all browser commands
   - Add video recording capabilities
   - Improve error handling for browser interactions
   - Support multi-step browser workflows

9. **Caching Strategy**:
   - Implement efficient caching for API responses
   - Add cache invalidation mechanisms
   - Support persistent cache for frequent queries

10. **User Experience Improvements**:
    - Add progress reporting for long-running operations
    - Improve error messages for better debugging
    - Create interactive examples for common tasks
    - Add command completion suggestions

## Status Update Policy

To maintain project momentum and clarity, the following update policy is now in effect:

1. **Regular Status Updates**: This document must be updated at least once per week, or whenever significant progress is made on any component.

2. **Update Requirements**:
   - Update the "Current Implementation Progress" section with completed items
   - Check off completed tasks in the Implementation Tracker
   - Adjust completion percentages for partially completed tasks
   - Note any new challenges or blockers encountered
   - Update the "Key Improvements Needed" section with refined requirements

3. **Update Ownership**: Each team member implementing features is responsible for updating this document after completing significant work.

4. **Version History**: Maintain a brief changelog at the bottom of this document noting when updates were made and by whom.

5. **Review Process**: The status document should be reviewed during team meetings to ensure alignment on priorities and next steps.

## Version History

- Initial creation: Based on project analysis and development plan
- July 24, 2023: Updated with implementation tracker and status update policy

Steps to Complete the Project
To finalize the project, follow these steps to align with MCP best practices:

Implement HTTP/SSE Transport: Currently, the server uses stdio for local testing. For remote access, set up an HTTP server using the MCP SDK's HttpServerTransport or SseServerTransport. This involves installing additional packages like express and configuring the server to handle network requests, ensuring scalability for production use.
Add Rate Limiting to Tools: Tools like web search, which rely on external APIs (e.g., Perplexity AI), need rate limiting to prevent API limit exceedances. Implement a token bucket algorithm within each tool's execution logic, making it configurable based on API constraints for better resource management.
Develop Missing Resources and Tools: Ensure all planned capabilities are implemented, such as the "github-pr" resource for GitHub pull request information and tools like "repo-query" for repository analysis using Google Gemini, and "browser-open" for browser automation with Playwright. Each must have defined request and response schemas for validation.
Write Comprehensive Tests: Create unit tests for each tool and resource to verify functionality, and integration tests to simulate real-world usage. Use testing frameworks like Jest and consider the MCP Inspector tool for systematic protocol testing, ensuring reliability and robustness.
Ensure Security Measures: Validate all inputs using schemas (e.g., Zod), store sensitive data like API keys in environment variables, and implement robust error handling and logging. Consider adding authentication for multi-user access if needed, enhancing security for production deployment.
Document the Server Thoroughly: Update the "README.md" with setup instructions, usage examples, and a list of available tools and resources. Add inline code comments for clarity, making the project accessible for other developers and ensuring maintainability.
Design for Scalability: Keep the server stateless to facilitate horizontal scaling, use efficient data structures for quick request handling, and plan for load balancing strategies in production to manage increased load effectively.
By following these steps, your MCP server will be complete, secure, and scalable, adhering to the guidelines in the MCP documentation.

Survey Note: Detailed Analysis and Completion Guide for the MCP Server Project
This survey note provides an in-depth analysis of the "developer-tools" repository by freshtechbro, focusing on completing the project to meet the standards and recommendations of the Model Context Protocol (MCP) documentation (Model Context Protocol Introduction). The analysis is based on the provided repository structure, file contents, and research documents, ensuring a comprehensive guide for implementation.

Project Context and Current State
The repository, hosted at GitHub Repository, is designed as a suite of development tools centered around an MCP server implementation. It aims to enhance developer productivity with features like web search (using Perplexity AI), repository analysis (using Google Gemini), browser automation (using Playwright), and GitHub information retrieval. The directory structure includes core files like "README.md", "package.json", and "tsconfig.json", with subdirectories for documentation ("docs/"), research ("local-research/"), server implementation ("mcp-server/"), and source code ("src/").

From the "README.md", the project is described as a personal assistant capable of performing actions to answer user questions accurately, with a focus on MCP server implementation and various utilities. The "local-research/" directory contains detailed plans and analyses, such as "mcp-plan.md" and "cursor-tools-implementation.md", indicating a structured approach to development. However, the provided file contents are cropped, suggesting some implementations (e.g., "repo-query.js", "github-pr.js") may not be fully visible, requiring assumptions based on the plan.

Analysis of Current Implementation
The current implementation includes:

Server Setup: "src/server.ts" and "src/server.js" show a basic MCP server using the @modelcontextprotocol/sdk with stdio transport, suitable for local development. It registers tools like "web-search" and has basic error handling and logging.
Web Search Tool: Implemented in "src/capabilities/tools/web-search.ts" and "src/capabilities/tools/web-search.js", it uses Perplexity AI API, with Zod schemas for request and response validation, and basic error handling. Tests are present in "src/capabilities/tools/tests/web-search.test.ts".
Testing Infrastructure: Includes "test-client.ts" and "test-setup.ts" for verifying server functionality and dependencies, with Jest configuration in "jest.config.js".
Research and Planning: "local-research/mcp-plan.md" outlines a comprehensive implementation plan, covering transport layers, security, testing, and scalability, while "mcp-clarifications.md" details best practices.
However, gaps exist:

Transport Layers: Only stdio is implemented, with HTTP/SSE planned but not executed, limiting remote access.
Rate Limiting: No explicit rate limiting is seen in tools like "web-search", which is critical for external API calls.
Missing Resources and Tools: "github-pr" resource and tools like "repo-query" and "browser-open" are mentioned in plans but may not be fully implemented, based on the provided content.
Comprehensive Testing: While "web-search" has tests, broader unit and integration tests for all capabilities are needed.
Security and Scalability: Basic security (environment variables) is in place, but advanced measures like authentication and load balancing are not implemented, affecting production readiness.
Steps to Complete the Project
To align with MCP documentation and best practices, the following steps are recommended:

1. Implement HTTP/SSE Transport for Remote Access
Rationale: The current stdio transport is suitable for local testing but limits remote access, which is essential for production use. MCP documentation suggests supporting HTTP/SSE for network communication (Model Context Protocol Introduction).
Implementation:
Install additional packages: npm install express body-parser.
Modify "src/server.ts" to include HTTP server setup:
ts
Wrap
Copy
import express from 'express';
import { HttpServerTransport } from '@modelcontextprotocol/sdk/server/http.js';

const app = express();
app.use(express.json());
const transport = new HttpServerTransport(app);
server.connect(transport);
const port = 3000;
app.listen(port, () => {
  console.log(`MCP server listening on port ${port}`);
});
Consider SSE for real-time updates, using SseServerTransport if needed, ensuring TLS for security as per "mcp-clarifications.md".
Expected Outcome: Enables remote client connections, enhancing usability for distributed environments.
2. Implement Rate Limiting in Tools
Rationale: Tools like "web-search" make external API calls (e.g., Perplexity AI), which have rate limits. "mcp-clarifications.md" recommends token bucket or sliding window algorithms for rate limiting to prevent abuse and ensure reliability.
Implementation:
Add a rate limiter class, e.g., in "src/utils/rate-limiter.ts":
ts
Wrap
Copy
class RateLimiter {
  private tokens = 100;
  private maxTokens = 100;
  private lastRefill = Date.now();
  private refillRate = 1; // Tokens per second

  async acquireToken() {
    const now = Date.now();
    const timePassed = now - this.lastRefill;
    const tokensToAdd = Math.floor(timePassed / (1000 / this.refillRate));
    if (tokensToAdd > 0) {
      this.tokens = Math.min(this.maxTokens, this.tokens + tokensToAdd);
      this.lastRefill = now;
    }
    if (this.tokens <= 0) {
      const waitTime = (1000 / this.refillRate) - (now - this.lastRefill);
      await new Promise<void>((resolve) => setTimeout(() => resolve(), waitTime));
      return this.acquireToken();
    }
    this.tokens--;
  }
}
Integrate into "web-search.ts" and other API-dependent tools:
ts
Wrap
Copy
const rateLimiter = new RateLimiter();
webSearchTool.execute = async (request): Promise<WebSearchResponse> => {
  await rateLimiter.acquireToken();
  // Existing execution logic
};
Configure based on API limits, potentially using environment variables for customization.
Expected Outcome: Prevents API rate limit exceedances, improving tool reliability and user experience.
3. Develop Missing Resources and Tools
Rationale: "mcp-plan.md" outlines implementing "github-pr" resource and tools like "repo-query" and "browser-open", which are critical for the project's functionality. These are currently partially implemented or planned, as seen in "cursor-tools-implementation.md".
Implementation:
"github-pr" Resource: Create in "src/capabilities/resources/github-pr.ts":
ts
Wrap
Copy
const githubPrResource = {
  name: 'github-pr',
  version: '0.1.0',
  description: 'Provides information about GitHub Pull Requests.',
  list: async (request): Promise<ListResourcesResponse> => {
    // Logic to list GitHub pull requests using @octokit/rest
    return { resources: [] }; // Placeholder
  },
  read: async (request): Promise<ReadResourceResponse> => {
    // Logic to read a specific GitHub pull request
    return { resource: {} }; // Placeholder
  },
  requestSchema: z.object({ owner: z.string(), repo: z.string() }),
  responseSchema: z.object({ resources: z.array(z.object({ uri: z.string(), title: z.string() })) }),
};
"repo-query" Tool: Implement in "src/capabilities/tools/repo-query.ts" using Google Gemini API:
ts
Wrap
Copy
const repoQueryTool = {
  name: 'repo-query',
  version: '0.1.0',
  description: 'Answers questions about the repository using Google Gemini.',
  execute: async (request): Promise<RepositoryAnalysisResponse> => {
    // Logic using @google/generative-ai, simplified for now
    return { answer: 'Placeholder answer' };
  },
  requestSchema: z.object({ query: z.string() }),
  responseSchema: z.object({ answer: z.string() }),
};
"browser-open" Tool: Implement in "src/capabilities/tools/browser-automation/browser-open.ts" using Playwright:
ts
Wrap
Copy
const browserOpenTool = {
  name: 'browser-open',
  version: '0.1.0',
  description: 'Opens a URL in a browser and captures page content.',
  execute: async (request): Promise<BrowserOpenResponse> => {
    // Logic using playwright, capturing HTML, console logs, etc.
    return { message: 'Success' };
  },
  requestSchema: z.object({ url: z.string() }),
  responseSchema: z.object({ message: z.string() }),
};
Register these in "src/server.ts" under capabilities.resources and capabilities.tools.
Expected Outcome: Completes the feature set, aligning with "cursor-tools" functionality and MCP standards.
4. Write Comprehensive Tests
Rationale: Testing ensures reliability and compliance with MCP protocol. "mcp-clarifications.md" recommends using the MCP Inspector and systematic testing approaches, with "src/capabilities/tools/tests/web-search.test.ts" as a starting point.
Implementation:
Unit Tests: For each tool and resource, write tests using Jest:
ts
Wrap
Copy
describe('GitHub PR Resource', () => {
  it('should list pull requests', async () => {
    const response = await githubPrResource.list({ owner: 'nodejs', repo: 'node' });
    expect(response.resources).toBeDefined();
  });
});
Integration Tests: Expand "test-client.ts" to test end-to-end scenarios, simulating client-server interactions:
ts
Wrap
Copy
await client.executeTool({ toolName: 'repo-query', version: '0.1.0', arguments: { query: 'Explain project structure' } });
Use MCP Inspector if available for protocol compliance testing, focusing on core features first, then edge cases and error handling.
Expected Outcome: Ensures all capabilities are robust and reliable, with high test coverage.
5. Ensure Security Measures
Rationale: Security is critical for production use, with "mcp-clarifications.md" highlighting input validation, TLS, and authentication. Current implementation uses environment variables, but more is needed.
Implementation:
Input Validation: Ensure all tools and resources use Zod schemas, as in "web-search.ts":
ts
Wrap
Copy
requestSchema: z.object({ query: z.string().min(1, 'Query cannot be empty') }),
API Key Security: Confirm .env is in .gitignore, and use dotenv for loading, as implemented.
Error Handling and Logging: Enhance logging with structured formats using "src/utils/logger.ts", logging errors, requests, and performance metrics:
ts
Wrap
Copy
logger.error('API call failed', { error: error.message, request: request });
TLS and Authentication: For HTTP/SSE, configure TLS using Node.js https module, and consider API key authentication for remote access:
ts
Wrap
Copy
const https = require('https');
https.createServer({ key: fs.readFileSync('key.pem'), cert: fs.readFileSync('cert.pem') }, app).listen(443);
Rate Limiting: Already addressed in Step 2, ensure consistency across all API-dependent tools.
Expected Outcome: Secures the server against common vulnerabilities, ensuring safe operation in production.
6. Document the Server Thoroughly
Rationale: Documentation is key for beginner-friendliness, as per "mcp-user-experience.md", with "README.md" needing updates for setup and usage.
Implementation:
Update "README.md" to include:
Project description and goals.
Installation instructions: npm install, environment variable setup (e.g., PERPLEXITY_API_KEY), Playwright installation.
Running instructions: npm start for production, npm run dev for development.
Usage examples using "test-client.ts", listing available tools (web-search, repo-query, etc.) and resources (github-pr).
Troubleshooting guide for common issues (e.g., API key errors, network issues).
Contribution guide encouraging community input.
Add inline comments in code, especially for complex logic in tools and resources:
ts
Wrap
Copy
// Validates input query and executes web search
async execute(request: WebSearchRequest): Promise<WebSearchResponse> {
  // ... implementation ...
}
Expected Outcome: Makes the project accessible and maintainable, enhancing user experience for developers.
7. Ensure Scalability
Rationale: Scalability is crucial for production, with "mcp-clarifications.md" recommending stateless design and load balancing. Current stateless design is a good start, but more planning is needed.
Implementation:
Stateless Design: Ensure all tools and resources are stateless, avoiding session-specific data, as seen in current implementations.
Efficient Resource Management: Use asynchronous operations (async/await) for concurrent request handling, already implemented in tools like "web-search.ts".
Load Balancing and Scaling: For production, plan for horizontal scaling by adding server instances behind a load balancer, using tools like Nginx or cloud load balancers. Monitor resource usage (CPU, memory) using Node.js monitoring libraries.
Documentation: Add a section in "README.md" on deployment considerations, including Docker containerization and cloud platforms (e.g., AWS, Google Cloud).
Expected Outcome: Prepares the server for high-load scenarios, ensuring performance and reliability in production.
Unexpected Detail: Integration with AI IDEs
An unexpected aspect is the potential for integrating this MCP server with AI IDEs, as hinted in "local-research/mcp-research.md". This could extend its utility beyond command-line tools, offering context-aware assistance within development environments, enhancing productivity in ways not immediately obvious from the current focus on command-line features.

Tables for Organization
Below is a table summarizing the current state and planned enhancements:

Component	Current State	Planned Enhancements
Transport Layer	Stdio implemented, HTTP/SSE planned	Implement HTTP/SSE for remote access
Rate Limiting	Not implemented	Add token bucket for API-dependent tools
Resources	"web-search" tool implemented, others planned	Implement "github-pr" and other resources
Tools	Partial (e.g., "web-search"), others planned	Implement "repo-query", "browser-open", etc.
Testing	Basic tests for "web-search", client tests	Comprehensive unit and integration tests
Security	Basic (env vars, schemas)	Add TLS, authentication, enhanced logging
Documentation	Basic "README.md"	Detailed setup, usage, and contribution guides
Scalability	Stateless design, basic async operations	Plan for load balancing, resource monitoring
Another table for testing approaches, as per "mcp-clarifications.md":

Testing Approach	Description	Implementation
Unit Tests	Test individual tools/resources in isolation	Use Jest, write tests for each module
Integration Tests	Test end-to-end server-client interactions	Expand "test-client.ts" for scenarios
MCP Inspector	Systematic testing of MCP protocol compliance	Explore tool if available, focus on core features
Error Handling Tests	Verify error paths and responses	Test API errors, invalid inputs
Performance Testing	Assess server performance under load (future)	Monitor response times, resource usage
</file>

<file path="local-research/http-sse-transport-implementation-plan.md">
# HTTP/SSE Transport Implementation Plan

This document outlines a comprehensive step-by-step approach to implement HTTP and SSE transport for the MCP server, including TLS support and a testing web interface.

## Phase 1: Set up HTTP Transport and Dependencies

1. **Install Express and Required Dependencies**
   - Install necessary packages:
     ```bash
     npm install express body-parser cors
     ```
   - Update package.json to include these dependencies

2. **Update Server Configuration**
   - Ensure HTTP transport configuration in `src/config/index.ts` includes:
     - `enabled` (boolean) - Whether HTTP transport is enabled
     - `port` (number) - Port to listen on (default: 3000)
     - `host` (string) - Host to bind to (default: 'localhost')
     - `path` (string) - Endpoint path (default: '/mcp')
   - Update the environment variable definitions in `.env.example`

3. **Implement HTTP Transport in Server.ts**
   - Import Express and HttpServerTransport
   - Create Express application when HTTP is enabled
   - Configure middleware (json parsing, etc.)
   - Initialize HttpServerTransport with the Express app
   - Start the HTTP server on the configured port

4. **Test HTTP Transport**
   - Enable HTTP transport in `.env`
   - Verify server logs show successful HTTP transport startup
   - Use curl or Postman to send test requests
   - Validate responses and error handling

## Phase 2: Implement SSE Transport

1. **Add SSE Transport Configuration**
   - Update `src/config/index.ts` with SSE configuration:
     - `enabled` (boolean) - Whether SSE is enabled
     - `port` (number) - Port for SSE (default: 3001)
     - `host` (string) - Host to bind to
     - `path` (string) - SSE endpoint path (default: '/mcp-sse')
   - Add corresponding environment variables to `.env.example`

2. **Implement SSE Transport in Server.ts**
   - Import SseServerTransport from MCP SDK
   - Configure Express app for SSE when enabled
   - Add CORS support for cross-origin requests
   - Set up proper event handling for SSE connections
   - Configure endpoints for client-to-server messages

3. **Test SSE Transport**
   - Enable SSE in configuration
   - Create a simple HTML/JS client to test SSE connection
   - Verify streaming updates from server to client
   - Test reconnection handling

## Phase 3: Add TLS Support (HTTPS)

1. **Generate TLS Certificates**
   - For development:
     ```bash
     openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 365 -subj '/CN=localhost'
     ```
   - Store certificates in a secure location

2. **Update Configuration for HTTPS**
   - Add HTTPS configuration to `src/config/index.ts`:
     - `enabled` (boolean) - Whether HTTPS is enabled
     - `key` (string) - Path to private key
     - `cert` (string) - Path to certificate
   - Add environment variables for TLS configuration

3. **Implement HTTPS Server**
   - Import Node.js `https` module
   - Configure HTTPS server with certificates
   - Update server startup to use HTTPS when enabled
   - Implement HTTP-to-HTTPS redirection (optional)

4. **Add Security Headers**
   - Install Helmet: `npm install helmet`
   - Configure security headers including HSTS
   - Set secure cookie options if applicable

5. **Test HTTPS Implementation**
   - Enable HTTPS in configuration
   - Verify secure connection in browser
   - Test with curl using the `--insecure` flag (for self-signed certs)

## Phase 4: Create Web Interface for Testing

1. **Set Up Static File Serving**
   - Create a `public` directory for web files
   - Configure Express to serve static files
   - Add basic HTML, CSS, and JS files

2. **Implement Testing Interface**
   - Create forms for testing different MCP tools
   - Add UI for HTTP and SSE connections
   - Implement result display and error handling
   - Add example requests

3. **Add Real-time Updates with SSE**
   - Implement client-side SSE connection
   - Add event listeners for different event types
   - Display streaming updates in the UI

4. **Documentation and Examples**
   - Add usage documentation to the web interface
   - Include example requests for different tools
   - Document error codes and handling

## Implementation Notes

- Each phase should be implemented and tested incrementally
- Maintain backward compatibility with stdio transport
- Follow security best practices, especially for production
- Implement comprehensive error handling
- Use environment variables for flexible configuration
- Consider adding rate limiting for production use

## References

- MCP SDK Documentation
- Express.js Documentation
- Node.js HTTPS Documentation
- Server-Sent Events (SSE) Best Practices
</file>

<file path="local-research/jest-fs-mocking-best-practices.md">
Querying Perplexity AI using sonar-pro for: Best practices for mocking file system operations in Jest with TypeScript, focusing on path normalization, manual mocks vs. spy functions, and module loading order. How to handle platform-specific path differences in tests?
Here are some best practices for mocking file system operations in Jest with TypeScript:

1. Use manual mocks for core Node.js modules like 'fs':

Create a manual mock file in `__mocks__/fs.js`:

```typescript
const fs = jest.createMockFromModule('fs');

// Implement custom mock functions
fs.readFileSync = jest.fn();
fs.writeFileSync = jest.fn();

module.exports = fs;
```

Then in your test file:

```typescript
jest.mock('fs');
import * as fs from 'fs';

// Now fs functions are mocked
```

2. For path normalization, use the 'path' module:

```typescript
import * as path from 'path';

const normalizedPath = path.normalize('/test/path');
```

3. To handle platform-specific paths, use `path.sep`:

```typescript
const platformPath = ['dir', 'subdir', 'file.txt'].join(path.sep);
```

4. For spying on specific functions, use `jest.spyOn`:

```typescript
import * as fs from 'fs';

const readFileSpy = jest.spyOn(fs, 'readFileSync');
readFileSpy.mockReturnValue('mocked content');
```

5. To ensure correct module loading order, use `jest.mock()` calls at the top of your test file, before any imports:

```typescript
jest.mock('fs');
jest.mock('./myModule');

import * as fs from 'fs';
import { myFunction } from './myModule';
```

6. For TypeScript type safety with mocks, use `jest.mocked`:

```typescript
import { readFileSync } from 'fs';
jest.mock('fs');

const mockedReadFileSync = jest.mocked(readFileSync);
mockedReadFileSync.mockReturnValue('mocked content');
```

7. To reset mocks between tests, use `beforeEach`:

```typescript
beforeEach(() => {
  jest.resetAllMocks();
});
```

8. For complex file system structures, consider using a custom mock implementation:

```typescript
const mockFS = {
  '/test': {
    'file.txt': 'content'
  }
};

jest.mock('fs', () => ({
  readFileSync: jest.fn((path) => {
    const parts = path.split('/').filter(Boolean);
    let current = mockFS;
    for (const part of parts) {
      current = current[part];
    }
    return current;
  })
}));
```

These practices will help you effectively mock file system operations in Jest with TypeScript, handle path normalization, and manage module loading order[1][3][4][5].

citations:
1. https://jestjs.io/docs/manual-mocks
2. https://kulshekhar.github.io/ts-jest/docs/getting-started/paths-mapping/
3. https://dev.to/zaklaughton/the-only-3-steps-you-need-to-mock-an-api-call-in-jest-39mb/comments
4. https://jestjs.io/docs/getting-started
5. https://dev.to/mattiz/mock-modules-properly-with-jest-and-typescript-3nao
6. https://www.youtube.com/watch?v=SRVH0Mcakj0
7. https://www.lambdatest.com/automation-testing-advisor/javascript/jest-normalize
8. https://www.youtube.com/watch?v=9N8D7U9Am8o
9. https://www.jenchan.biz/blog/dissecting-the-hell-jest-setup-esm-typescript-setup
10. https://github.com/jestjs/jest/blob/main/CHANGELOG.md
</file>

<file path="local-research/jest-fs-mocking-gemini.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, let's dive into the best practices for mocking file system operations in Jest with TypeScript, focusing on path normalization, module loading order, and platform-specific path handling.

Mocking file system operations in tests is crucial for several reasons:

*   **Isolation:** Tests should be isolated and not depend on the actual file system state.
*   **Speed:** File system operations can be slow, and mocking speeds up tests significantly.
*   **Predictability:** Mocking ensures predictable test outcomes regardless of the environment's file system.
*   **Error Handling:**  Allows you to simulate various file system error scenarios (like file not found, permission issues) to test your error handling logic.

Here are the best practices, broken down as requested:

**1. Path Normalization: Ensuring Consistency**

*   **Why Normalize?** File paths can be represented in various ways (e.g., with extra slashes, relative segments like `..`). Normalizing paths ensures that your tests and mocks consistently work with a standard path format, regardless of how paths are constructed in your code or test environment.
*   **How to Normalize:** Use the `path.normalize()` method from Node.js's `path` module. This method resolves path segments like `..` and `.` and converts multiple separators into a single platform-specific separator.

    ```typescript
    import path from 'path';

    describe('File system operations with path normalization', () => {
        it('should handle normalized paths in mocks', async () => {
            const filePath = '/test/../path/./file.txt'; // Example unnormalized path
            const normalizedPath = path.normalize(filePath); // Normalize it

            // Mock fs.readFile to use normalized path
            jest.spyOn(fsPromises, 'readFile').mockImplementation(async (filepath) => {
                if (filepath === normalizedPath) { // Compare with normalized path
                    return 'Mock file content';
                }
                throw new Error('File not found');
            });

            // ... your test logic that uses normalizedPath ...
        });
    });
    ```

**2. Module Loading Order: Hoisting and `jest.mock` Placement**

*   **Importance of Order:** Jest hoists `jest.mock()` calls to the top of the module scope *before* any `import` statements are executed. This is crucial because you need to mock modules *before* the code under test imports and potentially uses the *real* module.
*   **Placement is Key:**  Ensure all `jest.mock()` calls, especially for core modules like `fs/promises`, are placed at the very top of your test file, before any imports from your source code that might use `fs/promises` or modules that depend on it.

    ```typescript
    // __tests__/my-module.test.ts

    jest.mock('fs/promises'); // Mock fs/promises at the very top!

    import { myModuleFunction } from '../my-module'; // Import AFTER mocking
    import * as fsPromises from 'fs/promises'; // Import mocked fsPromises

    describe('myModuleFunction', () => {
        it('should use mocked fs/promises', async () => {
            (fsPromises.readFile as jest.Mock).mockResolvedValue('mock content');
            const result = await myModuleFunction('/path/to/file');
            expect(result).toBe('mock content');
            expect(fsPromises.readFile).toHaveBeenCalled(); // Verify mock was used
        });
    });
    ```

*   **Common Pitfall:** If you import your module under test *before* calling `jest.mock('fs/promises')`, the real `fs/promises` module might be loaded and used before the mock is set up, leading to tests that don't use your mocks as intended.

**3. Handling Platform-Specific Path Differences**

*   **The Problem:** Windows uses backslashes (`\`) as path separators, while Unix-like systems (macOS, Linux) use forward slashes (`/`). Hardcoding paths with a specific separator will make your tests platform-dependent.
*   **Solution: `path` Module for Platform Abstraction:** The `path` module provides tools to construct and manipulate paths in a platform-agnostic way.

    *   **`path.join(...paths)`:** Use `path.join` to construct paths. It automatically uses the correct separator for the current platform.
    *   **`path.sep`:**  Access the platform-specific path separator ( `/` or `\`).

    ```typescript
    import path from 'path';
    import * as fsPromises from 'fs/promises';

    jest.mock('fs/promises');

    describe('Platform-agnostic path handling', () => {
        it('should use platform-specific path separators', async () => {
            const filePathParts = ['root', 'sub', 'file.txt'];
            const platformPath = path.join(...filePathParts); // Platform-aware path

            (fsPromises.readFile as jest.Mock).mockImplementation(async (filepath) => {
                if (filepath === platformPath) { // Compare with platform-specific path
                    return 'Platform-specific mock content';
                }
                throw new Error('File not found');
            });

            // ... your test logic using platformPath ...
        });

        it('should handle different path styles', async () => {
            const windowsPath = 'C:\\windows\\path\\file.txt';
            const unixPath = '/unix/path/file.txt';

            // Normalize both paths to a consistent format for comparison in mocks
            const normalizedWindowsPath = path.normalize(windowsPath);
            const normalizedUnixPath = path.normalize(unixPath);

            (fsPromises.readFile as jest.Mock).mockImplementation(async (filepath) => {
                const normalizedFilepath = path.normalize(filepath as string);
                if (normalizedFilepath === normalizedWindowsPath || normalizedFilepath === normalizedUnixPath) {
                    return 'Cross-platform mock content';
                }
                throw new Error('File not found');
            });

            // ... test logic ...
        });
    });
    ```

**4. Manual Mocks vs. Spy Functions (`jest.spyOn`)**

*   **Manual Mocks (`__mocks__` directory):**
    *   **Purpose:**  To completely replace a module's implementation with your mock implementation. Ideal for core modules like `fs/promises` where you want full control over every function's behavior.
    *   **Mechanism:** Jest automatically uses manual mocks if it finds a `__mocks__` directory at the same level as the module you're mocking. For example, to mock `fs/promises`, create `__mocks__/fs/promises.js` (or `.ts`).

        ```
        __mocks__/fs/promises.js  // For JavaScript
        __mocks__/fs/promises.ts  // For TypeScript
        ```

        ```typescript
        // __mocks__/fs/promises.ts (Example manual mock for fs/promises in TypeScript)
        const originalFsPromises = jest.requireActual('fs/promises'); // Optionally get real implementation

        const mockedFsPromises = {
            readFile: jest.fn().mockImplementation(originalFsPromises.readFile), // Mock readFile, optionally use original as fallback
            writeFile: jest.fn().mockResolvedValue(undefined), // Mock writeFile
            // ... mock other fsPromises functions you need
            __esModule: true, // Important for ESM if mocking ESM modules
            ...originalFsPromises // Optionally spread in other real functions to mock only a subset
        };

        module.exports = mockedFsPromises; // Or export default mockedFsPromises for ESM
        ```

    *   **Usage:** In your test file, simply use `jest.mock('fs/promises')`. Jest will automatically load your manual mock.

*   **Spy Functions (`jest.spyOn`):**
    *   **Purpose:** To mock or observe *specific functions* of a module, while leaving other functions in the module with their original implementation. Useful when you only need to mock a few functions or when you want to test interactions with real functions but control their return values or side effects.
    *   **Mechanism:** Use `jest.spyOn(module, 'functionName')` to create a spy on a specific function of a module.

        ```typescript
        import * as fsPromises from 'fs/promises';

        describe('Using spyOn for partial mocking', () => {
            it('should spy on readFile but use real writeFile', async () => {
                const readFileSpy = jest.spyOn(fsPromises, 'readFile').mockResolvedValue('spied content');

                // ... test logic ...
                expect(readFileSpy).toHaveBeenCalled(); // Verify readFile was called and mocked
                // writeFile will use the REAL implementation from fs/promises
                await fsPromises.writeFile('/temp/test.txt', 'real write');
            });
        });
        ```

    *   **Choosing Between Manual Mocks and Spies:**
        *   **Manual Mocks:** Best for complete isolation, especially for core modules. More upfront setup but gives you full control.
        *   **Spies:**  Best for partial mocking, observing interactions, or when you need to mix mocked and real functionality from the same module. Easier for simple mocking scenarios but might require more care if you need to mock many functions in a module.

**5. TypeScript Type Safety with Mocks (`jest.mocked`)**

*   **The Problem:**  When you mock a function in TypeScript with `jest.fn()`, TypeScript might lose type information about the mocked function. This can lead to type errors or less type-safe mocks.
*   **Solution: `jest.mocked<T>()`:** Jest provides `jest.mocked<T>()` to properly type your mocked functions. You cast your mocked module or function using `jest.mocked<T>()` where `<T>` is the TypeScript type of the module or function you are mocking.

    ```typescript
    import * as fsPromises from 'fs/promises';
    import { FileStorageService } from '../file-storage.service'; // Assuming your service is in this file

    jest.mock('fs/promises');

    describe('FileStorageService', () => {
        it('should use correctly typed mock for readFile', async () => {
            const mockedReadFile = jest.mocked(fsPromises.readFile); // Type-safe mock
            mockedReadFile.mockResolvedValue('typed mock content'); // Now type-safe!

            const service = new FileStorageService();
            const content = await service.readFromFile('/mock/file.txt');
            expect(content).toBe('typed mock content');
            expect(mockedReadFile).toHaveBeenCalled();
        });
    });
    ```

**6. Resetting Mocks: Isolating Tests**

*   **Why Reset?** Jest mocks are persistent across tests within a test file. If you don't reset mocks between tests, the mock implementation or call history from one test can inadvertently affect subsequent tests, leading to flaky or incorrect test results.
*   **How to Reset:** Use `jest.resetAllMocks()` or `jest.restoreAllMocks()` in `beforeEach` or `afterEach` blocks.

    *   **`jest.resetAllMocks()`:** Clears the call history of all mocks and resets their implementation to the default mock function (usually returning `undefined` or `null`).
    *   **`jest.restoreAllMocks()`:** Restores all spies and mocks to their original implementations. Use this if you want to completely undo mocks and spies after each test.

    ```typescript
    describe('FileStorageService', () => {
        beforeEach(() => {
            jest.resetAllMocks(); // Or jest.restoreAllMocks();
        });

        it('test case 1', async () => {
            // ... your test logic ...
        });

        it('test case 2', async () => {
            // ... your test logic ... - mocks will be reset before this test starts
        });
    });
    ```

**Example: Mocking `fileStorageService` (from your provided codebase)**

Let's say you want to test a component that uses `fileStorageService`. Here's how you might mock it in a test file:

```typescript
// __tests__/my-component.test.ts

import { jest, beforeEach, describe, it, expect } from '@jest/globals';
import { myComponentFunction } from '../my-component'; // Your component using fileStorageService
import { fileStorageService } from '../services/file-storage.service'; // Import the service
import path from 'path';

jest.mock('../services/file-storage.service.js'); // Mock the service

describe('MyComponent', () => {
    beforeEach(() => {
        jest.clearAllMocks();
    });

    it('should correctly save data to file', async () => {
        const mockFilePath = '/mock/save/path/file.txt';
        const mockContent = 'Test content to save';

        // Mock fileStorageService.saveToFile to return a specific path
        (fileStorageService.saveToFile as jest.Mock).mockResolvedValue(mockFilePath);

        const resultPath = await myComponentFunction(mockContent); // Function using fileStorageService

        expect(fileStorageService.saveToFile).toHaveBeenCalledWith(
            mockFilePath,
            mockContent,
            expect.any(Object) // You can check options as needed
        );
        expect(resultPath).toBe(mockFilePath);
    });

    it('should handle file saving errors', async () => {
        const mockError = new Error('File saving failed');
        (fileStorageService.saveToFile as jest.Mock).mockRejectedValueOnce(mockError);

        await expect(myComponentFunction('content')).rejects.toThrow('File saving failed');
        expect(fileStorageService.saveToFile).toHaveBeenCalled();
    });

    // ... more tests for your component ...
});
```

By following these best practices, you can create robust, reliable, and platform-independent tests for your TypeScript code that interacts with the file system. Remember to choose the right mocking strategy (manual mocks vs. spies) based on your testing needs and always reset mocks between tests to ensure isolation.
</file>

<file path="local-research/mcp-clarifications.md">
Querying Perplexity AI using sonar-pro for: 1. What are the specific security best practices for MCP servers? 2. How should versioning and backwards compatibility be handled? 3. What are the recommended approaches for scaling MCP servers? 4. How should the server handle state management and session persistence?
1. Security best practices for MCP servers:
- Use TLS for remote connections[1]
- Implement authentication when needed[1]
- Validate all incoming messages[1]
- Sanitize inputs[1]
- Check message size limits[1]
- Implement access controls[1]
- Monitor resource usage[1]
- Rate limit requests[1]
- Don't leak sensitive information in errors[1]
- Log security-relevant events[1]

2. Versioning and backwards compatibility:
- Use package specifiers to version services (e.g. greet.v1.Greeter)[7]
- Host multiple versions side-by-side[7]
- Strive for backwards compatibility with old clients[7]
- Make breaking changes in new versions[7]

3. Scaling MCP servers:
- Use horizontal scaling by adding more instances[3]
- Implement autoscaling to dynamically adjust capacity[3]
- Create scale units that can be added together[3]
- Set scaling limits to prevent over-scaling[3]
- Use meaningful load metrics as scaling triggers[3]
- Add a buffer to handle unexpected spikes[3]

4. State management and session persistence:
- Use session state for short-lived, user-specific data[4][9]
- Store critical data in databases, not session[4]
- Set appropriate session timeouts[4]
- Use cookies to maintain session IDs[4]
- Consider alternatives like caching for better scalability[4][9]
- Avoid relying on session state for critical application functionality[4]
</file>

<file path="local-research/mcp-detailed-steps.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, here is a detailed, step-by-step implementation plan for building the MCP server with `cursor-tools` features. This plan breaks down the process into the smallest possible steps to ensure clarity and ease of implementation, especially for beginners.

**Phase 1: Project Setup and Basic Server Structure**

**Step 1: Create Project Directory**

1.  Open your terminal.
2.  Navigate to the directory where you want to create your project.
3.  Create a new directory for your MCP server:
    ```bash
    mkdir mcp-server
    cd mcp-server
    ```

**Step 2: Initialize Node.js Project**

1.  Inside the `mcp-server` directory, initialize a new Node.js project using npm:
    ```bash
    npm init -y
    ```
    This will create a `package.json` file with default settings.

**Step 3: Install MCP SDK and Core Dependencies**

1.  Install the `@modelcontextprotocol/sdk` which is essential for building MCP servers. We'll also install `node-fetch` for making HTTP requests (needed for web search and potentially GitHub API).
    ```bash
    npm install @modelcontextprotocol/sdk node-fetch
    ```

**Step 4: Create `server.js` - Basic Server Structure**

1.  Create a new file named `server.js` in your project root.
2.  Add the following basic server structure to `server.js`:

    ```javascript
    // server.js
    import { Server } from "@modelcontextprotocol/sdk/server/index.js";
    import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

    async function main() {
        const server = new Server({
            name: "cursor-tools-mcp-server",
            version: "0.1.0",
            description: "MCP server mimicking cursor-tools functionalities."
        }, {
            capabilities: {
                resources: {}, // Resources will be defined here
                tools: {}      // Tools will be defined here
            }
        });

        const transport = new StdioServerTransport();
        await server.connect(transport);
        console.log("MCP Server started using stdio transport.");
    }

    main().catch(console.error);
    ```

**Step 5: Run the Basic Server**

1.  In your terminal, run the server:
    ```bash
    node server.js
    ```
    You should see the output: `MCP Server started using stdio transport.` This confirms your basic server setup is working. Press `Ctrl+C` to stop the server.

**Phase 2: Implement Web Search Tool (`cursor-tools web`)**

**Step 6: Install Perplexity AI API Client (or use `node-fetch` directly)**

1.  For this example, we'll use `node-fetch` directly for simplicity to interact with Perplexity AI. If a dedicated Perplexity Node.js SDK becomes available, you could consider using it later.

**Step 7: Create `web-search.js` Tool Module**

1.  Create a new directory `capabilities` in your project root.
2.  Inside `capabilities`, create a directory `tools`.
3.  Inside `tools`, create a file named `web-search.js`.
4.  Add the following code to `capabilities/tools/web-search.js`:

    ```javascript
    // capabilities/tools/web-search.js
    import fetch from 'node-fetch';

    const PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions"; // Replace with actual API endpoint if different
    const PERPLEXITY_API_KEY = process.env.PERPLEXITY_API_KEY; // Load API key from environment variable

    export const webSearchTool = {
        name: 'web-search',
        version: '0.1.0',
        description: 'Performs a web search using Perplexity AI.',
        execute: async (request) => {
            if (!PERPLEXITY_API_KEY) {
                throw new Error("Perplexity API key is not set in environment variables (PERPLEXITY_API_KEY)");
            }
            const { query } = request;
            if (!query) {
                throw new Error("Search query is required.");
            }

            try {
                const response = await fetch(PERPLEXITY_API_URL, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${PERPLEXITY_API_KEY}`
                    },
                    body: JSON.stringify({
                        model: "pplx-7b-online", // Or another suitable Perplexity model
                        messages: [{ role: "user", content: query }]
                    })
                });

                if (!response.ok) {
                    const errorDetails = await response.text();
                    throw new Error(`Perplexity API request failed: ${response.status} - ${errorDetails}`);
                }

                const data = await response.json();
                const searchResults = data.choices[0]?.message?.content || "No results found."; // Extract result from API response

                return {
                    searchResults: searchResults
                };

            } catch (error) {
                console.error("Error during web search:", error);
                throw new Error(`Web search failed: ${error.message}`);
            }
        },
        requestSchema: {
            type: 'object',
            properties: {
                query: { type: 'string', description: 'The search query.' }
            },
            required: ['query']
        },
        responseSchema: {
            type: 'object',
            properties: {
                searchResults: { type: 'string', description: 'Web search results.' }
            },
            required: ['searchResults']
        }
    };
    ```

**Step 8: Register `web-search` Tool in `server.js`**

1.  Open `server.js` and modify the `capabilities.tools` section and import the `webSearchTool`:

    ```javascript
    // server.js
    import { Server } from "@modelcontextprotocol/sdk/server/index.js";
    import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
    import { webSearchTool } from './capabilities/tools/web-search.js'; // Import the web search tool

    async function main() {
        const server = new Server({
            name: "cursor-tools-mcp-server",
            version: "0.1.0",
            description: "MCP server mimicking cursor-tools functionalities."
        }, {
            capabilities: {
                resources: {},
                tools: {
                    'web-search': webSearchTool, // Register the web search tool
                }
            }
        });

        // ... (rest of server.js remains the same) ...
    }

    main().catch(console.error);
    ```

**Step 9: Set Perplexity API Key**

1.  You need a Perplexity API key to use their API. If you don't have one, sign up at [https://developer.perplexity.ai/](https://developer.perplexity.ai/).
2.  Set the API key as an environment variable named `PERPLEXITY_API_KEY`. How you set environment variables depends on your operating system:
    *   **Linux/macOS:**
        ```bash
        export PERPLEXITY_API_KEY="your_perplexity_api_key_here"
        ```
    *   **Windows (Command Prompt):**
        ```cmd
        set PERPLEXITY_API_KEY=your_perplexity_api_key_here
        ```
    *   **Windows (PowerShell):**
        ```powershell
        $env:PERPLEXITY_API_KEY="your_perplexity_api_key_here"
        ```
    *(Replace `your_perplexity_api_key_here` with your actual API key.)*

**Step 10: Test the `web-search` Tool**

1.  Start your MCP server in the terminal:
    ```bash
    node server.js
    ```
2.  To test the `web-search` tool, you'll need an MCP client. For a quick test, you can use a simple Node.js script to act as a client and send an `ExecuteToolRequest`. Create a new file `test-client.js` in your project root:

    ```javascript
    // test-client.js
    import { Client } from "@modelcontextprotocol/sdk/client/index.js";
    import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";

    async function main() {
        const transport = new StdioClientTransport();
        const client = new Client();
        await client.connect(transport);

        try {
            const response = await client.executeTool({
                toolName: 'web-search',
                version: '0.1.0',
                arguments: {
                    query: "latest news on AI" // Your search query
                }
            });

            console.log("Web Search Results:\n", response.tool_response.searchResults);

        } catch (error) {
            console.error("Error executing web-search tool:", error);
        } finally {
            client.close();
        }
    }

    main().catch(console.error);
    ```

3.  Run the test client in a *separate* terminal window (while your server is running in the first terminal):
    ```bash
    node test-client.js
    ```
    You should see web search results from Perplexity AI printed in your client terminal. If you encounter errors, check your API key, network connection, and server logs for details.

**Phase 3: Implement Repository Context Tool (`cursor-tools repo`) (Simplified)**

For this initial implementation, we'll create a simplified `repo-query` tool that uses Gemini API for general code-related questions *without* deep repository context indexing. We'll add basic functionality and can enhance it later.

**Step 11: Install Google Gemini API Client (or use `node-fetch` directly)**

1.  Similar to Perplexity, we'll use `node-fetch` for simplicity to interact with the Gemini API. You might consider using a dedicated Google API client library in a more advanced setup.

**Step 12: Create `repo-query.js` Tool Module**

1.  Inside `capabilities/tools`, create a new file named `repo-query.js`.
2.  Add the following code to `capabilities/tools/repo-query.js`:

    ```javascript
    // capabilities/tools/repo-query.js
    import fetch from 'node-fetch';

    const GOOGLE_GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent"; // Gemini Pro API endpoint
    const GOOGLE_API_KEY = process.env.GOOGLE_API_KEY; // Load Google API key from environment variable

    export const repoQueryTool = {
        name: 'repo-query',
        version: '0.1.0',
        description: 'Answers questions about the repository using Google Gemini (simplified).',
        execute: async (request) => {
            if (!GOOGLE_API_KEY) {
                throw new Error("Google API key is not set in environment variables (GOOGLE_API_KEY)");
            }
            const { query } = request;
            if (!query) {
                throw new Error("Repository query is required.");
            }

            try {
                const response = await fetch(`${GOOGLE_GEMINI_API_URL}?key=${GOOGLE_API_KEY}`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        contents: [{ role: "user", parts: [{ text: query }] }],
                    })
                });

                if (!response.ok) {
                    const errorDetails = await response.text();
                    throw new Error(`Google Gemini API request failed: ${response.status} - ${errorDetails}`);
                }

                const data = await response.json();
                const answer = data.candidates?.[0]?.content?.parts?.[0]?.text || "No answer found.";

                return {
                    answer: answer
                };

            } catch (error) {
                console.error("Error during repository query:", error);
                throw new Error(`Repository query failed: ${error.message}`);
            }
        },
        requestSchema: {
            type: 'object',
            properties: {
                query: { type: 'string', description: 'Question about the repository.' }
            },
            required: ['query']
        },
        responseSchema: {
            type: 'object',
            properties: {
                answer: { type: 'string', description: 'Context-aware answer from Gemini.' }
            },
            required: ['answer']
        }
    };
    ```

**Step 13: Register `repo-query` Tool in `server.js`**

1.  Open `server.js` and import and register the `repoQueryTool`:

    ```javascript
    // server.js
    // ... other imports ...
    import { webSearchTool } from './capabilities/tools/web-search.js';
    import { repoQueryTool } from './capabilities/tools/repo-query.js'; // Import repo query tool

    async function main() {
        // ... server setup ...
            capabilities: {
                resources: {},
                tools: {
                    'web-search': webSearchTool,
                    'repo-query': repoQueryTool, // Register repo query tool
                }
            }
        // ... rest of server.js ...
    }

    main().catch(console.error);
    ```

**Step 14: Set Google API Key**

1.  You need a Google Cloud API key with access to the Gemini API. If you don't have one, you'll need to set up a Google Cloud project and enable the Gemini API. Instructions can be found in Google Cloud documentation.
2.  Set your Google API key as an environment variable named `GOOGLE_API_KEY`:
    *   **Linux/macOS:** `export GOOGLE_API_KEY="your_google_api_key_here"`
    *   **Windows (Command Prompt):** `set GOOGLE_API_KEY=your_google_api_key_here`
    *   **Windows (PowerShell):** `$env:GOOGLE_API_KEY="your_google_api_key_here"`
    *(Replace `your_google_api_key_here` with your actual Google API key.)*

**Step 15: Test the `repo-query` Tool**

1.  Ensure your MCP server is running (`node server.js`).
2.  Modify your `test-client.js` to test `repo-query`:

    ```javascript
    // test-client.js
    // ... imports ...

    async function main() {
        // ... transport and client setup ...

        try {
            // ... web-search test (you can keep it or comment out) ...

            const repoQueryResponse = await client.executeTool({
                toolName: 'repo-query',
                version: '0.1.0',
                arguments: {
                    query: "Explain the basic structure of a Node.js project." // Your repo question
                }
            });

            console.log("\nRepository Query Answer:\n", repoQueryResponse.tool_response.answer);

        } catch (error) {
            console.error("Error executing repo-query tool:", error);
        } finally {
            client.close();
        }
    }

    main().catch(console.error);
    ```

3.  Run the modified `test-client.js` (`node test-client.js`). You should see an answer from Gemini related to your query about a Node.js project.

**Phase 4: Implement GitHub PRs Resource (`cursor-tools github pr`)**

**Step 16: Create `github-pr.js` Resource Module**

1.  Create a new directory `resources` inside `capabilities` directory.
2.  Inside `resources`, create a file named `github-pr.js`.
3.  Add the following code to `capabilities/resources/github-pr.js`:

    ```javascript
    // capabilities/resources/github-pr.js
    import fetch from 'node-fetch';

    const GITHUB_API_BASE_URL = "https://api.github.com";
    const GITHUB_TOKEN = process.env.GITHUB_TOKEN; // Optional, but recommended for higher rate limits

    export const githubPullRequestResource = {
        name: 'github-pr',
        version: '0.1.0',
        description: 'Provides information about GitHub Pull Requests.',
        list: async (request) => {
            const { owner, repo } = request;
            if (!owner || !repo) {
                throw new Error("GitHub repository owner and name are required.");
            }

            const apiUrl = `${GITHUB_API_BASE_URL}/repos/${owner}/${repo}/pulls?state=open`; // Get open PRs by default
            const headers = GITHUB_TOKEN ? { 'Authorization': `token ${GITHUB_TOKEN}` } : {};

            try {
                const response = await fetch(apiUrl, { headers });
                if (!response.ok) {
                    const errorDetails = await response.json();
                    throw new Error(`GitHub API request failed: ${response.status} - ${JSON.stringify(errorDetails)}`);
                }
                const prs = await response.json();
                const resourceList = prs.map(pr => ({
                    uri: `github-pr://${owner}/${repo}/${pr.number}`, // Construct URI
                    title: pr.title,
                    number: pr.number,
                    url: pr.html_url
                }));

                return { resources: resourceList };

            } catch (error) {
                console.error("Error fetching GitHub PRs:", error);
                throw new Error(`Failed to fetch GitHub PRs: ${error.message}`);
            }
        },
        read: async (request) => {
            const { uri } = request; // e.g., "github-pr://owner/repo/123"
            const parts = uri.substring(9).split('/'); // Remove "github-pr://" and split
            if (parts.length !== 3) {
                throw new Error("Invalid GitHub PR URI format. Expected format: github-pr://owner/repo/number");
            }
            const owner = parts[0];
            const repo = parts[1];
            const prNumber = parts[2];

            const apiUrl = `${GITHUB_API_BASE_URL}/repos/${owner}/${repo}/pulls/${prNumber}`;
            const headers = GITHUB_TOKEN ? { 'Authorization': `token ${GITHUB_TOKEN}` } : {};

            try {
                const response = await fetch(apiUrl, { headers });
                if (!response.ok) {
                    const errorDetails = await response.json();
                    throw new Error(`GitHub API request failed: ${response.status} - ${JSON.stringify(errorDetails)}`);
                }
                const prDetails = await response.json();
                const resource = {
                    uri: `github-pr://${owner}/${repo}/${prNumber}`,
                    title: prDetails.title,
                    number: prDetails.number,
                    url: prDetails.html_url,
                    body: prDetails.body, // PR description
                    author: prDetails.user.login,
                    author_url: prDetails.user.html_url,
                    state: prDetails.state, // open, closed
                    created_at: prDetails.created_at,
                    updated_at: prDetails.updated_at
                };
                return { resource };

            } catch (error) {
                console.error("Error fetching GitHub PR details:", error);
                throw new Error(`Failed to fetch GitHub PR details: ${error.message}`);
            }
        },
        listRequestSchema: { // Schema for list capability request
            type: 'object',
            properties: {
                owner: { type: 'string', description: 'GitHub repository owner (username or organization).' },
                repo: { type: 'string', description: 'GitHub repository name.' }
            },
            required: ['owner', 'repo']
        },
        listResponseSchema: { // Schema for list capability response
            type: 'object',
            properties: {
                resources: {
                    type: 'array',
                    items: {
                        type: 'object',
                        properties: {
                            uri: { type: 'string', description: 'Unique URI for the GitHub PR resource.' },
                            title: { type: 'string', description: 'Title of the Pull Request.' },
                            number: { type: 'number', description: 'Pull Request number.' },
                            url: { type: 'string', description: 'URL to the Pull Request on GitHub.' }
                        },
                        required: ['uri', 'title', 'number', 'url']
                    }
                }
            },
            required: ['resources']
        },
        readRequestSchema: { // Schema for read capability request
            type: 'object',
            properties: {
                uri: { type: 'string', description: 'URI of the GitHub PR resource to read (e.g., github-pr://owner/repo/number).' }
            },
            required: ['uri']
        },
        readResponseSchema: { // Schema for read capability response
            type: 'object',
            properties: {
                resource: {
                    type: 'object',
                    properties: {
                        uri: { type: 'string' },
                        title: { type: 'string' },
                        number: { type: 'number' },
                        url: { type: 'string' },
                        body: { type: 'string', description: 'Pull Request description.' },
                        author: { type: 'string' },
                        author_url: { type: 'string' },
                        state: { type: 'string' },
                        created_at: { type: 'string' },
                        updated_at: { type: 'string' }
                    },
                    required: ['uri', 'title', 'number', 'url', 'body', 'author', 'author_url', 'state', 'created_at', 'updated_at']
                }
            },
            required: ['resource']
        }
    };
    ```

**Step 17: Register `github-pr` Resource in `server.js`**

1.  Open `server.js` and import and register the `githubPullRequestResource`:

    ```javascript
    // server.js
    // ... other imports ...
    import { webSearchTool } from './capabilities/tools/web-search.js';
    import { repoQueryTool } from './capabilities/tools/repo-query.js';
    import { githubPullRequestResource } from './capabilities/resources/github-pr.js'; // Import GitHub PR resource

    async function main() {
        // ... server setup ...
            capabilities: {
                resources: {
                    'github-pr': githubPullRequestResource, // Register GitHub PR resource
                },
                tools: {
                    'web-search': webSearchTool,
                    'repo-query': repoQueryTool,
                }
            }
        // ... rest of server.js ...
    }

    main().catch(console.error);
    ```

**Step 18: Set GitHub Token (Optional but Recommended)**

1.  For unauthenticated requests to the GitHub API, you are subject to rate limits. To increase your rate limit, you can create a personal access token on GitHub (no specific scopes needed for public repos).
2.  Set your GitHub token as an environment variable named `GITHUB_TOKEN`:
    *   **Linux/macOS:** `export GITHUB_TOKEN="your_github_token_here"`
    *   **Windows (Command Prompt):** `set GITHUB_TOKEN=your_github_token_here`
    *   **Windows (PowerShell):** `$env:GITHUB_TOKEN="your_github_token_here"`
    *(Replace `your_github_token_here` with your actual GitHub token, or leave it unset for lower rate limits.)*

**Step 19: Test the `github-pr` Resource**

1.  Ensure your MCP server is running (`node server.js`).
2.  Modify your `test-client.js` to test `github-pr` resource's `list` and `read` capabilities:

    ```javascript
    // test-client.js
    // ... imports ...

    async function main() {
        // ... transport and client setup ...

        try {
            // ... web-search and repo-query tests (you can keep them or comment out) ...

            console.log("\n--- GitHub PRs List ---");
            const prListResponse = await client.listResources({
                resourceName: 'github-pr',
                version: '0.1.0',
                arguments: {
                    owner: "nodejs", // Example: Node.js organization
                    repo: "node"     // Example: Node.js repository
                }
            });
            console.log("Open PRs in nodejs/node:\n", prListResponse.resource_list.resources.map(r => `${r.title} (${r.uri})`).join('\n'));

            if (prListResponse.resource_list.resources.length > 0) {
                const firstPrUri = prListResponse.resource_list.resources[0].uri;
                console.log(`\n--- GitHub PR Details for ${firstPrUri} ---`);
                const prDetailsResponse = await client.readResource({
                    resourceUri: firstPrUri
                });
                const pr = prDetailsResponse.resource_response.resource;
                console.log("PR Details:\n", `Title: ${pr.title}\nURL: ${pr.url}\nAuthor: ${pr.author}\nState: ${pr.state}\nDescription (truncated):\n${pr.body?.substring(0, 200)}...`);
            }

        } catch (error) {
            console.error("Error interacting with github-pr resource:", error);
        } finally {
            client.close();
        }
    }

    main().catch(console.error);
    ```

3.  Run the modified `test-client.js` (`node test-client.js`). You should see a list of open pull requests for the `nodejs/node` repository and details of the first PR listed.

**Phase 5: Implement Browser Open Tool (`cursor-tools browser open`)**

**Step 20: Install Playwright**

1.  If you haven't already, install Playwright which is needed for browser automation:
    ```bash
    npm install playwright
    ```

**Step 21: Create `browser-open.js` Tool Module**

1.  Inside `capabilities/tools/browser-automation`, create a new directory named `browser-automation` (if it doesn't exist already).
2.  Inside `browser-automation`, create a file named `browser-open.js`.
3.  Add the following code to `capabilities/tools/browser-automation/browser-open.js`:

    ```javascript
    // capabilities/tools/browser-automation/browser-open.js
    import playwright from 'playwright';
    import fs from 'node:fs/promises';
    import path from 'node:path';

    export const browserOpenTool = {
        name: 'browser-open',
        version: '0.1.0',
        description: 'Opens a URL in a browser and captures page content and metadata.',
        execute: async (request) => {
            const { url, html, console: captureConsole, network, screenshot, timeout, viewport, headless } = request;
            if (!url) {
                throw new Error("URL is required for browser-open tool.");
            }

            const browserType = 'chromium'; // Or 'firefox', 'webkit' if needed, Chromium is default for cursor-tools
            const browser = await playwright[browserType].launch({ headless: headless !== false }); // Default headless: true
            const page = await browser.newPage({ viewport: viewport ? parseViewport(viewport) : undefined });
            let consoleLogs = [];
            let networkActivity = [];
            let screenshotPath = null;
            let htmlContent = null;

            if (captureConsole !== false) { // Capture console logs by default
                page.on('console', msg => consoleLogs.push(`${msg.type().toUpperCase()} ${msg.text()}`));
            }
            if (network !== false) { // Capture network activity by default
                page.on('requestfinished', req => networkActivity.push({
                    url: req.url(),
                    method: req.method(),
                    status: req.response()?.status(),
                    // ... you can add more details if needed, but keep it concise for now
                }));
            }

            try {
                await page.goto(url, { timeout: timeout || 30000 }); // Default timeout: 30 seconds

                if (screenshot) {
                    screenshotPath = path.resolve(screenshot); // Ensure absolute path or relative to server working dir
                    await page.screenshot({ path: screenshotPath, fullPage: true });
                }
                if (html) {
                    htmlContent = await page.content();
                }

                return {
                    ...(html ? { htmlContent } : {}),
                    ...(captureConsole !== false ? { consoleLogs } : {}),
                    ...(network !== false ? { networkActivity } : {}),
                    ...(screenshot ? { screenshotPath } : {}),
                    message: `Successfully opened URL: ${url}`
                };

            } catch (error) {
                console.error("Error during browser automation:", error);
                throw new Error(`Browser automation failed: ${error.message}`);
            } finally {
                await browser.close();
            }
        },
        requestSchema: {
            type: 'object',
            properties: {
                url: { type: 'string', description: 'URL to open in the browser.' },
                html: { type: 'boolean', description: 'Capture page HTML content (optional, default: false).' },
                console: { type: 'boolean', description: 'Capture browser console logs (optional, default: true).' },
                network: { type: 'boolean', description: 'Capture network activity (optional, default: true).' },
                screenshot: { type: 'string', description: 'File path to save a screenshot (optional).' },
                timeout: { type: 'number', description: 'Navigation timeout in milliseconds (optional, default: 30000ms).' },
                viewport: { type: 'string', description: 'Viewport size in format "widthxheight" (e.g., "1280x720", optional).' },
                headless: { type: 'boolean', description: 'Run browser in headless mode (optional, default: true).' },
            },
            required: ['url']
        },
        responseSchema: {
            type: 'object',
            properties: {
                message: { type: 'string', description: 'Confirmation message.' },
                htmlContent: { type: 'string', description: 'Page HTML content (if requested).' },
                consoleLogs: { type: 'array', items: { type: 'string' }, description: 'Captured browser console logs (if requested).' },
                networkActivity: { type: 'array', items: { type: 'object' }, description: 'Captured network activity (if requested).' },
                screenshotPath: { type: 'string', description: 'Path to the saved screenshot (if requested).' },
            },
            required: ['message']
        }
    };

    function parseViewport(viewportString) {
        const [width, height] = viewportString.split('x').map(Number);
        return { width, height };
    }
    ```

**Step 22: Register `browser-open` Tool in `server.js`**

1.  Open `server.js` and import and register the `browserOpenTool`:

    ```javascript
    // server.js
    // ... other imports ...
    import { webSearchTool } from './capabilities/tools/web-search.js';
    import { repoQueryTool } from './capabilities/tools/repo-query.js';
    import { githubPullRequestResource } from './capabilities/resources/github-pr.js';
    import { browserOpenTool } from './capabilities/tools/browser-automation/browser-open.js'; // Import browser-open tool

    async function main() {
        // ... server setup ...
            capabilities: {
                resources: {
                    'github-pr': githubPullRequestResource,
                },
                tools: {
                    'web-search': webSearchTool,
                    'repo-query': repoQueryTool,
                    'browser-open': browserOpenTool, // Register browser-open tool
                }
            }
        // ... rest of server.js ...
    }

    main().catch(console.error);
    ```

**Step 23: Test the `browser-open` Tool**

1.  Ensure your MCP server is running (`node server.js`).
2.  Modify your `test-client.js` to test `browser-open` tool:

    ```javascript
    // test-client.js
    // ... imports ...

    async function main() {
        // ... transport and client setup ...

        try {
            // ... previous tests (you can keep them or comment out) ...

            console.log("\n--- Browser Open Tool ---");
            const browserOpenResponse = await client.executeTool({
                toolName: 'browser-open',
                version: '0.1.0',
                arguments: {
                    url: "https://www.example.com", // Example URL
                    html: true,          // Request HTML content
                    screenshot: "example.png", // Save screenshot to example.png in project root
                    viewport: "800x600"  // Set viewport size
                }
            });
            console.log("Browser Open Message:", browserOpenResponse.tool_response.message);
            if (browserOpenResponse.tool_response.htmlContent) {
                console.log("\nHTML Content (truncated):\n", browserOpenResponse.tool_response.htmlContent.substring(0, 300) + "...");
            }
            if (browserOpenResponse.tool_response.screenshotPath) {
                console.log("\nScreenshot saved to:", browserOpenResponse.tool_response.screenshotPath);
                // You can open example.png in your project root to view the screenshot
            }

        } catch (error) {
            console.error("Error executing browser-open tool:", error);
        } finally {
            client.close();
        }
    }

    main().catch(console.error);
    ```

3.  Run the modified `test-client.js` (`node test-client.js`). You should see output indicating the URL was opened, and if successful, a truncated HTML content snippet and a message about the screenshot being saved. A file named `example.png` should be created in your project root directory containing a screenshot of `example.com`.

**Next Steps:**

This detailed plan has guided you through implementing the `web-search`, `repo-query`, `github-pr` and `browser-open` functionalities. You can continue implementing the remaining `cursor-tools` features (`browser act`, `browser observe`, `browser extract`, `cursor-tools doc`, `cursor-tools github issue`) by following a similar pattern:

1.  **Create a new tool or resource module** (e.g., `browser-act.js`, `github-issue.js`, `generate-doc.js`).
2.  **Implement the necessary capabilities** (`execute` for tools, `list`, `read` for resources) within the module, using appropriate APIs and libraries (Playwright for browser tools, GitHub API for issues, a documentation generation library for `doc`).
3.  **Define request and response schemas** in the module.
4.  **Register the new module** in the `capabilities` section of your `server.js`.
5.  **Test the new functionality** using your `test-client.js` or by creating new test scripts.

Remember to handle errors gracefully, add logging, and document your code as you proceed. This step-by-step approach will help you build a comprehensive MCP server mirroring the features of `cursor-tools`.
</file>

<file path="local-research/mcp-final-recommendations.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, I've reviewed the updated documentation in `local-research/`, focusing on how well the `cursor-tools` features are incorporated into the MCP server implementation plan and whether it meets best practices.

Here's a breakdown of my review and final recommendations:

**Summary of `cursor-tools` Feature Integration in the MCP Plan:**

The `mcp-plan.md` and related documents (`cursor-tools-analysis.md`, `cursor-tools-implementation.md`, `mcp-detailed-steps.md`) demonstrate a strong understanding of how to translate `cursor-tools` functionalities into an MCP server architecture.

*   **Clear Mapping:** The analysis in `cursor-tools-analysis.md` effectively maps each `cursor-tools` command (web, repo, doc, github, browser) to potential MCP resources and tools.  It correctly identifies which functionalities are better suited as resources (like GitHub PRs/issues) and which are better as tools (like web search, documentation generation, browser automation).
*   **Detailed Implementation Steps:** `mcp-detailed-steps.md` provides a very granular, step-by-step guide to implementing a subset of `cursor-tools` features (web search, repo query, github PRs, browser open) as MCP resources and tools. This is excellent for beginner-friendliness.
*   **Practical Examples:** The detailed steps include code snippets for server setup, tool/resource modules, request handlers, and even a basic test client. This makes the plan very actionable.
*   **Prioritization and Simplification:** The plan intelligently suggests starting with a simplified approach, focusing on core features and `stdio` transport first, and gradually adding complexity. This is crucial for a beginner-friendly approach and allows for iterative development.
*   **Schema Awareness:** The plan recognizes the importance of schemas for request and response validation, although the initial examples are kept simple for clarity. `mcp-plan.md` includes example schema definitions within capability descriptions.
*   **Dependency Identification:** `cursor-tools-implementation.md` correctly identifies key dependencies and APIs (Perplexity, Gemini, GitHub API, Playwright) needed for implementing the features.

**Review against Best Practices (Based on `mcp-clarifications.md`, `mcp-research.md`, `mcp-final-review.md`):**

The plan incorporates many best practices for MCP server development, as highlighted in `mcp-final-review.md`:

*   **Security:** The plan acknowledges security best practices (TLS, authentication, input validation, rate limiting, logging security events). `mcp-final-review.md` suggests further elaboration on these, which is a valid point.
*   **Versioning and Backwards Compatibility:** The plan mentions semantic versioning and striving for backwards compatibility, although detailed versioning strategies for resources and tools could be further elaborated.
*   **Scaling:** The plan considers horizontal scaling and statelessness, especially for HTTP/SSE transport.
*   **State Management:**  The plan correctly recommends a stateless server design, which is a key best practice for scalability and simplicity.
*   **Error Handling and Logging:** The plan emphasizes graceful error handling and basic logging. `mcp-final-review.md` recommends more specific error response structures and structured logging.
*   **Documentation:**  The plan strongly emphasizes clear and comprehensive documentation, including a `README.md` and code comments, which is excellent for beginner-friendliness.
*   **Modular Design:** The modular architecture is a core principle, promoting maintainability and extensibility.
*   **Transport Layer Flexibility:** Planning for both `stdio` and HTTP/SSE provides flexibility for different use cases.

**Beginner-Friendliness Assessment (Based on `mcp-user-experience.md` and overall plan):**

The plan is very well-aligned with making the MCP server beginner-friendly:

*   **Simple Setup and Configuration:** The plan starts with `stdio` transport, which greatly simplifies setup. The detailed steps in `mcp-detailed-steps.md` are designed for beginners.
*   **Intuitive API Design:** While the server API is defined by the MCP protocol itself, the plan focuses on creating clear resource and tool names and descriptions. The example schemas also contribute to API clarity.
*   **Comprehensive Documentation:** The plan prioritizes documentation, including a `README.md` and code comments. `mcp-detailed-steps.md` itself acts as a detailed tutorial.
*   **Error Handling and Feedback:** The plan mentions error handling and logging, which are important for debugging and user feedback.
*   **Modular Design:** The modular design allows beginners to focus on implementing one tool or resource at a time, gradually learning and expanding their server.
*   **Interactive Learning Tools (Future):** While not yet implemented, the plan could potentially incorporate interactive elements like a CLI or playground in the future, as suggested in `mcp-user-experience.md`.

**Power and Flexibility Assessment:**

The plan lays a solid foundation for a powerful and flexible MCP server:

*   **Extensible Architecture:** The modular design and clear separation of concerns make the server architecture inherently extensible. New resources and tools can be added relatively easily.
*   **Support for Diverse Functionalities:** By mapping `cursor-tools` features, the plan demonstrates the potential to integrate a wide range of functionalities into the MCP server, from web search to browser automation and GitHub interactions.
*   **Scalability Potential:** Planning for HTTP/SSE transport and statelessness opens the door for scaling the server for more demanding applications.
*   **Future Enhancements:** The plan explicitly lists powerful features as future enhancements (multiple transports, robust error handling, schema validation, security, IDE integration), showing a forward-looking approach.

**Final Recommendations for Improvement:**

Based on my review and the points raised in `mcp-final-review.md`, here are my final recommendations to further improve the plan and its execution:

1.  **Schema Definition Examples:**  In `mcp-plan.md` and `mcp-detailed-steps.md`, add more concrete examples of schema definitions, especially using the MCP SDK's schema capabilities. Show how schemas are used for request and response validation in code. This will make schemas less abstract for beginners.

2.  **Detailed Error Handling Examples:** Expand on error handling in code examples. Show how to construct and return MCP-compliant error responses in request handlers. Provide examples of different error types and how to handle them gracefully.

3.  **Testing Strategy Expansion:**  Elaborate on the testing strategy. Provide examples of unit tests for handlers and integration tests to verify MCP protocol interactions.  Suggest a testing framework (like `jest` or `mocha` for Node.js) and demonstrate basic test cases.

4.  **Security Best Practices - Actionable Steps:** For each security best practice mentioned, provide more actionable steps and code snippets or references. For example:
    *   **Input Validation:** Show examples of using libraries like `joi` or `zod` for input validation in request handlers.
    *   **TLS for HTTP/SSE:** Briefly explain how to set up HTTPS in Node.js using `https` module or `express` with TLS certificates.
    *   **Authentication:**  Suggest a simple authentication method like API keys for initial implementation and provide a basic example of how to implement API key authentication in a tool/resource.
    *   **Rate Limiting:** Recommend a Node.js rate limiting middleware (e.g., `express-rate-limit`) and show a basic configuration example.

5.  **Structured Logging Example:** Demonstrate how to implement structured logging (e.g., using `pino` or `winston` with JSON format) in the server. Show how to log requests, responses, and errors with different log levels.

6.  **Health Check Endpoint Example:** Include a code snippet for implementing a basic health check endpoint in Node.js (e.g., using `http` module or `express` to create a `/healthz` endpoint).

7.  **Basic MCP Client Example:**  Provide a minimal, runnable Node.js script using `@modelcontextprotocol/sdk/client` to interact with the server. This client should demonstrate sending `ListResourcesRequest`, `ReadResourceRequest`, and `ExecuteToolRequest` and handling responses. This will be extremely helpful for beginners to test and understand client-server interaction.

8.  **Deployment Considerations (Brief Overview):** Add a brief section on deployment considerations, mentioning containerization with Docker and potential cloud deployment platforms (like AWS, Google Cloud, or Azure). This will give a more complete picture of the server's lifecycle.

**Final Conclusion:**

The documentation and implementation plan for the MCP server are **excellent and well-structured**. They effectively integrate `cursor-tools` features and address many MCP server best practices. By incorporating the final recommendations, especially by adding more concrete examples for schemas, error handling, testing, security, logging, client interaction, and deployment, the plan will become even more robust, beginner-friendly, and practically valuable for developers looking to build MCP servers. The plan is already very strong and these additions will make it truly outstanding.
</file>

<file path="local-research/mcp-final-review.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, I've reviewed the documentation generated in `local-research/`, specifically `mcp-clarifications.md`, `mcp-plan.md`, `mcp-research.md`, and `mcp-user-experience.md`. Here's my final assessment of the `mcp-plan.md` against global best practices for MCP server development:

**Overall Assessment:**

The `mcp-plan.md` is a well-structured and comprehensive plan for developing a beginner-friendly MCP server. It successfully incorporates many best practices identified in the research and user experience considerations. The plan is particularly strong in its step-by-step implementation guide, focus on `stdio` transport for initial simplicity, and emphasis on clear documentation.

**Strengths of the Plan:**

*   **Beginner-Friendly Approach:** The plan explicitly prioritizes beginner-friendliness by starting with `stdio`, simple examples, and clear documentation. This aligns strongly with the user experience research.
*   **Modular Architecture:** The plan emphasizes a modular design, separating concerns into core logic, resource/tool providers, and configuration. This promotes maintainability, extensibility, and allows for gradual feature adoption, as recommended for beginner-friendly systems.
*   **Step-by-Step Implementation Guide:** The detailed, numbered implementation steps with code snippets provide a clear and actionable path for development, making it easy for someone new to MCP to follow.
*   **Focus on Core MCP Concepts:** The plan correctly focuses on resources and tools as the initial capabilities, which are fundamental to MCP.
*   **Inclusion of Best Practices:** The plan explicitly addresses security, versioning, scaling, and state management best practices in a dedicated section, demonstrating awareness of these critical aspects.
*   **Documentation Emphasis:**  The plan highlights the importance of documentation, including a `README.md` and code comments, crucial for beginner onboarding.
*   **Iterative Development Approach:** The plan promotes iterative refinement and expansion, suggesting starting simple and gradually adding features, which is a practical approach for complex projects and aligns with agile methodologies.
*   **Transport Layer Flexibility:**  Planning for both `stdio` and HTTP/SSE transport layers offers flexibility for different deployment scenarios and future scalability.

**Areas for Improvement and Additional Consideration:**

*   **Schema Definition Depth:** While the plan mentions schema definitions, it could benefit from more concrete examples of schema usage and how they contribute to type safety and validation.  Perhaps adding a simple schema definition example using the MCP SDK's schema capabilities would be beneficial.
*   **Error Handling Specificity:**  The plan mentions error handling but could elaborate further on specific error response structures according to MCP conventions and best practices for providing informative error messages to clients. Showcasing how to return MCP-compliant error responses would be helpful.
*   **Testing Strategy Details:** The plan mentions testing but lacks specifics. It could be improved by outlining a more detailed testing strategy. This could include:
    *   Unit tests for individual handlers and modules.
    *   Integration tests to verify the interaction between server components and the MCP protocol.
    *   Example test cases for resources and tools.
    *   Guidance on using testing frameworks suitable for Node.js.
*   **Security Best Practices Elaboration:** While security is mentioned, the plan could provide more specific and actionable steps for each security best practice. For example:
    *   **Input Validation:**  Provide examples of input validation techniques in the request handlers.
    *   **TLS for HTTP/SSE:** Briefly mention how to configure TLS for an HTTP server in Node.js when implementing HTTP/SSE transport.
    *   **Authentication:**  Suggest a few common authentication methods suitable for MCP servers (e.g., API keys, JWT) and point to resources for implementation.
    *   **Rate Limiting:** Recommend libraries or techniques for implementing rate limiting in a Node.js server.
*   **Logging Best Practices:** Expand on logging recommendations. Suggest using structured logging (e.g., JSON format) for easier analysis and integration with logging tools. Recommend what kind of information should be logged at different levels (info, warning, error).
*   **Health Checks Implementation:** Provide a code snippet or guidance on how to implement a basic health check endpoint in Node.js.
*   **Client Interaction Examples:** While `cursor-tools` was mentioned (and noted as not ideal for this purpose), providing a simple, runnable example of a basic MCP client (even a very minimal Node.js script using the MCP SDK client library) would be extremely helpful for beginners to test and understand how to interact with the server.
*   **Deployment Considerations (briefly):**  Although the initial focus is local development, briefly touching upon deployment considerations (e.g., containerization with Docker, cloud deployment platforms) would provide a more complete picture for users looking to move beyond local testing.

**Final Recommendation:**

The `mcp-plan.md` is a solid foundation for building a beginner-friendly MCP server. The plan effectively balances simplicity with the necessary considerations for a robust server.  By incorporating the suggested improvements, particularly by adding more detail and concrete examples around schema definition, error handling, testing, security, logging, client interaction, and deployment, the plan will become even more comprehensive and valuable, further enhancing its beginner-friendliness and practical utility.

**In summary, the plan is very good and meets global best practices for MCP server development at a high level. Addressing the areas for improvement will elevate it to an excellent and highly actionable guide.**
</file>

<file path="local-research/mcp-implementation-plan.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, based on all the research in `local-research/`, here's a comprehensive implementation plan for our MCP server, designed to be both beginner-friendly and powerful, drawing inspiration from Claude's MCP, popular servers, and best practices:

## MCP Server Implementation Plan: Beginner-Friendly & Powerful

**I. Project Goals & Principles:**

*   **Goal:** Build an MCP server that mirrors the core functionalities of `cursor-tools`, providing AI assistance for web search, repository context, GitHub information, and browser automation.
*   **Beginner-Friendliness:**  Prioritize ease of installation, setup, and initial use. Offer a smooth onboarding experience for developers new to MCP.
*   **Power & Flexibility:** Design an extensible and modular architecture that can be easily expanded with new resources, tools, and features. Ensure scalability and robustness for future growth.
*   **Best Practices:**  Incorporate security, versioning, error handling, logging, and documentation best practices throughout the development process.
*   **Iterative Development:** Adopt an iterative approach, starting with core features and progressively adding complexity and enhancements.

**II. Architectural Design:**

1.  **Client-Server Model:** Adhere to the standard MCP client-server architecture using `@modelcontextprotocol/sdk` (Node.js).
2.  **Transport Layer:**
    *   **Initial:** `stdio` (Standard Input/Output) for local development and beginner simplicity.
    *   **Future:** HTTP/SSE (Server-Sent Events) for remote access, scalability, and broader deployment scenarios.
3.  **Modular Design:**
    *   **Core Server:** Handles MCP protocol, request routing, and capability registration.
    *   **Capabilities:** Organized into `resources/` and `tools/` directories, each in its own module for maintainability and extensibility.
    *   **Schemas:**  `schemas/` directory to store JSON schemas for request and response validation, ensuring type safety and clear API contracts.
    *   **Configuration:**  `config/` directory for server configuration (API keys, settings), using environment variables for sensitive information.
4.  **Statelessness:**  Design server components to be as stateless as possible for improved scalability and simplified management.
5.  **Error Handling & Logging:** Implement robust error handling with MCP-compliant error responses. Utilize structured logging for debugging and monitoring.

**III. Implementation Phases & Steps:**

**Phase 1: Project Setup & Basic Server Core (Beginner-Focused)**

1.  **Step 1: Project Initialization:**
    *   Create project directory: `mkdir mcp-server && cd mcp-server`
    *   Initialize Node.js project: `npm init -y`
    *   Install MCP SDK: `npm install @modelcontextprotocol/sdk node-fetch` (for API interactions)

2.  **Step 2: Create Basic `server.js`:**
    ```javascript
    // server.js
    import { Server } from "@modelcontextprotocol/sdk/server/index.js";
    import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

    async function main() {
        const server = new Server({
            name: "cursor-tools-mcp-server",
            version: "0.1.0",
            description: "MCP server mimicking cursor-tools functionalities."
        }, {
            capabilities: {
                resources: {},
                tools: {}
            }
        });

        const transport = new StdioServerTransport();
        await server.connect(transport);
        console.log("MCP Server started using stdio transport.");
    }

    main().catch(console.error);
    ```

3.  **Step 3: Run the Basic Server:**
    *   Execute: `node server.js`
    *   Verify output: "MCP Server started using stdio transport."

**Phase 2: Implement Web Search Tool (`cursor-tools web`)**

1.  **Step 4: Create `web-search.js` Tool Module:**
    *   Create directories: `mkdir -p capabilities/tools`
    *   Create file: `capabilities/tools/web-search.js`
    *   Implement `webSearchTool` (using Perplexity API - refer to `mcp-detailed-steps.md` and `cursor-tools-implementation.md` for code structure and API interaction).  Remember to use environment variables for `PERPLEXITY_API_KEY`.

2.  **Step 5: Register `web-search` Tool:**
    *   Modify `server.js` to import and register `webSearchTool` in `capabilities.tools`.

3.  **Step 6: Set Perplexity API Key:**
    *   Instruct users to obtain a Perplexity API key and set the `PERPLEXITY_API_KEY` environment variable.

4.  **Step 7: Test `web-search` Tool:**
    *   Create `test-client.js` (based on `mcp-detailed-steps.md`) to send `ExecuteToolRequest` for `web-search`.
    *   Run server in one terminal (`node server.js`), client in another (`node test-client.js`).
    *   Verify web search results are returned.

**Phase 3: Implement GitHub PRs Resource (`cursor-tools github pr`)**

1.  **Step 8: Create `github-pr.js` Resource Module:**
    *   Create directory: `mkdir capabilities/resources`
    *   Create file: `capabilities/resources/github-pr.js`
    *   Implement `githubPullRequestResource` (using GitHub API - refer to `mcp-detailed-steps.md` and `cursor-tools-implementation.md` for code structure and API interaction). Use environment variable for `GITHUB_TOKEN` (optional but recommended).

2.  **Step 9: Register `github-pr` Resource:**
    *   Modify `server.js` to import and register `githubPullRequestResource` in `capabilities.resources`.

3.  **Step 10: Set GitHub Token (Optional):**
    *   Instruct users on how to create a GitHub personal access token and set `GITHUB_TOKEN` for higher rate limits.

4.  **Step 11: Test `github-pr` Resource:**
    *   Modify `test-client.js` to test `ListResourcesRequest` and `ReadResourceRequest` for `github-pr` (refer to `mcp-detailed-steps.md`).
    *   Run client and server, verify PR list and details are retrieved.

**Phase 4: Implement Browser Open Tool (`cursor-tools browser open`)**

1.  **Step 12: Install Playwright:**
    *   Instruct users to install Playwright: `npm install playwright`

2.  **Step 13: Create `browser-open.js` Tool Module:**
    *   Create directory: `mkdir -p capabilities/tools/browser-automation`
    *   Create file: `capabilities/tools/browser-automation/browser-open.js`
    *   Implement `browserOpenTool` (using Playwright - refer to `mcp-detailed-steps.md` and `cursor-tools-implementation.md` for code structure and Playwright usage).

3.  **Step 14: Register `browser-open` Tool:**
    *   Modify `server.js` to import and register `browserOpenTool` in `capabilities.tools`.

4.  **Step 15: Test `browser-open` Tool:**
    *   Modify `test-client.js` to test `ExecuteToolRequest` for `browser-open` (refer to `mcp-detailed-steps.md`).
    *   Run client and server, verify browser automation and screenshot functionality.

**Phase 5:  Repository Context Tool (Simplified `cursor-tools repo`)**

1.  **Step 16: Create `repo-query.js` Tool Module:**
    *   Create file: `capabilities/tools/repo-query.js`
    *   Implement `repoQueryTool` (using Gemini API - refer to `mcp-detailed-steps.md` and `cursor-tools-implementation.md` for code structure and Gemini API interaction).  Initially, implement a *simplified* version without deep repository indexing, focusing on general code questions. Use environment variable for `GOOGLE_API_KEY`.

2.  **Step 17: Register `repo-query` Tool:**
    *   Modify `server.js` to import and register `repoQueryTool` in `capabilities.tools`.

3.  **Step 18: Set Google API Key:**
    *   Instruct users to obtain a Google Cloud API key with Gemini API access and set `GOOGLE_API_KEY` environment variable.

4.  **Step 19: Test `repo-query` Tool:**
    *   Modify `test-client.js` to test `ExecuteToolRequest` for `repo-query` (refer to `mcp-detailed-steps.md`).
    *   Run client and server, verify Gemini-powered code question answering.

**Phase 6: Documentation, Refinement & Best Practices Integration**

1.  **Step 20: Comprehensive Documentation (Beginner-Focused):**
    *   **README.md:** Create a detailed README.md with:
        *   Project description and goals.
        *   **Clear Installation Instructions:** Step-by-step guide using `npm install`, environment variable setup for API keys, and Playwright installation.
        *   **Quick Start Guide:**  Simple example of using `test-client.js` to interact with the server.
        *   **Capabilities Overview:** Explain the provided resources (`github-pr`) and tools (`web-search`, `browser-open`, `repo-query`).
        *   **Troubleshooting Guide:** Common issues and solutions.
        *   **Contribution Guide:** Encourage community contributions.
    *   **Code Comments:** Add clear and concise comments throughout the codebase.

2.  **Step 21: Implement Robust Error Handling:**
    *   Refine error handling in all resource and tool modules to return MCP-compliant error responses with descriptive messages.
    *   Use `try...catch` blocks and throw appropriate errors.

3.  **Step 22: Implement Structured Logging:**
    *   Integrate a logging library (e.g., `pino` or `winston`).
    *   Log requests, responses, errors, and important server events with appropriate log levels.
    *   Use JSON format for logs for easier analysis.

4.  **Step 23: Basic Input Validation:**
    *   Implement basic input validation in request handlers to check for required parameters and data types.
    *   Consider using schema validation from MCP SDK for more robust validation in the future.

5.  **Step 24: Testing Strategy Expansion:**
    *   Write basic unit tests for individual tool and resource handlers.
    *   Expand `test-client.js` to include more comprehensive integration tests for different scenarios and edge cases.

**Phase 7: Future Enhancements (Power & Flexibility)**

1.  **Step 25: HTTP/SSE Transport Implementation:**
    *   Add support for HTTP/SSE transport using `HttpServerTransport` or `SseServerTransport` from the MCP SDK.
    *   Set up an HTTP server (using Node.js `http` or `express`).
    *   Provide instructions on how to run the server with HTTP/SSE transport.

2.  **Step 26: Advanced Schema Validation:**
    *   Implement full schema validation using the MCP SDK's schema capabilities for all requests and responses.
    *   Define schemas in separate `.json` files in `schemas/` directory.

3.  **Step 27: Security Enhancements:**
    *   **TLS for HTTP/SSE:** Configure HTTPS for HTTP/SSE transport.
    *   **Authentication:** Implement a basic authentication mechanism (e.g., API keys) for remote access via HTTP/SSE.
    *   **Rate Limiting:**  Implement rate limiting middleware for HTTP/SSE transport to prevent abuse.

4.  **Step 28: Advanced Repository Context (Indexing):**
    *   Enhance `repo-query` tool with repository indexing for deeper context-aware answers.
    *   Explore code parsing libraries and potentially vector databases for efficient code indexing and semantic search (as discussed in `cursor-tools-implementation.md`).

5.  **Step 29: Implement Remaining `cursor-tools browser` Features:**
    *   Implement `browser-act`, `browser-observe`, and `browser-extract` tools, following the pattern of `browser-open`.

6.  **Step 30: Health Check Endpoint:**
    *   Implement a basic health check endpoint (e.g., `/healthz` for HTTP/SSE).

7.  **Step 31: Deployment Considerations Documentation:**
    *   Add a section in `README.md` on basic deployment considerations (Docker, cloud platforms).

**IV. Technology Stack:**

*   **Language:** JavaScript (Node.js)
*   **MCP SDK:** `@modelcontextprotocol/sdk` (Node.js)
*   **HTTP Client:** `node-fetch` (or `axios`)
*   **Browser Automation:** `playwright`
*   **AI APIs:** Perplexity AI API, Google Gemini API
*   **Logging:** (e.g., `pino`, `winston`)
*   **Testing:** (e.g., `jest`, `mocha`)

**V.  Beginner-Friendliness Features Summary:**

*   **`stdio` Transport First:** Simplifies initial setup and testing.
*   **Detailed Step-by-Step Guide:**  Phased implementation plan with granular steps.
*   **Clear Installation Instructions:**  Emphasis on npm, environment variables, and Playwright setup.
*   **Quick Start Example:** `test-client.js` for immediate interaction.
*   **Comprehensive README.md:**  Well-structured documentation with troubleshooting and examples.
*   **Modular Design:**  Allows for gradual learning and feature adoption.
*   **Simple Examples:** Start with basic resources and tools to illustrate core concepts.

**VI. Power & Flexibility Features Summary:**

*   **Extensible Architecture:** Modular design for easy addition of new capabilities.
*   **HTTP/SSE Transport Support:** Enables remote access and scalability.
*   **Schema Validation:** Ensures API contract and data integrity.
*   **Robust Error Handling & Logging:**  Production-ready server characteristics.
*   **Security Best Practices Integration:**  Protects server and data.
*   **Advanced Features Planned:** Repository indexing, full browser automation suite, health checks, deployment considerations.

This implementation plan provides a structured roadmap for building a beginner-friendly yet powerful MCP server. By following these phases and steps, and continuously referring to the research and best practices, we can create a valuable tool that effectively integrates AI assistance into development workflows. Remember to prioritize clear communication, documentation, and iterative development throughout the process.
</file>

<file path="local-research/mcp-installation-research.md">
Querying Perplexity AI using sonar-pro for: Research on Claude Anthropic's Model Context Protocol implementation, installation process, and user onboarding. Also find the top 5 most starred MCP servers on GitHub and their installation processes. Focus on user experience and ease of installation.
Claude's Model Context Protocol (MCP) enables integration between AI assistants and external data sources/tools. Key aspects of implementation and installation:

1. Install Claude Desktop app[1][2]
2. Edit Claude Desktop config file to add MCP servers[1][2]
3. Restart Claude app[6]

User onboarding steps:
1. Download Claude Desktop
2. Add Filesystem MCP server to config
3. Restart Claude
4. Test functionality[6]

Top 5 most starred MCP servers on GitHub (as of February 2025):

1. filesystem-mcp: File system access
Installation: `npm install @modelcontextprotocol/server-filesystem`

2. github-mcp: GitHub integration 
Installation: `npm install @modelcontextprotocol/server-github`

3. slack-mcp: Slack integration
Installation: `npm install @modelcontextprotocol/server-slack`

4. postgres-mcp: PostgreSQL database access
Installation: `npm install @modelcontextprotocol/server-postgres`

5. brave-search-mcp: Brave Search integration
Installation: `npm install @modelcontextprotocol/server-brave-search`

User experience is generally straightforward, with most servers installable via npm. Claude Desktop provides a GUI for enabling installed servers[1][2][6].
</file>

<file path="local-research/mcp-plan.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Okay, let's develop a comprehensive plan for building an MCP server.

## Model Context Protocol (MCP) Server Development Plan

**Introduction:**

The Model Context Protocol (MCP) is emerging as a crucial standard for enabling seamless communication between Large Language Model (LLM) applications and external resources and tools. By building an MCP server, we can provide AI agents with structured access to valuable context, enhancing their capabilities within IDEs and other environments. This plan outlines the steps for developing an MCP server that is designed to be both approachable for beginners and robust enough to handle complex interactions.

**I. Architecture Decisions:**

Based on our research, we will adopt the following architectural principles:

*   **Client-Server Model:** We will adhere to the standard MCP client-server architecture. Our server will act as a provider of resources and tools, responding to requests from MCP clients (like AI IDE extensions or agents).
*   **Protocol Layer (MCP SDK):** We will leverage the official MCP SDK (likely the Node.js SDK based on the research example) to handle the underlying protocol complexities, message framing, and schema validation. This ensures compliance and simplifies development.
*   **Transport Layer (Initial: stdio, Future: HTTP/SSE):**
    *   **stdio (Standard Input/Output):**  We will initially implement the `stdio` transport. This is ideal for local development, testing, and scenarios where the MCP client and server run on the same machine. `stdio` simplifies setup and debugging for beginners.
    *   **HTTP/SSE (Server-Sent Events):**  For future expansion and remote access, we will plan for supporting HTTP/SSE. This will enable the server to be hosted independently and accessed by clients over a network.
*   **Modular Design:** The server will be designed with modularity in mind. This means separating concerns into distinct modules, such as:
    *   **Core Server Logic:** Handling MCP protocol interactions, request routing, and capability management.
    *   **Resource Providers:** Modules responsible for fetching and managing specific types of resources (e.g., file system resources, database resources, API data).
    *   **Tool Providers:** Modules implementing specific tools or actions that the server can expose.
    *   **Configuration & Management:**  Handling server configuration, logging, and potentially health checks.
*   **Statelessness:**  We will aim for a stateless server design as much as possible. This improves scalability and simplifies management. Session-specific data should be avoided or handled externally (e.g., by the client or a separate data store) if absolutely necessary.

**II. Implementation Steps:**

Here are the step-by-step instructions to build the MCP server:

1.  **Project Setup:**
    *   **Initialize Node.js Project:**
        ```bash
        mkdir mcp-server
        cd mcp-server
        npm init -y
        ```
    *   **Install MCP SDK:**
        ```bash
        npm install @modelcontextprotocol/sdk
        ```
    *   **(Optional) Install Playwright for potential future browser-based tools:**
        ```bash
        npm install playwright
        ```

2.  **Basic Server Structure (e.g., `server.js`):**
    ```javascript
    // server.js
    import { Server } from "@modelcontextprotocol/sdk/server/index.js";
    import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
    // Import Schemas for requests and responses (as needed - will be defined later)
    // Example schema import (replace with actual schemas):
    // import { ListResourcesRequestSchema, ListResourcesResponseSchema } from './schemas.js';

    async function main() {
        const server = new Server({
            name: "beginner-friendly-mcp-server",
            version: "0.1.0",
            description: "A beginner-friendly MCP server example."
        }, {
            capabilities: {
                resources: { // Define resource capabilities here},
                tools: {      // Define tool capabilities here}
                // prompts: {     // Define prompt capabilities here - optional for initial version}
            }
        });

        // Example Request Handler (for ListResources - adapt based on your schemas)
        // server.setRequestHandler(ListResourcesRequestSchema, async (request) => {
        //     // ... your resource listing logic ...
        //     return { resources: [] }; // Replace with actual resources
        // });


        const transport = new StdioServerTransport();
        await server.connect(transport);
        console.log("MCP Server started using stdio transport.");
    }

    main().catch(console.error);
    ```

3.  **Define Capabilities (Resources and Tools):**
    *   **Start Simple:** For a beginner-friendly approach, begin with a very basic resource and tool. For example:
        *   **Resource:**  A "greeting" resource that returns a simple greeting message.
        *   **Tool:** A "reverse-string" tool that reverses a given string.
    *   **Define Schemas (if needed):**  For more complex interactions, you'll need to define schemas using the MCP SDK's schema definition capabilities. For simple examples, you might be able to start without explicit schemas and use basic JavaScript objects for requests and responses initially for rapid prototyping, but strongly consider adding them for type safety and robustness as you progress.
    *   **Example Capability Definitions (in `server.js` - within `capabilities`):**
        ```javascript
        capabilities: {
            resources: {
                'greeting': { // Resource name
                    list: {  // Capability: listing resources of this type
                        // Optionally define request schema here if needed
                        responseSchema: { // Define response schema
                            type: 'object',
                            properties: {
                                resources: {
                                    type: 'array',
                                    items: {
                                        type: 'object',
                                        properties: {
                                            uri: { type: 'string', description: 'Unique URI for the greeting resource' },
                                            message: { type: 'string', description: 'The greeting message' }
                                        },
                                        required: ['uri', 'message']
                                    }
                                },
                                required: ['resources']
                            }
                        }
                    },
                    read: { // Capability: reading a specific resource
                        requestSchema: { // Define request schema (e.g., for resource URI)
                            type: 'object',
                            properties: {
                                uri: { type: 'string', description: 'URI of the greeting resource to read' }
                            },
                            required: ['uri']
                        },
                        responseSchema: { // Define response schema
                            type: 'object',
                            properties: {
                                resource: {
                                    type: 'object',
                                    properties: {
                                        uri: { type: 'string' },
                                        message: { type: 'string' }
                                    },
                                    required: ['uri', 'message']
                                }
                            },
                            required: ['resource']
                        }
                    }
                }
            },
            tools: {
                'reverseString': { // Tool name
                    execute: { // Capability: executing the tool
                        requestSchema: { // Define request schema (input for the tool)
                            type: 'object',
                            properties: {
                                text: { type: 'string', description: 'Text to reverse' }
                            },
                            required: ['text']
                        },
                        responseSchema: { // Define response schema (output of the tool)
                            type: 'object',
                            properties: {
                                reversedText: { type: 'string', description: 'Reversed text' }
                            },
                            required: ['reversedText']
                        }
                    }
                }
            }
        }
        ```

4.  **Implement Request Handlers:**
    *   **`ListResources` Handler (for "greeting" resource):**
        ```javascript
        server.setRequestHandler('greeting/list', async () => {
            return {
                resources: [
                    { uri: 'greeting://default', message: 'Hello from MCP Server!' },
                    { uri: 'greeting://custom', message: 'Greetings, user!' }
                ]
            };
        });
        ```
    *   **`ReadResource` Handler (for "greeting" resource):**
        ```javascript
        server.setRequestHandler('greeting/read', async (request) => {
            const { uri } = request;
            let message = '';
            if (uri === 'greeting://default') {
                message = 'Hello from MCP Server!';
            } else if (uri === 'greeting://custom') {
                message = 'Greetings, user!';
            } else {
                throw new Error(`Resource URI not found: ${uri}`); // Error handling
            }
            return {
                resource: { uri, message }
            };
        });
        ```
    *   **`ExecuteTool` Handler (for "reverseString" tool):**
        ```javascript
        server.setRequestHandler('reverseString/execute', async (request) => {
            const { text } = request;
            const reversedText = text.split('').reverse().join('');
            return {
                reversedText: reversedText
            };
        });
        ```

5.  **Testing the Server:**
    *   **Using `cursor-tools` (as a basic client):** You can use `cursor-tools` to interact with your MCP server if it supports `stdio`.  However, `cursor-tools` is primarily designed to *use* tools, not act as a generic MCP client *to* a server you're building. For basic testing, you might need to use a more direct MCP client library or write a simple test script.
    *   **Simple Test Script (Node.js):** Create a file (e.g., `test-client.js`) to send requests to your server via `stdio`.  (Example would be more involved and might be a separate task to detail).
    *   **Manual Testing (using MCP Client SDK directly):** Write a small Node.js script that uses the `@modelcontextprotocol/sdk/client` to connect to your server and send requests. This gives you more direct control for testing.

6.  **Error Handling and Logging:**
    *   **Graceful Error Handling:** Implement `try...catch` blocks in your request handlers to catch errors and return informative error responses (as defined by MCP error handling conventions).
    *   **Basic Logging:** Use `console.log` or a more robust logging library (like `winston` or `pino`) to log server events, requests, responses, and errors. This is crucial for debugging and monitoring.

7.  **Documentation (for Beginners):**
    *   **README.md:** Create a `README.md` file in your project root. Include:
        *   Project description (beginner-friendly MCP server).
        *   Setup instructions (Node.js and dependencies).
        *   Running instructions (`node server.js`).
        *   Examples of how to interact with the server (even basic curl examples if using HTTP/SSE later, or instructions for a simple test client).
        *   Explanation of the provided resources and tools.
    *   **Code Comments:** Add clear and concise comments in your code to explain the logic, especially in request handlers and capability definitions.

8.  **Iterative Refinement and Expansion:**
    *   **Add More Resources and Tools:** Gradually expand the server by adding more useful resources and tools. Think about what kind of context or actions would be valuable for AI agents in an IDE or other applications.
    *   **Implement HTTP/SSE Transport:**  Once the `stdio` version is working, add support for HTTP/SSE transport. This will involve using `HttpServerTransport` or `SseServerTransport` from the MCP SDK and setting up an HTTP server (using Node.js `http` or a framework like `express`).
    *   **Security Enhancements:** Implement security best practices as outlined in the research (TLS, authentication, input validation, rate limiting). Start with input validation and consider adding authentication later if needed for remote access.
    *   **Configuration Management:** Externalize configuration (e.g., using environment variables or a configuration file) for server settings, resource locations, etc.
    *   **Health Checks:** Implement a health check endpoint to allow monitoring of server availability.
    *   **Performance Profiling:**  Profile the server's performance and optimize as needed, especially if you are dealing with complex resources or tools.


**III. Best Practices:**

*   **Security:**
    *   **Input Validation:**  Thoroughly validate all incoming requests to prevent injection attacks and ensure data integrity.
    *   **TLS for Remote Connections (HTTP/SSE):**  Enforce TLS (HTTPS) for all remote connections to protect data in transit.
    *   **Authentication (for Remote Access):**  Implement authentication mechanisms if your server will be accessed remotely and needs to control access.
    *   **Rate Limiting:** Implement rate limiting to prevent abuse and ensure server stability.
    *   **Logging Security Events:** Log security-relevant events for auditing and intrusion detection.
*   **Versioning and Backwards Compatibility:**
    *   **Semantic Versioning:** Use semantic versioning for your server (e.g., `0.1.0`, `1.0.0`, `1.1.0`).
    *   **Backwards Compatibility:** Strive to maintain backwards compatibility when making changes. When breaking changes are necessary, introduce them in new versions and consider providing migration paths.
    *   **API Versioning (if needed):** For more complex servers with evolving APIs, consider API versioning (e.g., `/v1/resources`, `/v2/resources`).
*   **Scaling:**
    *   **Horizontal Scaling (for HTTP/SSE):** Design the server to be horizontally scalable. This means you should be able to run multiple instances of the server behind a load balancer to handle increased load. Statelessness helps with horizontal scaling.
    *   **Autoscaling (Future Consideration):** For production deployments, consider autoscaling to dynamically adjust the number of server instances based on demand.
    *   **Meaningful Load Metrics:** Monitor relevant metrics (request rate, latency, resource usage) to understand server load and identify scaling needs.
*   **State Management:**
    *   **Stateless Server (Recommended):** Aim for a stateless server design. Avoid storing session-specific data within the server process.
    *   **External Data Stores:** If persistent data is required, use external databases or caching mechanisms rather than relying on server-side session state.

**IV. Beginner-Friendly Features:**

*   **Simple `stdio` Transport:** Start with `stdio` for easy local testing and development without needing to configure network settings.
*   **Minimalistic Examples:** Provide simple, easy-to-understand examples of resources and tools.
*   **Clear Documentation:** Focus on clear and concise documentation, especially in the `README.md`, to guide beginners through setup, running, and basic usage.
*   **Step-by-Step Guide:**  The implementation steps outlined above are designed to be a step-by-step guide for building the server incrementally.
*   **Focus on Core Concepts:** Initially, focus on the core MCP concepts of resources, tools, and request handling, without overwhelming beginners with advanced features.

**V. Powerful Features (Future Enhancements):**

*   **Extensible Resource and Tool System:** Design the server to be easily extensible, allowing developers to add new resource providers and tools as needed. Use a plugin-based architecture or modular design to facilitate this.
*   **Support for Multiple Transport Layers:**  Supporting both `stdio` and HTTP/SSE provides flexibility for different deployment scenarios (local vs. remote).
*   **Robust Error Handling and Logging:**  Comprehensive error handling and logging are essential for production-ready servers.
*   **Schema Validation:**  Enforce schema validation for requests and responses to ensure data integrity and type safety (using the MCP SDK's schema capabilities).
*   **Security Features:**  Implement robust security features as described in best practices to protect the server and its data.
*   **Integration with AI IDEs:**  As the MCP ecosystem matures, aim for seamless integration with popular AI IDEs by providing resources and tools that are relevant to code editing, analysis, and generation workflows.


**Conclusion:**

This plan provides a roadmap for building a beginner-friendly yet powerful MCP server. By starting with a simple architecture, focusing on core concepts, and iteratively adding features and best practices, we can create a valuable tool for enabling AI agents with contextual awareness. The initial focus on `stdio` transport and basic resources/tools makes it approachable for beginners, while the planned expansions and best practices ensure the server can evolve into a robust and scalable solution. Remember to prioritize clear documentation and incremental development to make the process manageable and successful.
</file>

<file path="local-research/mcp-research.md">
Querying Perplexity AI using sonar-pro for: Detailed research on Model Context Protocol (MCP) server architecture, implementation best practices, and guidelines for generating project artifacts and IDE rules. Include specific details about server design, rule generation, and integration with AI IDEs.
The Model Context Protocol (MCP) is an open standard for communication between LLM applications and external data sources/tools[1][4]. Key aspects of MCP server architecture and implementation include:

Architecture:
- Client-server model with hosts (LLM apps), clients (maintain 1:1 connections), and servers (provide context/tools)[1]
- Protocol layer handles message framing and communication patterns[1]
- Transport layer supports stdio (local) and HTTP/SSE (remote) communication[1]

Claude's MCP Implementation:
- Anthropic implements MCP in Claude through a standardized interface for accessing external tools and context
- Installation is handled through the Claude API client libraries (Python, Node.js, etc.)
- Users don't need to install MCP separately - it's built into the Claude SDK
- Claude's implementation focuses on security and validation of tool/context access
- Provides built-in support for common tools like web search, file operations, and code analysis

Popular MCP Server Implementations (by GitHub stars):

1. cursor-tools (2.3k stars)
   - Installation: `npm install -g cursor-tools`
   - Simple CLI-based installation and usage
   - Excellent documentation and examples
   - Focus on IDE integration and developer tools

2. mcp-server (1.8k stars)
   - Installation: `npm install @mcp/server`
   - Modular architecture with plugin support
   - Comprehensive security features
   - Built-in monitoring and scaling support

3. anthropic-mcp (1.5k stars)
   - Installation: `pip install anthropic-mcp`
   - Official Anthropic MCP reference implementation
   - Extensive documentation and tutorials
   - Strong focus on security and validation

4. mcp-toolkit (1.2k stars)
   - Installation: `npm install mcp-toolkit`
   - Batteries-included approach with many tools
   - Easy-to-use API and configuration
   - Active community and regular updates

5. mcp-core (900 stars)
   - Installation: `npm install mcp-core`
   - Minimal, lightweight implementation
   - Focus on performance and stability
   - Excellent for learning and customization

Best Practices for Easy Installation:
- Provide clear installation instructions in README
- Use standard package managers (npm, pip)
- Include quick start guides and examples
- Automate dependency installation
- Provide configuration templates
- Include troubleshooting guides

Server implementation:
```javascript
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

const server = new Server({
  name: "example-server",
  version: "1.0.0"
}, {
  capabilities: {
    resources: {}
  }
});

server.setRequestHandler(ListResourcesRequestSchema, async () => {
  return {
    resources: [
      {
        uri: "example://resource",
        name: "Example Resource"
      }
    ]
  };
});

const transport = new StdioServerTransport();
await server.connect(transport);
```

Best practices:
- Use stdio transport for local processes, SSE for remote[1]
- Validate inputs, use type-safe schemas, handle errors gracefully[1]
- Implement timeouts and progress reporting for long operations[1]
- Use TLS for remote connections, validate origins, implement authentication[1]
- Log protocol events, implement health checks, profile performance[1]

For generating project artifacts and IDE rules:
- MCP servers can provide resources (data), tools (actions), and prompts (templates)[4][6]
- Servers expose functionality through endpoints like resources/list, resources/read[6]
- AI IDEs like IntelliJ IDEA use MCP to access project structure and code context[6]

Integration with AI IDEs:
- Implement MCP servers to expose project artifacts, code structure, and IDE functionality[6]
- Use resources to represent files, database records, API responses[6]
- Implement tools for code generation, refactoring, and other IDE actions
- Create prompts for common coding tasks and interactions

Rule generation:
- Define schemas for different artifact types (e.g. code files, models, configs)
- Implement validation logic in MCP server to enforce project rules
- Expose rule checking as MCP tools that can be invoked by AI agents

Example rule implementation:
```javascript
server.setRequestHandler(CheckCodeStyleSchema, async (request) => {
  const { code } = request;
  const violations = linter.checkStyle(code);
  return {
    valid: violations.length === 0,
    violations: violations
  };
});
```
</file>

<file path="local-research/mcp-setup-guide.md">
# Beginner-Friendly MCP Server Setup Guide

This guide will walk you through setting up a basic Model Context Protocol (MCP) server with initial functionality. We'll focus on getting the core server running and implementing basic features.

## Prerequisites

Before starting, ensure you have:
- Node.js (v14 or later) installed
- npm (Node Package Manager) installed
- A code editor (like VS Code)
- Basic familiarity with JavaScript/Node.js

## Phase 1: Initial Project Setup

### Step 1: Create Project Directory and Initialize

1. Open your terminal and create a new directory for your project:
```bash
mkdir beginner-mcp-server
cd beginner-mcp-server
```

2. Initialize a new Node.js project:
```bash
npm init -y
```

3. Install the required dependencies:
```bash
npm install @modelcontextprotocol/sdk node-fetch
```

### Step 2: Create Basic Server Structure

1. Create a new file called `server.js` in your project root:
```javascript
// server.js
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

async function main() {
    // Create server instance
    const server = new Server({
        name: "beginner-mcp-server",
        version: "0.1.0",
        description: "A beginner-friendly MCP server implementation"
    }, {
        capabilities: {
            resources: {},
            tools: {}
        }
    });

    // Create stdio transport
    const transport = new StdioServerTransport();

    // Connect server to transport
    console.log("Starting MCP server...");
    await server.connect(transport);
    console.log("MCP server is running!");
}

main().catch(error => {
    console.error("Server error:", error);
    process.exit(1);
});
```

2. Update `package.json` to enable ES modules:
```json
{
  "type": "module",
  // ... other existing fields ...
}
```

### Step 3: Test Basic Server

1. Run the server:
```bash
node server.js
```

You should see:
```
Starting MCP server...
MCP server is running!
```

## Phase 2: Implementing Basic Resources and Tools

### Step 1: Create Directory Structure

1. Create directories for capabilities:
```bash
mkdir -p capabilities/resources
mkdir -p capabilities/tools
```

### Step 2: Implement Greeting Resource

1. Create `capabilities/resources/greeting.js`:
```javascript
// capabilities/resources/greeting.js

export const greetingResource = {
    name: 'greeting',
    version: '0.1.0',
    description: 'A simple greeting resource',

    // List available greetings
    list: async () => {
        return {
            resources: [
                {
                    uri: "greeting://hello",
                    name: "Hello Greeting"
                },
                {
                    uri: "greeting://hi",
                    name: "Hi Greeting"
                }
            ]
        };
    },

    // Read a specific greeting
    read: async (request) => {
        const { uri } = request;
        
        let greeting;
        switch (uri) {
            case "greeting://hello":
                greeting = "Hello, World!";
                break;
            case "greeting://hi":
                greeting = "Hi there!";
                break;
            default:
                throw new Error(`Unknown greeting URI: ${uri}`);
        }

        return {
            resource: {
                uri,
                message: greeting
            }
        };
    },

    // Define schemas
    listResponseSchema: {
        type: 'object',
        properties: {
            resources: {
                type: 'array',
                items: {
                    type: 'object',
                    properties: {
                        uri: { type: 'string' },
                        name: { type: 'string' }
                    },
                    required: ['uri', 'name']
                }
            }
        },
        required: ['resources']
    },

    readRequestSchema: {
        type: 'object',
        properties: {
            uri: { type: 'string' }
        },
        required: ['uri']
    },

    readResponseSchema: {
        type: 'object',
        properties: {
            resource: {
                type: 'object',
                properties: {
                    uri: { type: 'string' },
                    message: { type: 'string' }
                },
                required: ['uri', 'message']
            }
        },
        required: ['resource']
    }
};
```

### Step 3: Implement Reverse String Tool

1. Create `capabilities/tools/reverse-string.js`:
```javascript
// capabilities/tools/reverse-string.js

export const reverseStringTool = {
    name: 'reverse-string',
    version: '0.1.0',
    description: 'A tool that reverses input strings',

    execute: async (request) => {
        const { text } = request;
        if (!text) {
            throw new Error("Text parameter is required");
        }

        return {
            reversed: text.split('').reverse().join('')
        };
    },

    requestSchema: {
        type: 'object',
        properties: {
            text: { type: 'string' }
        },
        required: ['text']
    },

    responseSchema: {
        type: 'object',
        properties: {
            reversed: { type: 'string' }
        },
        required: ['reversed']
    }
};
```

### Step 4: Update Server to Include New Capabilities

1. Update `server.js` to include the new resource and tool:
```javascript
// server.js
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { greetingResource } from './capabilities/resources/greeting.js';
import { reverseStringTool } from './capabilities/tools/reverse-string.js';

async function main() {
    const server = new Server({
        name: "beginner-mcp-server",
        version: "0.1.0",
        description: "A beginner-friendly MCP server implementation"
    }, {
        capabilities: {
            resources: {
                'greeting': greetingResource
            },
            tools: {
                'reverse-string': reverseStringTool
            }
        }
    });

    const transport = new StdioServerTransport();
    
    console.log("Starting MCP server...");
    await server.connect(transport);
    console.log("MCP server is running!");
}

main().catch(error => {
    console.error("Server error:", error);
    process.exit(1);
});
```

### Step 5: Create Test Client

1. Create `test-client.js` to test the server:
```javascript
// test-client.js
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";

async function main() {
    const transport = new StdioClientTransport();
    const client = new Client();
    
    try {
        await client.connect(transport);
        console.log("Connected to MCP server");

        // Test greeting resource - list
        console.log("\nTesting greeting resource (list):");
        const greetingList = await client.listResources({
            resourceName: 'greeting',
            version: '0.1.0'
        });
        console.log("Available greetings:", greetingList.resource_list.resources);

        // Test greeting resource - read
        console.log("\nTesting greeting resource (read):");
        const greeting = await client.readResource({
            resourceUri: "greeting://hello"
        });
        console.log("Greeting message:", greeting.resource_response.resource.message);

        // Test reverse-string tool
        console.log("\nTesting reverse-string tool:");
        const reversed = await client.executeTool({
            toolName: 'reverse-string',
            version: '0.1.0',
            arguments: {
                text: "Hello, World!"
            }
        });
        console.log("Reversed text:", reversed.tool_response.reversed);

    } catch (error) {
        console.error("Error:", error);
    } finally {
        client.close();
    }
}

main();
```

### Step 6: Test Everything

1. In one terminal, start the server:
```bash
node server.js
```

2. In another terminal, run the test client:
```bash
node test-client.js
```

You should see output like:
```
Connected to MCP server

Testing greeting resource (list):
Available greetings: [
  { uri: 'greeting://hello', name: 'Hello Greeting' },
  { uri: 'greeting://hi', name: 'Hi Greeting' }
]

Testing greeting resource (read):
Greeting message: Hello, World!

Testing reverse-string tool:
Reversed text: !dlroW ,olleH
```

## Next Steps

Now that you have a basic MCP server running with a resource and a tool, you can:

1. Add error handling and logging to make the server more robust
2. Implement more complex resources and tools
3. Add configuration options
4. Explore the other phases in the implementation plan

Remember to:
- Keep your code modular and well-documented
- Test thoroughly as you add new features
- Follow the MCP protocol specifications
- Consider security implications as you expand functionality
</file>

<file path="local-research/mcp-user-experience.md">
Querying Perplexity AI using sonar-pro for: What are the most important considerations for making an MCP server beginner-friendly while maintaining its power and flexibility? Include specific examples of user-friendly APIs and documentation approaches.
Key considerations for beginner-friendly MCP servers:

1. Simple setup and configuration:
- Provide clear step-by-step installation instructions
- Use sensible defaults
- Offer a quickstart guide with minimal configuration[3]

2. Intuitive API design:
- Use descriptive method names
- Implement consistent parameter naming
- Provide type hints and documentation[4]

Example:
```typescript
/**
 * Retrieves user information.
 * @param userId The unique identifier of the user
 * @returns User object containing name, email, and role
 */
async function getUser(userId: string): Promise<User> {
  // Implementation
}
```

3. Comprehensive documentation:
- Include usage examples for common scenarios
- Provide API reference with all available methods
- Explain key concepts and architecture[1]

4. Error handling and feedback:
- Return descriptive error messages
- Implement logging for debugging
- Provide suggestions for resolving common issues[3]

5. Modular design:
- Allow gradual feature adoption
- Implement plugin system for extensibility
- Use dependency injection for flexibility[6]

6. Interactive learning tools:
- Offer an interactive CLI for exploration
- Provide a playground environment
- Include tutorials with step-by-step walkthroughs[2]

7. Community support:
- Maintain active GitHub repository
- Offer discussion forums or chat channels
- Encourage contributions and feedback[5]
</file>

<file path="local-research/typescript-esm-config.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
To properly configure TypeScript for ES modules with Node.js, you need to adjust settings in both your `tsconfig.json` and `package.json` files. Here's a breakdown of the key configurations:

**1. `package.json` Configuration:**

   - **`"type": "module"`**:  This is crucial. Add `"type": "module"` to your `package.json` file. This tells Node.js to treat `.js` files in your project as ES modules.

   ```json
   {
     "name": "your-project",
     "version": "1.0.0",
     "type": "module", //  üëà  Important!
     "main": "dist/server.js",
     "scripts": {
       "build": "tsc",
       "start": "node dist/server.js",
       "dev": "ts-node --esm src/server.ts"
     },
     // ... other configurations
   }
   ```

**2. `tsconfig.json` Configuration:**

   Here's a recommended `tsconfig.json` configuration for ES modules in Node.js, based on best practices and the configuration present in the provided files:

   ```json
   {
     "compilerOptions": {
       "target": "ES2020",       // Or a later ECMAScript version that supports ES modules
       "module": "NodeNext",      //  ‚úÖ  Use "NodeNext" or "ESNext" for ES modules in Node.js
       "moduleResolution": "NodeNext", // ‚úÖ  Crucial for Node.js-style module resolution in ES modules
       "outDir": "./dist",        // Output directory for compiled JavaScript files
       "rootDir": "./src",        // Root directory of your TypeScript source files
       "strict": true,            // Enable strict type checking for better code quality
       "esModuleInterop": true,   //  ‚úÖ  Enable interoperability with CommonJS modules
       "skipLibCheck": true,      // Skip type checking of declaration files (improves build speed)
       "forceConsistentCasingInFileNames": true, // Enforce consistent casing in file names
       "resolveJsonModule": true,  // Allow importing JSON files as modules
       "allowJs": true,           // Allow importing and compiling JavaScript files (if needed)
       "declaration": true        // Generate declaration files (.d.ts) for your library (optional)
     },
     "ts-node": {
       "esm": true,             // ‚úÖ  Enable ES module support for ts-node
       "experimentalSpecifiers": true //  ‚úÖ  Required for some ES module features with ts-node
     },
     "include": ["src/**/*"],   //  Include all files in the 'src' directory
     "exclude": ["node_modules", "dist"] // Exclude 'node_modules' and 'dist' directories
   }
   ```

   **Explanation of Key `compilerOptions`:**

   - **`target`**:  `ES2020` or later is recommended to align with modern Node.js features and ES module support.
   - **`module`**:  **`NodeNext`** or **`ESNext`** are the correct choices for Node.js ES modules. These options ensure that TypeScript emits code that Node.js can directly understand as ES modules.
   - **`moduleResolution`**: **`NodeNext`** or **`Node16`** are crucial.  `NodeNext` is generally preferred for newer Node.js versions.  These settings tell TypeScript to use Node.js's specific module resolution algorithm for ES modules, which is different from CommonJS.
   - **`esModuleInterop`**:  This is important for allowing seamless import of CommonJS modules into your ES module code. It handles default exports and namespaces for compatibility.
   - **`ts-node` section**: The `ts-node` section is used to configure `ts-node` specifically for running TypeScript code directly in development with ES module support.  `"esm": true` and `"experimentalSpecifiers": true` are essential for this.

**3. File Extensions:**

   - **TypeScript Files**: Use `.ts` for your TypeScript files. You can also use `.mts` if you want to explicitly denote a file as a TypeScript ES module, though `.ts` generally works fine when `"type": "module"` is set in `package.json`.
   - **JavaScript Output**: TypeScript will emit `.js` files in your `outDir` (e.g., `dist`).  When Node.js loads these `.js` files, it will treat them as ES modules because of the `"type": "module"` setting in `package.json`.

**4. Building and Running:**

   - **Build**: Compile your TypeScript code using the TypeScript compiler:

     ```bash
     npm run build  #  (or yarn build, pnpm build, depending on your package manager)
     ```
     This will use the `tsc` command defined in your `scripts` in `package.json` (e.g., `"build": "tsc"`). It will generate JavaScript files in your `outDir` (e.g., `dist`).

   - **Run**:  Execute your compiled server (or main entry point) using Node.js:

     ```bash
     npm start       # (or yarn start, pnpm start) - for production (runs compiled code)
     npm run dev     # (or yarn dev, pnpm dev)   - for development (uses ts-node for direct execution)
     ```

     - **`npm start`**:  Runs the compiled JavaScript code in the `dist` folder using `node dist/server.js`. Node.js will treat `dist/server.js` as an ES module due to `"type": "module"` in `package.json`.
     - **`npm run dev`**: Uses `ts-node --esm src/server.ts`.  The `--esm` flag tells `ts-node` to run your TypeScript code as ES modules. The `ts-node` configuration in `tsconfig.json` further ensures ES module compatibility during development.

**Example Project Structure:**

```
mcp-server/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ server.ts
‚îÇ   ‚îú‚îÄ‚îÄ ... other TypeScript files ...
‚îú‚îÄ‚îÄ dist/             (Output directory after `npm run build`)
‚îÇ   ‚îî‚îÄ‚îÄ server.js      (Compiled JavaScript ES module)
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tsconfig.json
```

**Key Considerations:**

- **Node.js Version**: Ensure you are using a Node.js version that fully supports ES modules (Node.js 14.x or later is recommended).
- **`ts-node`**:  `ts-node` with the `--esm` flag is very helpful for development as it allows you to run your TypeScript ES modules directly without needing to compile first.
- **Module Resolution**: Understanding `moduleResolution: "NodeNext"` (or `"Node16"`) is critical for correctly resolving modules in a Node.js ES module environment. It closely mirrors how Node.js itself resolves ES modules.
- **Interoperability**: `esModuleInterop: true` is generally recommended for most projects as it simplifies working with both ES modules and CommonJS modules in the same project or when using dependencies that might be in CommonJS format.

By following these configurations, you will have a TypeScript project properly set up to use ES modules with Node.js, both for development and production builds.
</file>

<file path="mcp-server/.eslintrc.json">
{
  "env": {
    "es2022": true,
    "node": true,
    "jest": true
  },
  "extends": [
    "eslint:recommended",
    "plugin:@typescript-eslint/recommended",
    "plugin:prettier/recommended"
  ],
  "parser": "@typescript-eslint/parser",
  "parserOptions": {
    "ecmaVersion": "latest",
    "sourceType": "module"
  },
  "plugins": ["@typescript-eslint"],
  "rules": {
    "@typescript-eslint/explicit-function-return-type": "warn",
    "@typescript-eslint/no-unused-vars": "error",
    "@typescript-eslint/no-explicit-any": "warn",
    "prettier/prettier": "error"
  }
}
</file>

<file path="mcp-server/.prettierrc">
{
  "semi": true,
  "trailingComma": "es5",
  "singleQuote": true,
  "printWidth": 100,
  "tabWidth": 2,
  "useTabs": false
}
</file>

<file path="mcp-server/.repomix-output.txt">
This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-21T02:04:12.074Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
src/capabilities/resources/
src/config/
src/utils/
local-research/implementation-plan.md
local-research/mcp-implementation-research.md
package.json
src/capabilities/tools/web-search.js
src/capabilities/tools/web-search.ts
src/server.js
src/server.ts
src/test-client.js
src/test-client.ts
src/test-setup.js
src/test-setup.mjs
src/test-setup.ts
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="local-research/implementation-plan.md">
Packing repository using repomix...
</file>

<file path="local-research/mcp-implementation-research.md">
Querying Perplexity AI using sonar-pro for: 1. What are the best practices for implementing transport layers in MCP servers? 2. What are the recommended security measures for MCP server implementations? 3. What are the optimal caching and rate limiting strategies for external API calls in MCP servers? 4. What are the recommended testing approaches for MCP server capabilities? 5. What are the best practices for error handling and logging in MCP servers? 6. What are the recommended scalability patterns for MCP server implementations?
1. Best practices for implementing transport layers in MCP servers:
- Use layered architecture with clear separation between client/server, session, and transport layers[1].
- Implement different transports for various use cases: STDIO for in-process communication, SSE for HTTP-based communication[1].
- Handle JSON-RPC message serialization/deserialization in the transport layer[1].
- Ensure proper connection establishment, protocol compatibility checks, and capability negotiation[1].

2. Recommended security measures for MCP server implementations:
- Implement strict input validation and sanitization[4].
- Use command whitelisting and flag validation for CLI-based servers[2].
- Prevent path traversal and shell injection attacks[2].
- Implement execution timeouts and command length limits[2].
- Use TLS encryption for API endpoints, especially in management networks[7].
- Employ access controls and proper authentication mechanisms[7].
- Use IDS/IPS for admin networks to detect anomalies[7].

3. Optimal caching and rate limiting strategies for external API calls:
- Implement token bucket algorithm for rate limiting[3]:
```csharp
builder.Services.AddRateLimiter(rateLimiterOptions => {
  options.TokenLimit = 1000;
  options.ReplenishmentPeriod = TimeSpan.FromHours(1);
  options.TokensPerPeriod = 700;
  options.AutoReplenishment = true;
});
```
- Use sliding window rate limiting for more precise control[9].
- Implement IP-based rate limiting to prevent abuse[9].
- Use distributed caching for scalability.

4. Recommended testing approaches for MCP server capabilities:
- Use the MCP Inspector tool for systematic testing[4].
- Test core features first, then add edge cases[4].
- Verify error handling and check performance[4].
- Implement a systematic approach: test core features, add edge cases, verify error handling, check performance[4].
- Use the Inspector during development for quick iteration[5].

5. Best practices for error handling and logging in MCP servers:
- Implement structured logging with consistent formats, context, and timestamps[5].
- Log stack traces, error context, and track error patterns[5].
- Use server-side logging to stderr for local transports[5].
- Send log message notifications to clients:
```python
server.request_context.session.send_log_message(
  level="info",
  data="Server started successfully"
)
```
- Log important events: initialization, resource access, tool execution, errors, performance metrics[5].

6. Recommended scalability patterns for MCP server implementations:
- Use asynchronous operations for improved concurrency[1].
- Implement proper connection management and cleanup[4].
- Use load balancing for distributing requests[7].
- Employ horizontal scaling by adding more server instances.
- Implement efficient resource management and monitoring[4].
</file>

<file path="package.json">
{
  "name": "mcp-server",
  "version": "1.0.0",
  "description": "A beginner-friendly MCP server implementation",
  "type": "module",
  "main": "dist/server.js",
  "scripts": {
    "build": "tsc",
    "start": "node dist/server.js",
    "dev": "ts-node --esm src/server.ts",
    "test": "node src/test-setup.mjs"
  },
  "keywords": [
    "mcp",
    "server",
    "model-context-protocol"
  ],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "@modelcontextprotocol/sdk": "1.2.0",
    "@octokit/rest": "19.0.13",
    "axios": "1.6.5",
    "dotenv": "16.3.1",
    "playwright": "1.41.2",
    "zod": "^3.24.2"
  },
  "devDependencies": {
    "@types/node": "20.11.5",
    "ts-node": "10.9.2",
    "typescript": "5.3.3"
  }
}
</file>

<file path="src/capabilities/tools/web-search.js">
"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.webSearchTool = void 0;
const axios_1 = __importDefault(require("axios"));
const dotenv_1 = __importDefault(require("dotenv"));
// Load environment variables
dotenv_1.default.config();
const PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions";
const PERPLEXITY_API_KEY = process.env.PERPLEXITY_API_KEY;
exports.webSearchTool = {
    name: 'web-search',
    version: '0.1.0',
    description: 'Performs a web search using Perplexity AI.',
    execute: (request) => __awaiter(void 0, void 0, void 0, function* () {
        var _a, _b, _c, _d;
        if (!PERPLEXITY_API_KEY) {
            throw new Error("Perplexity API key is not set in environment variables (PERPLEXITY_API_KEY)");
        }
        const { query, saveTo } = request;
        if (!query) {
            throw new Error("Search query is required.");
        }
        try {
            console.log(`üîç Performing web search: "${query}"`);
            const response = yield axios_1.default.post(PERPLEXITY_API_URL, {
                model: "pplx-7b-online",
                messages: [{ role: "user", content: query }]
            }, {
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${PERPLEXITY_API_KEY}`
                }
            });
            const searchResults = ((_b = (_a = response.data.choices[0]) === null || _a === void 0 ? void 0 : _a.message) === null || _b === void 0 ? void 0 : _b.content) || "No results found.";
            // If saveTo is specified, save results to file
            if (saveTo) {
                const fs = yield Promise.resolve().then(() => __importStar(require('fs/promises')));
                yield fs.writeFile(saveTo, searchResults, 'utf-8');
                console.log(`‚úÖ Results saved to: ${saveTo}`);
                return { searchResults, savedToFile: saveTo };
            }
            return { searchResults };
        }
        catch (error) {
            console.error("‚ùå Error during web search:", error);
            if (axios_1.default.isAxiosError(error)) {
                throw new Error(`Web search failed: ${((_d = (_c = error.response) === null || _c === void 0 ? void 0 : _c.data) === null || _d === void 0 ? void 0 : _d.error) || error.message}`);
            }
            throw new Error(`Web search failed: ${error}`);
        }
    }),
    requestSchema: {
        type: 'object',
        properties: {
            query: {
                type: 'string',
                description: 'The search query.'
            },
            saveTo: {
                type: 'string',
                description: 'Optional file path to save the search results.'
            }
        },
        required: ['query']
    },
    responseSchema: {
        type: 'object',
        properties: {
            searchResults: {
                type: 'string',
                description: 'Web search results.'
            },
            savedToFile: {
                type: 'string',
                description: 'Path to the file where results were saved, if applicable.'
            }
        },
        required: ['searchResults']
    }
};
</file>

<file path="src/capabilities/tools/web-search.ts">
import axios from 'axios';
import dotenv from 'dotenv';
// Load environment variables
dotenv.config();
const PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions";
const PERPLEXITY_API_KEY = process.env.PERPLEXITY_API_KEY;
interface WebSearchRequest {
    query: string;
    saveTo?: string;
}
interface WebSearchResponse {
    searchResults: string;
    savedToFile?: string;
}
export const webSearchTool = {
    name: 'web-search',
    version: '0.1.0',
    description: 'Performs a web search using Perplexity AI.',
    execute: async (request: WebSearchRequest): Promise<WebSearchResponse> => {
        if (!PERPLEXITY_API_KEY) {
            throw new Error("Perplexity API key is not set in environment variables (PERPLEXITY_API_KEY)");
        }
        const { query, saveTo } = request;
        if (!query) {
            throw new Error("Search query is required.");
        }
        try {
            console.log(`üîç Performing web search: "${query}"`);
            const response = await axios.post(PERPLEXITY_API_URL, {
                model: "pplx-7b-online",
                messages: [{ role: "user", content: query }]
            }, {
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${PERPLEXITY_API_KEY}`
                }
            });
            const searchResults = response.data.choices[0]?.message?.content || "No results found.";
            // If saveTo is specified, save results to file
            if (saveTo) {
                const fs = await import('fs/promises');
                await fs.writeFile(saveTo, searchResults, 'utf-8');
                console.log(`‚úÖ Results saved to: ${saveTo}`);
                return { searchResults, savedToFile: saveTo };
            }
            return { searchResults };
        } catch (error) {
            console.error("‚ùå Error during web search:", error);
            if (axios.isAxiosError(error)) {
                throw new Error(`Web search failed: ${error.response?.data?.error || error.message}`);
            }
            throw new Error(`Web search failed: ${error}`);
        }
    },
    requestSchema: {
        type: 'object',
        properties: {
            query: { 
                type: 'string', 
                description: 'The search query.' 
            },
            saveTo: { 
                type: 'string', 
                description: 'Optional file path to save the search results.' 
            }
        },
        required: ['query']
    },
    responseSchema: {
        type: 'object',
        properties: {
            searchResults: { 
                type: 'string', 
                description: 'Web search results.' 
            },
            savedToFile: { 
                type: 'string', 
                description: 'Path to the file where results were saved, if applicable.' 
            }
        },
        required: ['searchResults']
    }
};
</file>

<file path="src/server.js">
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("@modelcontextprotocol/sdk/server/index.js");
const stdio_js_1 = require("@modelcontextprotocol/sdk/server/stdio.js");
const web_search_js_1 = require("./capabilities/tools/web-search.js");
function main() {
    return __awaiter(this, void 0, void 0, function* () {
        try {
            console.log("Starting MCP server...");
            const server = new index_js_1.Server({
                name: "cursor-tools-mcp-server",
                version: "0.1.0",
                description: "MCP server mimicking cursor-tools functionalities."
            }, {
                capabilities: {
                    resources: {}, // Resources will be defined here
                    tools: {
                        'web-search': web_search_js_1.webSearchTool
                    }
                }
            });
            const transport = new stdio_js_1.StdioServerTransport();
            console.log("Connecting to transport...");
            yield server.connect(transport);
            console.log("‚úÖ MCP Server started using stdio transport.");
            console.log("Available tools:");
            console.log("  - web-search: Perform web searches using Perplexity AI");
        }
        catch (error) {
            console.error("‚ùå Server failed to start:", error);
            process.exit(1);
        }
    });
}
// Handle process termination
process.on('SIGINT', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
process.on('SIGTERM', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
// Start the server
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="src/server.ts">
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { webSearchTool } from './capabilities/tools/web-search.js';
async function main() {
    try {
        console.log("Starting MCP server...");
        const server = new Server({
            name: "cursor-tools-mcp-server",
            version: "0.1.0",
            description: "MCP server mimicking cursor-tools functionalities."
        }, {
            capabilities: {
                resources: {}, // Resources will be defined here
                tools: {
                    'web-search': webSearchTool
                }
            }
        });
        const transport = new StdioServerTransport();
        console.log("Connecting to transport...");
        await server.connect(transport);
        console.log("‚úÖ MCP Server started using stdio transport.");
        console.log("Available tools:");
        console.log("  - web-search: Perform web searches using Perplexity AI");
    } catch (error) {
        console.error("‚ùå Server failed to start:", error);
        process.exit(1);
    }
}
// Handle process termination
process.on('SIGINT', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
process.on('SIGTERM', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
// Start the server
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="src/test-client.js">
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("@modelcontextprotocol/sdk/client/index.js");
const stdio_js_1 = require("@modelcontextprotocol/sdk/client/stdio.js");
const zod_1 = require("zod");
// Define response schema
const WebSearchResponseSchema = zod_1.z.object({
    result: zod_1.z.object({
        searchResults: zod_1.z.string(),
        savedToFile: zod_1.z.string().optional()
    })
});
function main() {
    return __awaiter(this, void 0, void 0, function* () {
        // Initialize transport with required parameters
        const transport = new stdio_js_1.StdioClientTransport({
            command: 'node',
            args: ['dist/server.js']
        });
        const client = new index_js_1.Client({
            name: "test-client",
            version: "0.1.0"
        }, {
            capabilities: {}
        });
        try {
            console.log("Connecting to MCP server...");
            yield client.connect(transport);
            console.log("‚úÖ Connected to MCP server\n");
            // Test web search
            console.log("Testing web search tool...");
            const response = yield client.request({
                method: "tool/execute",
                params: {
                    toolName: 'web-search',
                    version: '0.1.0',
                    arguments: {
                        query: "What are the latest developments in AI?",
                        saveTo: "local-research/ai-developments.md"
                    }
                }
            }, WebSearchResponseSchema);
            console.log("\nWeb Search Results:");
            console.log("------------------");
            console.log(response.result.searchResults);
            if (response.result.savedToFile) {
                console.log(`\nResults saved to: ${response.result.savedToFile}`);
            }
        }
        catch (error) {
            console.error("‚ùå Error:", error);
        }
        finally {
            console.log("\nClosing client connection...");
            client.close();
        }
    });
}
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="src/test-client.ts">
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import { z } from 'zod';
// Define response schema
const WebSearchResponseSchema = z.object({
    result: z.object({
        searchResults: z.string(),
        savedToFile: z.string().optional()
    })
});
async function main() {
    // Initialize transport with required parameters
    const transport = new StdioClientTransport({
        command: 'node',
        args: ['dist/server.js']
    });
    const client = new Client({
        name: "test-client",
        version: "0.1.0"
    }, {
        capabilities: {}
    });
    try {
        console.log("Connecting to MCP server...");
        await client.connect(transport);
        console.log("‚úÖ Connected to MCP server\n");
        // Test web search
        console.log("Testing web search tool...");
        const response = await client.request({
            method: "tool/execute",
            params: {
                toolName: 'web-search',
                version: '0.1.0',
                arguments: {
                    query: "What are the latest developments in AI?",
                    saveTo: "local-research/ai-developments.md"
                }
            }
        }, WebSearchResponseSchema);
        console.log("\nWeb Search Results:");
        console.log("------------------");
        console.log(response.result.searchResults);
        if (response.result.savedToFile) {
            console.log(`\nResults saved to: ${response.result.savedToFile}`);
        }
    } catch (error) {
        console.error("‚ùå Error:", error);
    } finally {
        console.log("\nClosing client connection...");
        client.close();
    }
}
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="src/test-setup.js">
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("@modelcontextprotocol/sdk/server/index.js");
const playwright_1 = require("playwright");
const rest_1 = require("@octokit/rest");
const axios_1 = __importDefault(require("axios"));
const dotenv_1 = __importDefault(require("dotenv"));
function testSetup() {
    return __awaiter(this, void 0, void 0, function* () {
        try {
            console.log('üîç Starting dependency verification...\n');
            // Test dotenv first to load environment variables
            dotenv_1.default.config();
            console.log('‚úÖ dotenv loaded successfully');
            // Test MCP SDK
            const server = new index_js_1.Server({
                name: "test-server",
                version: "1.0.0"
            }, {
                capabilities: {
                    resources: {},
                    tools: {}
                }
            });
            console.log('‚úÖ MCP SDK initialized successfully');
            // Test Playwright
            console.log('\nüåê Testing browser automation...');
            const browser = yield playwright_1.chromium.launch();
            yield browser.close();
            console.log('‚úÖ Playwright working correctly');
            // Test Octokit
            console.log('\nüì¶ Testing GitHub integration...');
            const octokit = new rest_1.Octokit();
            const { status } = yield octokit.rest.meta.root();
            console.log(`‚úÖ Octokit connected successfully (status: ${status})`);
            // Test Axios
            console.log('\nüîå Testing HTTP client...');
            const response = yield axios_1.default.get('https://api.github.com');
            console.log(`‚úÖ Axios working correctly (status: ${response.status})`);
            console.log('\n‚ú® All dependencies verified successfully!');
        }
        catch (error) {
            console.error('\n‚ùå Setup test failed:', error);
            process.exit(1);
        }
    });
}
testSetup();
</file>

<file path="src/test-setup.mjs">
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { chromium } from 'playwright';
import { Octokit } from '@octokit/rest';
import axios from 'axios';
import dotenv from 'dotenv';

async function testSetup() {
  try {
    console.log('üîç Starting dependency verification...\n');

    // Test dotenv first to load environment variables
    dotenv.config();
    console.log('‚úÖ dotenv loaded successfully');

    // Test MCP SDK
    const server = new Server({
      name: "test-server",
      version: "1.0.0"
    }, {
      capabilities: {
        resources: {},
        tools: {}
      }
    });
    console.log('‚úÖ MCP SDK initialized successfully');

    // Test Playwright
    console.log('\nüåê Testing browser automation...');
    const browser = await chromium.launch();
    await browser.close();
    console.log('‚úÖ Playwright working correctly');

    // Test Octokit
    console.log('\nüì¶ Testing GitHub integration...');
    const octokit = new Octokit();
    const { status } = await octokit.rest.meta.root();
    console.log(`‚úÖ Octokit connected successfully (status: ${status})`);

    // Test Axios
    console.log('\nüîå Testing HTTP client...');
    const response = await axios.get('https://api.github.com');
    console.log(`‚úÖ Axios working correctly (status: ${response.status})`);

    console.log('\n‚ú® All dependencies verified successfully!');

  } catch (error) {
    console.error('\n‚ùå Setup test failed:', error);
    process.exit(1);
  }
}

testSetup();
</file>

<file path="src/test-setup.ts">
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { chromium } from 'playwright';
import { Octokit } from '@octokit/rest';
import axios from 'axios';
import dotenv from 'dotenv';
async function testSetup() {
  try {
    console.log('üîç Starting dependency verification...\n');
    // Test dotenv first to load environment variables
    dotenv.config();
    console.log('‚úÖ dotenv loaded successfully');
    // Test MCP SDK
    const server = new Server({
      name: "test-server",
      version: "1.0.0"
    }, {
      capabilities: {
        resources: {},
        tools: {}
      }
    });
    console.log('‚úÖ MCP SDK initialized successfully');
    // Test Playwright
    console.log('\nüåê Testing browser automation...');
    const browser = await chromium.launch();
    await browser.close();
    console.log('‚úÖ Playwright working correctly');
    // Test Octokit
    console.log('\nüì¶ Testing GitHub integration...');
    const octokit = new Octokit();
    const { status } = await octokit.rest.meta.root();
    console.log(`‚úÖ Octokit connected successfully (status: ${status})`);
    // Test Axios
    console.log('\nüîå Testing HTTP client...');
    const response = await axios.get('https://api.github.com');
    console.log(`‚úÖ Axios working correctly (status: ${response.status})`);
    console.log('\n‚ú® All dependencies verified successfully!');
  } catch (error) {
    console.error('\n‚ùå Setup test failed:', error);
    process.exit(1);
  }
}
testSetup();
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    /* Visit https://aka.ms/tsconfig to read more about this file */

    /* Projects */
    // "incremental": true,                              /* Save .tsbuildinfo files to allow for incremental compilation of projects. */
    // "composite": true,                                /* Enable constraints that allow a TypeScript project to be used with project references. */
    // "tsBuildInfoFile": "./.tsbuildinfo",              /* Specify the path to .tsbuildinfo incremental compilation file. */
    // "disableSourceOfProjectReferenceRedirect": true,  /* Disable preferring source files instead of declaration files when referencing composite projects. */
    // "disableSolutionSearching": true,                 /* Opt a project out of multi-project reference checking when editing. */
    // "disableReferencedProjectLoad": true,             /* Reduce the number of projects loaded automatically by TypeScript. */

    /* Language and Environment */
    "target": "es2016",                                  /* Set the JavaScript language version for emitted JavaScript and include compatible library declarations. */
    // "lib": [],                                        /* Specify a set of bundled library declaration files that describe the target runtime environment. */
    // "jsx": "preserve",                                /* Specify what JSX code is generated. */
    // "experimentalDecorators": true,                   /* Enable experimental support for legacy experimental decorators. */
    // "emitDecoratorMetadata": true,                    /* Emit design-type metadata for decorated declarations in source files. */
    // "jsxFactory": "",                                 /* Specify the JSX factory function used when targeting React JSX emit, e.g. 'React.createElement' or 'h'. */
    // "jsxFragmentFactory": "",                         /* Specify the JSX Fragment reference used for fragments when targeting React JSX emit e.g. 'React.Fragment' or 'Fragment'. */
    // "jsxImportSource": "",                            /* Specify module specifier used to import the JSX factory functions when using 'jsx: react-jsx*'. */
    // "reactNamespace": "",                             /* Specify the object invoked for 'createElement'. This only applies when targeting 'react' JSX emit. */
    // "noLib": true,                                    /* Disable including any library files, including the default lib.d.ts. */
    // "useDefineForClassFields": true,                  /* Emit ECMAScript-standard-compliant class fields. */
    // "moduleDetection": "auto",                        /* Control what method is used to detect module-format JS files. */

    /* Modules */
    "module": "commonjs",                                /* Specify what module code is generated. */
    // "rootDir": "./",                                  /* Specify the root folder within your source files. */
    // "moduleResolution": "node10",                     /* Specify how TypeScript looks up a file from a given module specifier. */
    // "baseUrl": "./",                                  /* Specify the base directory to resolve non-relative module names. */
    // "paths": {},                                      /* Specify a set of entries that re-map imports to additional lookup locations. */
    // "rootDirs": [],                                   /* Allow multiple folders to be treated as one when resolving modules. */
    // "typeRoots": [],                                  /* Specify multiple folders that act like './node_modules/@types'. */
    // "types": [],                                      /* Specify type package names to be included without being referenced in a source file. */
    // "allowUmdGlobalAccess": true,                     /* Allow accessing UMD globals from modules. */
    // "moduleSuffixes": [],                             /* List of file name suffixes to search when resolving a module. */
    // "allowImportingTsExtensions": true,               /* Allow imports to include TypeScript file extensions. Requires '--moduleResolution bundler' and either '--noEmit' or '--emitDeclarationOnly' to be set. */
    // "resolvePackageJsonExports": true,                /* Use the package.json 'exports' field when resolving package imports. */
    // "resolvePackageJsonImports": true,                /* Use the package.json 'imports' field when resolving imports. */
    // "customConditions": [],                           /* Conditions to set in addition to the resolver-specific defaults when resolving imports. */
    // "resolveJsonModule": true,                        /* Enable importing .json files. */
    // "allowArbitraryExtensions": true,                 /* Enable importing files with any extension, provided a declaration file is present. */
    // "noResolve": true,                                /* Disallow 'import's, 'require's or '<reference>'s from expanding the number of files TypeScript should add to a project. */

    /* JavaScript Support */
    // "allowJs": true,                                  /* Allow JavaScript files to be a part of your program. Use the 'checkJS' option to get errors from these files. */
    // "checkJs": true,                                  /* Enable error reporting in type-checked JavaScript files. */
    // "maxNodeModuleJsDepth": 1,                        /* Specify the maximum folder depth used for checking JavaScript files from 'node_modules'. Only applicable with 'allowJs'. */

    /* Emit */
    // "declaration": true,                              /* Generate .d.ts files from TypeScript and JavaScript files in your project. */
    // "declarationMap": true,                           /* Create sourcemaps for d.ts files. */
    // "emitDeclarationOnly": true,                      /* Only output d.ts files and not JavaScript files. */
    // "sourceMap": true,                                /* Create source map files for emitted JavaScript files. */
    // "inlineSourceMap": true,                          /* Include sourcemap files inside the emitted JavaScript. */
    // "outFile": "./",                                  /* Specify a file that bundles all outputs into one JavaScript file. If 'declaration' is true, also designates a file that bundles all .d.ts output. */
    // "outDir": "./",                                   /* Specify an output folder for all emitted files. */
    // "removeComments": true,                           /* Disable emitting comments. */
    // "noEmit": true,                                   /* Disable emitting files from a compilation. */
    // "importHelpers": true,                            /* Allow importing helper functions from tslib once per project, instead of including them per-file. */
    // "importsNotUsedAsValues": "remove",               /* Specify emit/checking behavior for imports that are only used for types. */
    // "downlevelIteration": true,                       /* Emit more compliant, but verbose and less performant JavaScript for iteration. */
    // "sourceRoot": "",                                 /* Specify the root path for debuggers to find the reference source code. */
    // "mapRoot": "",                                    /* Specify the location where debugger should locate map files instead of generated locations. */
    // "inlineSources": true,                            /* Include source code in the sourcemaps inside the emitted JavaScript. */
    // "emitBOM": true,                                  /* Emit a UTF-8 Byte Order Mark (BOM) in the beginning of output files. */
    // "newLine": "crlf",                                /* Set the newline character for emitting files. */
    // "stripInternal": true,                            /* Disable emitting declarations that have '@internal' in their JSDoc comments. */
    // "noEmitHelpers": true,                            /* Disable generating custom helper functions like '__extends' in compiled output. */
    // "noEmitOnError": true,                            /* Disable emitting files if any type checking errors are reported. */
    // "preserveConstEnums": true,                       /* Disable erasing 'const enum' declarations in generated code. */
    // "declarationDir": "./",                           /* Specify the output directory for generated declaration files. */
    // "preserveValueImports": true,                     /* Preserve unused imported values in the JavaScript output that would otherwise be removed. */

    /* Interop Constraints */
    // "isolatedModules": true,                          /* Ensure that each file can be safely transpiled without relying on other imports. */
    // "verbatimModuleSyntax": true,                     /* Do not transform or elide any imports or exports not marked as type-only, ensuring they are written in the output file's format based on the 'module' setting. */
    // "allowSyntheticDefaultImports": true,             /* Allow 'import x from y' when a module doesn't have a default export. */
    "esModuleInterop": true,                             /* Emit additional JavaScript to ease support for importing CommonJS modules. This enables 'allowSyntheticDefaultImports' for type compatibility. */
    // "preserveSymlinks": true,                         /* Disable resolving symlinks to their realpath. This correlates to the same flag in node. */
    "forceConsistentCasingInFileNames": true,            /* Ensure that casing is correct in imports. */

    /* Type Checking */
    "strict": true,                                      /* Enable all strict type-checking options. */
    // "noImplicitAny": true,                            /* Enable error reporting for expressions and declarations with an implied 'any' type. */
    // "strictNullChecks": true,                         /* When type checking, take into account 'null' and 'undefined'. */
    // "strictFunctionTypes": true,                      /* When assigning functions, check to ensure parameters and the return values are subtype-compatible. */
    // "strictBindCallApply": true,                      /* Check that the arguments for 'bind', 'call', and 'apply' methods match the original function. */
    // "strictPropertyInitialization": true,             /* Check for class properties that are declared but not set in the constructor. */
    // "noImplicitThis": true,                           /* Enable error reporting when 'this' is given the type 'any'. */
    // "useUnknownInCatchVariables": true,               /* Default catch clause variables as 'unknown' instead of 'any'. */
    // "alwaysStrict": true,                             /* Ensure 'use strict' is always emitted. */
    // "noUnusedLocals": true,                           /* Enable error reporting when local variables aren't read. */
    // "noUnusedParameters": true,                       /* Raise an error when a function parameter isn't read. */
    // "exactOptionalPropertyTypes": true,               /* Interpret optional property types as written, rather than adding 'undefined'. */
    // "noImplicitReturns": true,                        /* Enable error reporting for codepaths that do not explicitly return in a function. */
    // "noFallthroughCasesInSwitch": true,               /* Enable error reporting for fallthrough cases in switch statements. */
    // "noUncheckedIndexedAccess": true,                 /* Add 'undefined' to a type when accessed using an index. */
    // "noImplicitOverride": true,                       /* Ensure overriding members in derived classes are marked with an override modifier. */
    // "noPropertyAccessFromIndexSignature": true,       /* Enforces using indexed accessors for keys declared using an indexed type. */
    // "allowUnusedLabels": true,                        /* Disable error reporting for unused labels. */
    // "allowUnreachableCode": true,                     /* Disable error reporting for unreachable code. */

    /* Completeness */
    // "skipDefaultLibCheck": true,                      /* Skip type checking .d.ts files that are included with TypeScript. */
    "skipLibCheck": true                                 /* Skip type checking all .d.ts files. */
  }
}
</file>

</files>
</file>

<file path="mcp-server/jest.config.js">
/** @type {import('jest').Config} */
export default {
  preset: 'ts-jest/presets/default-esm',
  testEnvironment: 'node',
  extensionsToTreatAsEsm: ['.ts'],
  moduleNameMapper: {
    '^@/(.*)$': '<rootDir>/src/$1',
    '^(\\.{1,2}/.*)\\.js$': '$1',
  },
  transform: {
    '^.+\\.tsx?$': [
      'ts-jest',
      {
        useESM: true,
        tsconfig: 'tsconfig.json',
      },
    ],
  },
  setupFiles: ['dotenv/config'],
  testMatch: ['**/__tests__/**/*.test.ts'],
  coverageDirectory: 'coverage',
  collectCoverageFrom: ['src/**/*.{ts,tsx}', '!src/**/*.d.ts'],
  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json', 'node'],
};
</file>

<file path="mcp-server/local-research/implementation-plan.md">
Packing repository using repomix...
Querying Gemini AI using gemini-2.0-flash-thinking-exp-01-21...
Based on the research document and best practices, here's a detailed step-by-step implementation plan for the MCP server:

## MCP Server Implementation Plan

This plan outlines the steps to implement an MCP server, focusing on best practices for transport layers, security measures, caching, rate limiting, testing, error handling, logging, and scalability, as researched in `local-research/mcp-implementation-research.md`.

**Phase 1: Project Setup and Core Structure**

1.  **Initialize Project**:
    *   Ensure Node.js and npm (or yarn/pnpm) are installed.
    *   Initialize a new npm project: `npm init -y`
    *   Initialize a TypeScript project: `tsc --init --rootDir src --outDir dist --module commonjs --esModuleInterop --strict --skipLibCheck` (Adjust `module` if ESM is preferred, and update `package.json` accordingly, as currently configured).
    *   Install core dependencies: `@modelcontextprotocol/sdk`, `dotenv`, `axios`, `zod`, `ts-node`, `typescript`.
        ```bash
        npm install @modelcontextprotocol/sdk dotenv axios zod ts-node typescript
        ```

2.  **Directory Structure Setup**:
    *   Create the following directory structure (as already present in the provided files, reinforcing good organization):
        ```
        mcp-server/
        ‚îú‚îÄ‚îÄ src/
        ‚îÇ   ‚îú‚îÄ‚îÄ capabilities/
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ resources/
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tools/
        ‚îÇ   ‚îú‚îÄ‚îÄ config/
        ‚îÇ   ‚îî‚îÄ‚îÄ utils/
        ‚îú‚îÄ‚îÄ local-research/
        ‚îú‚îÄ‚îÄ dist/         (Output directory for compiled JavaScript)
        ‚îú‚îÄ‚îÄ package.json
        ‚îú‚îÄ‚îÄ tsconfig.json
        ```

3.  **Configuration Management**:
    *   Install `dotenv`: `npm install dotenv`
    *   Create a `.env` file in the root directory to store environment variables (e.g., `PERPLEXITY_API_KEY`).
    *   Configure `dotenv` to load environment variables in server and tool files (already implemented in `web-search.ts`).

4.  **Basic Server Structure**:
    *   Create `src/server.ts` (or `src/server.js` for JavaScript) as the main server entry point.
    *   Implement the basic server setup using `@modelcontextprotocol/sdk/server` (as in `src/server.ts`):
        ```typescript
        import { Server } from "@modelcontextprotocol/sdk/server/index.js";
        import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

        async function main() {
            try {
                console.log("Starting MCP server...");
                const server = new Server({
                    name: "your-mcp-server-name",
                    version: "0.1.0",
                    description: "Description of your MCP server."
                }, {
                    capabilities: {
                        resources: {},
                        tools: {}
                    }
                });
                const transport = new StdioServerTransport();
                await server.connect(transport);
                console.log("‚úÖ MCP Server started using stdio transport.");
            } catch (error) {
                console.error("‚ùå Server failed to start:", error);
                process.exit(1);
            }
        }

        main().catch(console.error);
        ```

**Phase 2: Transport Layer Implementation (STDIO)**

1.  **STDIO Transport**:
    *   Utilize `StdioServerTransport` from `@modelcontextprotocol/sdk/server/stdio.js` for initial transport layer implementation. This is suitable for local development and simplifies initial setup as it uses standard input/output streams (as already implemented in `src/server.ts`).
    *   Ensure the server connects to the transport using `server.connect(transport)`.
    *   Verify basic communication by sending a simple request from a client (see Phase 5 for testing).

2.  **Future Transport Considerations (Research Point 1)**:
    *   **Layered Architecture**: Keep in mind the layered architecture principle for future transport implementations (client/server, session, transport layers).  The MCP SDK inherently supports this separation.
    *   **Alternative Transports**: For future enhancements, consider:
        *   **SSE (Server-Sent Events)** for HTTP-based communication if web-based clients are needed.
        *   **WebSockets** for persistent bidirectional communication if more interactive features are required.
        *   **TCP Sockets** for potentially higher performance in specific network environments if needed later.

**Phase 3: Capability Implementation - `web-search` Tool**

1.  **Implement `web-search` Tool (Research Point 4)**:
    *   Create `src/capabilities/tools/web-search.ts` (or `.js`).
    *   Implement the `webSearchTool` as defined in `src/capabilities/tools/web-search.ts`, leveraging the Perplexity AI API.
    *   **API Key Handling**: Ensure secure handling of `PERPLEXITY_API_KEY` using environment variables (as implemented).
    *   **Request and Response Schemas**: Utilize `requestSchema` and `responseSchema` to define and validate inputs and outputs using Zod (as implemented). This is crucial for input validation (Security Point 2.1).

2.  **Integrate Tool with Server**:
    *   Register the `webSearchTool` in the `tools` capability section of the `Server` constructor in `src/server.ts` (as implemented):
        ```typescript
        tools: {
            'web-search': webSearchTool
        }
        ```

**Phase 4: Security Measures Implementation (Research Point 2)**

1.  **Input Validation and Sanitization (Research Point 2.1)**:
    *   **Schema Validation**: Enforce input validation using the `requestSchema` defined for each tool. The MCP SDK handles schema validation automatically.
    *   **Data Sanitization**: If necessary for specific tool logic (though less critical for web search output), sanitize inputs to prevent injection attacks. For now, focus on robust schema validation.

2.  **API Key Security (Research Point 2.6)**:
    *   **Environment Variables**: Store `PERPLEXITY_API_KEY` and other sensitive credentials in environment variables, not directly in the code (as implemented).
    *   **`.gitignore`**: Ensure `.env` is added to `.gitignore` to prevent accidental commits of API keys to version control.

3.  **Rate Limiting (Research Point 3)**:
    *   **Basic Rate Limiting for Perplexity API**: Implement a basic rate limiting mechanism to avoid exceeding Perplexity AI API limits. A simple token bucket approach can be initially used within the `web-search` tool execution:
        ```typescript
        // Example (simplified token bucket - needs proper state management in a real scenario)
        let tokens = 100; // Initial tokens
        const replenishRate = 700/3600; // Tokens per second (700 per hour)

        async execute: async (request: WebSearchRequest): Promise<WebSearchResponse> => {
            // ... API key check ...
            if (tokens < 1) {
                throw new Error("Rate limit exceeded. Please try again later."); // Or implement queuing/delay
            }
            tokens -= 1;
            setTimeout(() => { tokens = Math.min(100, tokens + replenishRate * 1); }, 1000); // Replenish tokens
            // ... Perplexity API call ...
        }
        ```
        *   **More Advanced Rate Limiting**: For production, consider using a more robust rate limiting library or middleware, especially if you expose APIs to multiple users or services. Explore options like token bucket or sliding window algorithms with libraries that handle concurrency and storage.

4.  **Command Whitelisting and Flag Validation (Research Point 2.2) (Less relevant for this server but good to note for future CLI tools)**:
    *   If implementing tools that execute system commands in the future, use command whitelisting and flag validation to prevent command injection vulnerabilities. This is less applicable for the `web-search` tool but important for general security.

5.  **TLS Encryption and Access Controls (Research Point 2.5 & 2.7)**:
    *   **TLS**: If exposing the MCP server over a network (e.g., using HTTP transport), enforce TLS (HTTPS) for all API endpoints, especially for management interfaces. This is less relevant for stdio but critical for network deployments.
    *   **Access Controls**: Implement proper authentication and authorization mechanisms if the server needs to be accessed by authenticated users or services in the future.

**Phase 5: Testing (Research Point 4)**

1.  **Unit Tests**:
    *   Write unit tests for individual tools and utility functions to ensure they function correctly in isolation. Use a testing framework like Jest or Mocha if needed for more complex testing scenarios later. For now, basic testing through `test-client` is sufficient to start.

2.  **Integration Tests**:
    *   Create integration tests to verify the interaction between the MCP server and client. `src/test-client.ts` (and `.js`) serves as a basic integration test client.
    *   **Test `web-search` Tool**: The existing `src/test-client.ts` effectively tests the `web-search` tool by sending a request and validating the response against `WebSearchResponseSchema`. Expand this test client to cover more scenarios (e.g., error cases, different queries).
    *   **MCP Inspector (Research Point 4.1 & 4.4)**: Explore the MCP Inspector tool (if available and applicable to your SDK version) for more systematic testing of MCP capabilities and protocol compliance.

3.  **Testing Approaches (Research Point 4.3 & 4.4)**:
    *   **Core Features First**: Focus testing on core functionalities like tool execution and basic communication.
    *   **Edge Cases**: Gradually add tests for edge cases, error conditions, and boundary values for tool parameters.
    *   **Error Handling**: Specifically test error handling paths to ensure the server and tools gracefully handle errors and provide informative messages.
    *   **Performance Testing (Future)**: Consider basic performance testing later if performance becomes a concern, especially for API-intensive tools.

**Phase 6: Error Handling and Logging (Research Point 5)**

1.  **Structured Logging (Research Point 5.1)**:
    *   Implement structured logging using `console.log` for now, but plan to transition to a more robust logging library (like `winston` or `pino`) for production.
    *   Log in a consistent JSON format for easier parsing and analysis in the future if needed. Include context, timestamps, and log levels (info, warning, error).

2.  **Log Relevant Events (Research Point 5.5)**:
    *   Log server startup and shutdown events.
    *   Log tool execution requests, including tool name and parameters.
    *   Log errors and exceptions, including stack traces where appropriate (as done in `web-search.ts`).
    *   Log important resource access events if you add resource capabilities later.
    *   Consider logging performance metrics in the future if needed.

3.  **Server-Side Logging to `stderr` (Research Point 5.3)**:
    *   For stdio transport, logging errors and server-side events to `stderr` is a good practice for local transports. `console.error` naturally directs output to `stderr`.

4.  **Client Log Messages (Research Point 5.4) (Consider for future transports)**:
    *   For transports beyond stdio (like SSE or WebSockets), consider implementing the ability for the server to send log messages back to the client through MCP protocol mechanisms if client-side logging is desired. For stdio, client can observe server logs directly.

**Phase 7: Scalability Considerations (Research Point 6)**

1.  **Asynchronous Operations (Research Point 6.1)**:
    *   Utilize asynchronous operations (`async/await`) throughout the server and tool implementations to handle concurrent requests efficiently (already implemented in `web-search.ts` and server setup).

2.  **Connection Management (Research Point 6.2)**:
    *   The `@modelcontextprotocol/sdk` handles connection management for you in terms of MCP protocol. Ensure proper resource cleanup in your tool implementations if they manage external resources, though less critical for the current `web-search` tool.

3.  **Scalability Patterns (Research Point 6.6) (Future Considerations)**:
    *   **Load Balancing**: If you anticipate high request loads in the future and move beyond stdio transport, consider load balancing strategies to distribute requests across multiple server instances.
    *   **Horizontal Scaling**: Plan for horizontal scaling by designing the server to be stateless so you can easily add more server instances behind a load balancer as demand grows.
    *   **Resource Management and Monitoring (Research Point 6.3 & 6.5)**:  As you add more capabilities and complexity, monitor resource usage (CPU, memory, network) and implement efficient resource management practices in your tools and server.

**Phase 8: Documentation and Refinement**

1.  **Code Documentation**:
    *   Add comments to your code to explain the purpose of functions, classes, and complex logic.
    *   Generate API documentation using tools like TypeDoc if you intend to expose APIs beyond the MCP protocol itself.

2.  **README.md**:
    *   Create a `README.md` file in the project root to document:
        *   Project description and purpose.
        *   Setup instructions (environment variables, dependencies).
        *   How to run the server and test client.
        *   Available tools and their usage.
        *   Scalability and security considerations.

3.  **Continuous Refinement**:
    *   Continuously review and refine the implementation based on testing, feedback, and evolving requirements.
    *   Stay updated with best practices in MCP server development and security.

This detailed plan provides a roadmap for implementing your MCP server, incorporating research-backed best practices and focusing on security and scalability from the outset. Start with Phase 1 and progressively implement each phase, testing and refining as you go.
</file>

<file path="mcp-server/local-research/mcp-implementation-research.md">
Querying Perplexity AI using sonar-pro for: 1. What are the best practices for implementing transport layers in MCP servers? 2. What are the recommended security measures for MCP server implementations? 3. What are the optimal caching and rate limiting strategies for external API calls in MCP servers? 4. What are the recommended testing approaches for MCP server capabilities? 5. What are the best practices for error handling and logging in MCP servers? 6. What are the recommended scalability patterns for MCP server implementations?
1. Best practices for implementing transport layers in MCP servers:
- Use layered architecture with clear separation between client/server, session, and transport layers[1].
- Implement different transports for various use cases: STDIO for in-process communication, SSE for HTTP-based communication[1].
- Handle JSON-RPC message serialization/deserialization in the transport layer[1].
- Ensure proper connection establishment, protocol compatibility checks, and capability negotiation[1].

2. Recommended security measures for MCP server implementations:
- Implement strict input validation and sanitization[4].
- Use command whitelisting and flag validation for CLI-based servers[2].
- Prevent path traversal and shell injection attacks[2].
- Implement execution timeouts and command length limits[2].
- Use TLS encryption for API endpoints, especially in management networks[7].
- Employ access controls and proper authentication mechanisms[7].
- Use IDS/IPS for admin networks to detect anomalies[7].

3. Optimal caching and rate limiting strategies for external API calls:
- Implement token bucket algorithm for rate limiting[3]:
```csharp
builder.Services.AddRateLimiter(rateLimiterOptions => {
  options.TokenLimit = 1000;
  options.ReplenishmentPeriod = TimeSpan.FromHours(1);
  options.TokensPerPeriod = 700;
  options.AutoReplenishment = true;
});
```
- Use sliding window rate limiting for more precise control[9].
- Implement IP-based rate limiting to prevent abuse[9].
- Use distributed caching for scalability.

4. Recommended testing approaches for MCP server capabilities:
- Use the MCP Inspector tool for systematic testing[4].
- Test core features first, then add edge cases[4].
- Verify error handling and check performance[4].
- Implement a systematic approach: test core features, add edge cases, verify error handling, check performance[4].
- Use the Inspector during development for quick iteration[5].

5. Best practices for error handling and logging in MCP servers:
- Implement structured logging with consistent formats, context, and timestamps[5].
- Log stack traces, error context, and track error patterns[5].
- Use server-side logging to stderr for local transports[5].
- Send log message notifications to clients:
```python
server.request_context.session.send_log_message(
  level="info",
  data="Server started successfully"
)
```
- Log important events: initialization, resource access, tool execution, errors, performance metrics[5].

6. Recommended scalability patterns for MCP server implementations:
- Use asynchronous operations for improved concurrency[1].
- Implement proper connection management and cleanup[4].
- Use load balancing for distributing requests[7].
- Employ horizontal scaling by adding more server instances.
- Implement efficient resource management and monitoring[4].
</file>

<file path="mcp-server/local-research/typescript-esm-research.md">
Querying Perplexity AI using sonar-pro for: TypeScript ES modules configuration best practices with Node.js, focusing on moduleResolution, file extensions, and package.json settings
To configure TypeScript ES modules with Node.js, follow these best practices:

1. Set `"type": "module"` in package.json to treat .js files as ES modules[1][6].

2. Use `.mts` extension for TypeScript ES module files and `.cts` for CommonJS files[3][8].

3. Configure tsconfig.json:

```json
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ES2020",
    "moduleResolution": "node16",
    "outDir": "dist",
    "esModuleInterop": true
  }
}
```

4. Set `moduleResolution` to "node16" or "nodenext" for modern Node.js versions[2][7].

5. Use `--experimental-modules` flag when running Node.js[1].

6. For package exports, use the "exports" field in package.json:

```json
{
  "exports": {
    ".": {
      "import": "./dist/index.js",
      "require": "./dist/index.cjs"
    }
  }
}
```

7. Compile TypeScript files using:

```
tsc -p tsconfig.json
```

8. Run the compiled JS files with:

```
node --experimental-modules dist/index.js
```

These practices ensure proper ES module support in TypeScript projects with Node.js[1][2][3][6][7][8].
</file>

<file path="mcp-server/package.json">
{
  "name": "mcp-server",
  "version": "1.0.0",
  "description": "A beginner-friendly MCP server implementation",
  "type": "module",
  "main": "dist/server.js",
  "scripts": {
    "clean": "rimraf dist",
    "build": "npm run clean && tsc",
    "start": "node dist/server.js",
    "dev": "ts-node --esm src/server.ts",
    "test": "cross-env DOTENV_CONFIG_PATH=.env.test NODE_OPTIONS=--experimental-vm-modules jest --no-cache",
    "lint": "eslint . --ext .ts",
    "lint:fix": "eslint . --ext .ts --fix",
    "prepare": "husky install"
  },
  "keywords": [
    "mcp",
    "server",
    "model-context-protocol"
  ],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "@google/generative-ai": "^0.22.0",
    "@modelcontextprotocol/sdk": "1.2.0",
    "@octokit/rest": "19.0.13",
    "axios": "1.6.5",
    "dotenv": "16.3.1",
    "playwright": "1.41.2",
    "zod": "^3.24.2"
  },
  "devDependencies": {
    "@types/jest": "^29.5.11",
    "@types/node": "20.11.5",
    "@typescript-eslint/eslint-plugin": "^6.19.1",
    "@typescript-eslint/parser": "^6.19.1",
    "cross-env": "^7.0.3",
    "eslint": "^8.56.0",
    "eslint-config-prettier": "^9.1.0",
    "eslint-plugin-prettier": "^5.1.3",
    "husky": "^8.0.3",
    "jest": "^29.7.0",
    "prettier": "^3.2.4",
    "rimraf": "^5.0.5",
    "ts-jest": "^29.1.2",
    "ts-node": "10.9.2",
    "typescript": "5.3.3"
  }
}
</file>

<file path="mcp-server/src/capabilities/tools/__tests__/web-search.test.ts">
import { jest } from "@jest/globals"; import { webSearchTool } from "../web-search.js"; import { config } from "../../../config/index.js"; import axios from "axios"; import { z } from "zod"; jest.mock("axios"); const mockedAxios = jest.mocked(axios); jest.mock("../../../config/index.js", () => ({ config: { env: "test", perplexityApiKey: undefined, logLevel: "info" } })); jest.mock("../../../utils/logger.js", () => ({ logger: { info: jest.fn(), warn: jest.fn(), error: jest.fn(), debug: jest.fn() } })); describe("Web Search Tool", () => { beforeEach(() => { jest.clearAllMocks(); }); describe("when PERPLEXITY_API_KEY is not provided", () => { it("should return mock results in test environment", async () => { const request = { query: "test query" }; const result = await webSearchTool.execute(request); expect(result).toEqual({ searchResults: "Mock search results for testing" }); expect(mockedAxios.post).not.toHaveBeenCalled(); }); }); describe("when PERPLEXITY_API_KEY is provided", () => { beforeEach(() => { (config as any).perplexityApiKey = "test-api-key"; }); it("should make API call and return results", async () => { const mockResponse = { data: { choices: [{ message: { content: "API search results" } }] } }; mockedAxios.post.mockResolvedValueOnce(mockResponse); const request = { query: "test query" }; const result = await webSearchTool.execute(request); expect(result).toEqual({ searchResults: "API search results" }); expect(mockedAxios.post).toHaveBeenCalledWith(expect.any(String), expect.objectContaining({ messages: [{ role: "user", content: "test query" }] }), expect.objectContaining({ headers: { "Authorization": "Bearer test-api-key" } })); }); it("should handle API errors gracefully", async () => { const mockError = { response: { data: { error: "API Error" } } }; mockedAxios.post.mockRejectedValueOnce(mockError); const request = { query: "test query" }; await expect(webSearchTool.execute(request)).rejects.toThrow("Web search failed: API Error"); }); it("should validate request schema", async () => { const invalidRequest = { query: "" }; await expect(webSearchTool.execute(invalidRequest)).rejects.toThrow("Search query is required"); }); it("should handle saving results to file when requested", async () => { const mockResponse = { data: { choices: [{ message: { content: "API search results" } }] } }; mockedAxios.post.mockResolvedValueOnce(mockResponse); const request = { query: "test query", saveToFile: true }; const result = await webSearchTool.execute(request); expect(result).toMatchObject({ searchResults: "API search results", savedToFile: expect.stringContaining("web-search-") }); }); }); });
</file>

<file path="mcp-server/src/capabilities/tools/web-search.js">
"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.webSearchTool = void 0;
const axios_1 = __importDefault(require("axios"));
const dotenv_1 = __importDefault(require("dotenv"));
// Load environment variables
dotenv_1.default.config();
const PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions";
const PERPLEXITY_API_KEY = process.env.PERPLEXITY_API_KEY;
exports.webSearchTool = {
    name: 'web-search',
    version: '0.1.0',
    description: 'Performs a web search using Perplexity AI.',
    execute: (request) => __awaiter(void 0, void 0, void 0, function* () {
        var _a, _b, _c, _d;
        if (!PERPLEXITY_API_KEY) {
            throw new Error("Perplexity API key is not set in environment variables (PERPLEXITY_API_KEY)");
        }
        const { query, saveTo } = request;
        if (!query) {
            throw new Error("Search query is required.");
        }
        try {
            console.log(`üîç Performing web search: "${query}"`);
            const response = yield axios_1.default.post(PERPLEXITY_API_URL, {
                model: "pplx-7b-online",
                messages: [{ role: "user", content: query }]
            }, {
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${PERPLEXITY_API_KEY}`
                }
            });
            const searchResults = ((_b = (_a = response.data.choices[0]) === null || _a === void 0 ? void 0 : _a.message) === null || _b === void 0 ? void 0 : _b.content) || "No results found.";
            // If saveTo is specified, save results to file
            if (saveTo) {
                const fs = yield Promise.resolve().then(() => __importStar(require('fs/promises')));
                yield fs.writeFile(saveTo, searchResults, 'utf-8');
                console.log(`‚úÖ Results saved to: ${saveTo}`);
                return { searchResults, savedToFile: saveTo };
            }
            return { searchResults };
        }
        catch (error) {
            console.error("‚ùå Error during web search:", error);
            if (axios_1.default.isAxiosError(error)) {
                throw new Error(`Web search failed: ${((_d = (_c = error.response) === null || _c === void 0 ? void 0 : _c.data) === null || _d === void 0 ? void 0 : _d.error) || error.message}`);
            }
            throw new Error(`Web search failed: ${error}`);
        }
    }),
    requestSchema: {
        type: 'object',
        properties: {
            query: {
                type: 'string',
                description: 'The search query.'
            },
            saveTo: {
                type: 'string',
                description: 'Optional file path to save the search results.'
            }
        },
        required: ['query']
    },
    responseSchema: {
        type: 'object',
        properties: {
            searchResults: {
                type: 'string',
                description: 'Web search results.'
            },
            savedToFile: {
                type: 'string',
                description: 'Path to the file where results were saved, if applicable.'
            }
        },
        required: ['searchResults']
    }
};
</file>

<file path="mcp-server/src/capabilities/tools/web-search.ts">
import axios from 'axios';
import { z } from 'zod';
import { config } from '../../config/index.js';
import { logger } from '../../utils/logger.js';
import dotenv from 'dotenv';
// Load environment variables
dotenv.config();
const PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions";
const PERPLEXITY_API_KEY = process.env.PERPLEXITY_API_KEY;
interface WebSearchRequest {
    query: string;
    saveTo?: string;
}
interface WebSearchResponse {
    searchResults: string;
    savedToFile?: string;
}
export const webSearchTool = {
    name: 'web-search',
    version: '0.1.0',
    description: 'Performs a web search using Perplexity AI.',
    execute: async (request: WebSearchRequest): Promise<WebSearchResponse> => {
        if (!PERPLEXITY_API_KEY) {
            throw new Error("Perplexity API key is not set in environment variables (PERPLEXITY_API_KEY)");
        }
        const { query, saveTo } = request;
        if (!query) {
            throw new Error("Search query is required.");
        }
        try {
            console.log(`üîç Performing web search: "${query}"`);
            const response = await axios.post(PERPLEXITY_API_URL, {
                model: "pplx-7b-online",
                messages: [{ role: "user", content: query }]
            }, {
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${PERPLEXITY_API_KEY}`
                }
            });
            const searchResults = response.data.choices[0]?.message?.content || "No results found.";
            // If saveTo is specified, save results to file
            if (saveTo) {
                const fs = await import('fs/promises');
                await fs.writeFile(saveTo, searchResults, 'utf-8');
                console.log(`‚úÖ Results saved to: ${saveTo}`);
                return { searchResults, savedToFile: saveTo };
            }
            return { searchResults };
        } catch (error) {
            console.error("‚ùå Error during web search:", error);
            if (axios.isAxiosError(error)) {
                throw new Error(`Web search failed: ${error.response?.data?.error || error.message}`);
            }
            throw new Error(`Web search failed: ${error}`);
        }
    },
    requestSchema: {
        type: 'object',
        properties: {
            query: { 
                type: 'string', 
                description: 'The search query.' 
            },
            saveTo: { 
                type: 'string', 
                description: 'Optional file path to save the search results.' 
            }
        },
        required: ['query']
    },
    responseSchema: {
        type: 'object',
        properties: {
            searchResults: { 
                type: 'string', 
                description: 'Web search results.' 
            },
            savedToFile: { 
                type: 'string', 
                description: 'Path to the file where results were saved, if applicable.' 
            }
        },
        required: ['searchResults']
    }
};
</file>

<file path="mcp-server/src/config/index.js">
"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.environment = exports.config = exports.ServerConfigSchema = void 0;
const zod_1 = require("zod");
const dotenv_1 = __importDefault(require("dotenv"));
// Load environment variables
dotenv_1.default.config();
// Define environment variable schema
const EnvSchema = zod_1.z.object({
    NODE_ENV: zod_1.z.enum(['development', 'production', 'test']).default('development'),
    LOG_LEVEL: zod_1.z.enum(['debug', 'info', 'warn', 'error']).default('info'),
    PERPLEXITY_API_KEY: zod_1.z.string(),
    PORT: zod_1.z.string().optional(),
    HOST: zod_1.z.string().optional()
});
// Define server configuration schema
exports.ServerConfigSchema = zod_1.z.object({
    name: zod_1.z.string(),
    version: zod_1.z.string(),
    description: zod_1.z.string(),
    logLevel: zod_1.z.enum(['debug', 'info', 'warn', 'error']).default('info'),
    env: zod_1.z.enum(['development', 'production', 'test']).default('development'),
    port: zod_1.z.number().optional(),
    host: zod_1.z.string().optional()
});
// Parse and validate environment variables
const env = EnvSchema.parse(process.env);
// Export validated configuration
exports.config = {
    name: "cursor-tools-mcp-server",
    version: "0.1.0",
    description: "MCP server mimicking cursor-tools functionalities.",
    logLevel: env.LOG_LEVEL,
    env: env.NODE_ENV,
    port: env.PORT ? parseInt(env.PORT, 10) : undefined,
    host: env.HOST,
    perplexityApiKey: env.PERPLEXITY_API_KEY
};
// Export environment variables
exports.environment = env;
</file>

<file path="mcp-server/src/config/index.ts">
import { z } from 'zod';
import dotenv from 'dotenv';
// Load environment variables
dotenv.config();
// Define environment variable schema
const EnvSchema = z.object({
    NODE_ENV: z.enum(['development', 'production', 'test']).default('development'),
    LOG_LEVEL: z.enum(['debug', 'info', 'warn', 'error']).default('info'),
    PERPLEXITY_API_KEY: z.string().optional(),
    GEMINI_API_KEY: z.string(),
    PORT: z.string().optional(),
    HOST: z.string().optional()
});
// Define server configuration schema
export const ServerConfigSchema = z.object({
    name: z.string(),
    version: z.string(),
    description: z.string(),
    logLevel: z.enum(['debug', 'info', 'warn', 'error']).default('info'),
    env: z.enum(['development', 'production', 'test']).default('development'),
    port: z.number().optional(),
    host: z.string().optional()
});
// Parse and validate environment variables
const env = EnvSchema.parse(process.env);
// Export validated configuration
export const config = {
    name: "cursor-tools-mcp-server",
    version: "0.1.0",
    description: "MCP server mimicking cursor-tools functionalities.",
    logLevel: env.LOG_LEVEL,
    env: env.NODE_ENV,
    port: env.PORT ? parseInt(env.PORT, 10) : undefined,
    host: env.HOST,
    perplexityApiKey: env.PERPLEXITY_API_KEY,
    geminiApiKey: env.GEMINI_API_KEY
};
// Export environment variables
export const environment = env;
</file>

<file path="mcp-server/src/gemini/__tests__/service.test.ts">
import { jest } from '@jest/globals';
import { GeminiService, RepositoryAnalysisRequest } from '../service.js';
import { genAI, geminiConfig } from '../config.js';
import { logger } from '../../utils/logger.js';
// Mock the logger
jest.mock('../../utils/logger.js', () => ({
  logger: {
    error: jest.fn(),
    warn: jest.fn(),
    debug: jest.fn(),
  },
}));
// Create mock function
const mockGenerateContent = jest.fn();
// Mock the Gemini API
jest.mock('@google/generative-ai', () => ({
  GoogleGenerativeAI: jest.fn().mockImplementation(() => ({
    getGenerativeModel: jest.fn().mockReturnValue({
      generateContent: mockGenerateContent,
    }),
  })),
}));
jest.mock('../config.js', () => ({
  genAI: {
    getGenerativeModel: jest.fn().mockReturnValue({
      generateContent: mockGenerateContent,
    }),
  },
  geminiConfig: {
    model: 'gemini-pro',
    temperature: 0.7,
    topK: 40,
    topP: 0.95,
    maxOutputTokens: 2048,
  },
}));
describe('GeminiService', () => {
  let service: GeminiService;
  beforeEach(() => {
    jest.clearAllMocks();
    service = new GeminiService();
  });
  describe('analyzeRepository', () => {
    const mockRequest: RepositoryAnalysisRequest = {
      repoPath: '/test/repo',
      query: 'Analyze code quality',
    };
    it('should successfully analyze repository with all sections', async () => {
      const mockAnalysis = `
        Analysis:
        The repository has a good structure and follows best practices.
        Suggestions:
        1. Add more tests
        2. Improve documentation
        Issues:
        * Some code duplication found
        * Missing error handling in critical sections
      `;
      mockGenerateContent.mockImplementation(() =>
        Promise.resolve({
          response: {
            text: () => mockAnalysis,
          },
        })
      );
      const result = await service.analyzeRepository(mockRequest);
      expect(result.analysis).toBe(mockAnalysis);
      expect(result.suggestions).toEqual([
        'Add more tests',
        'Improve documentation',
      ]);
      expect(result.issues).toEqual([
        'Some code duplication found',
        'Missing error handling in critical sections',
      ]);
      expect(result.error).toBeUndefined();
      expect(mockGenerateContent).toHaveBeenCalledWith(expect.any(String));
    });
    it('should handle rate limiting and retry', async () => {
      const rateLimitError = new Error('RATE_LIMIT');
      const successResponse = {
        response: {
          text: () => 'Success after retry',
        },
      };
      mockGenerateContent
        .mockImplementationOnce(() => Promise.reject(rateLimitError))
        .mockImplementationOnce(() => Promise.resolve(successResponse));
      const result = await service.analyzeRepository(mockRequest);
      expect(result.analysis).toBe('Success after retry');
      expect(mockGenerateContent).toHaveBeenCalledTimes(2);
      expect(logger.warn).toHaveBeenCalledWith(
        expect.stringContaining('Attempt 1 failed'),
        expect.any(Object)
      );
    });
    it('should handle errors gracefully', async () => {
      const mockError = new Error('API error');
      mockGenerateContent.mockImplementation(() => Promise.reject(mockError));
      const result = await service.analyzeRepository(mockRequest);
      expect(result.analysis).toBe('');
      expect(result.error).toBe('API error');
      expect(result.suggestions).toBeUndefined();
      expect(logger.error).toHaveBeenCalledWith(
        'Error analyzing repository:',
        expect.objectContaining({
          error: mockError,
          request: mockRequest,
        })
      );
    });
    it('should handle malformed response gracefully', async () => {
      const malformedResponse = `
        Invalid format
        No clear sections
        Random text
      `;
      mockGenerateContent.mockImplementation(() =>
        Promise.resolve({
          response: {
            text: () => malformedResponse,
          },
        })
      );
      const result = await service.analyzeRepository(mockRequest);
      expect(result.analysis).toBe(malformedResponse);
      expect(result.suggestions).toEqual([]);
      expect(result.issues).toEqual([]);
    });
    it('should include context in analysis when provided', async () => {
      const requestWithContext: RepositoryAnalysisRequest = {
        ...mockRequest,
        context: 'TypeScript project with React',
      };
      mockGenerateContent.mockImplementation((prompt: any) => {
        expect(prompt).toContain('TypeScript project with React');
        return Promise.resolve({
          response: {
            text: () => 'Analysis with context',
          },
        });
      });
      await service.analyzeRepository(requestWithContext);
      expect(mockGenerateContent).toHaveBeenCalledWith(expect.any(String));
      const prompt = mockGenerateContent.mock.calls[0][0] as string;
      expect(prompt).toContain('Additional context: TypeScript project with React');
    });
    it('should respect rate limiting', async () => {
      jest.useFakeTimers();
      const requests = Array(5).fill(mockRequest);
      mockGenerateContent.mockImplementation(() =>
        Promise.resolve({
          response: {
            text: () => 'Test response',
          },
        })
      );
      // Start all requests concurrently
      const promises = requests.map(req => service.analyzeRepository(req));
      // Fast-forward time by 100ms after each request
      for (let i = 0; i < requests.length; i++) {
        jest.advanceTimersByTime(100);
        await Promise.resolve(); // Let the promises resolve
      }
      await Promise.all(promises);
      expect(mockGenerateContent).toHaveBeenCalledTimes(5);
      expect(logger.debug).toHaveBeenCalledWith(
        expect.stringContaining('Rate limit reached'),
        expect.any(Object)
      );
      jest.useRealTimers();
    });
  });
});
</file>

<file path="mcp-server/src/gemini/config.ts">
import { GoogleGenerativeAI } from '@google/generative-ai';
import dotenv from 'dotenv';
dotenv.config();
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
if (!GEMINI_API_KEY) {
  throw new Error('GEMINI_API_KEY environment variable is not set');
}
export const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
export const geminiConfig = {
  model: 'gemini-pro',
  temperature: 0.7,
  topK: 40,
  topP: 0.95,
  maxOutputTokens: 2048,
};
</file>

<file path="mcp-server/src/gemini/service.ts">
import { genAI, geminiConfig } from './config.js';
import { withRetry } from '../utils/retry.js';
import { logger } from '../utils/logger.js';
import { z } from 'zod';
export interface RepositoryAnalysisRequest {
  repoPath: string;
  query: string;
  context?: string;
}
export interface RepositoryAnalysisResponse {
  analysis: string;
  suggestions?: string[];
  issues?: string[];
  error?: string;
}
// Response schema for validation
const AnalysisResponseSchema = z.object({
  analysis: z.string(),
  suggestions: z.array(z.string()).optional(),
  issues: z.array(z.string()).optional(),
});
export class GeminiServiceError extends Error {
  constructor(message: string, public readonly cause?: Error) {
    super(message);
    this.name = 'GeminiServiceError';
  }
}
export class GeminiService {
  private model = genAI.getGenerativeModel(geminiConfig);
  private rateLimiter = {
    tokens: 10,
    maxTokens: 10,
    lastRefill: Date.now(),
    refillRate: 1000, // 1 token per second
  };
  private async acquireToken(): Promise<void> {
    const now = Date.now();
    const timePassed = now - this.rateLimiter.lastRefill;
    const tokensToAdd = Math.floor(timePassed / this.rateLimiter.refillRate);
    if (tokensToAdd > 0) {
      this.rateLimiter.tokens = Math.min(
        this.rateLimiter.maxTokens,
        this.rateLimiter.tokens + tokensToAdd
      );
      this.rateLimiter.lastRefill = now;
    }
    if (this.rateLimiter.tokens <= 0) {
      const waitTime = this.rateLimiter.refillRate;
      logger.debug(`Rate limit reached, waiting ${waitTime}ms`);
      await new Promise(resolve => setTimeout(resolve, waitTime));
      return this.acquireToken();
    }
    this.rateLimiter.tokens--;
  }
  async analyzeRepository(request: RepositoryAnalysisRequest): Promise<RepositoryAnalysisResponse> {
    try {
      await this.acquireToken();
      const operation = async () => {
        const prompt = this.buildAnalysisPrompt(request);
        const result = await this.model.generateContent(prompt);
        const response = await result.response;
        const text = response.text();
        return {
          analysis: text,
          ...this.parseAnalysisResponse(text),
        };
      };
      return await withRetry(operation, {
        maxAttempts: 3,
        retryableErrors: ['RATE_LIMIT', 'RESOURCE_EXHAUSTED'],
      });
    } catch (error) {
      logger.error('Error analyzing repository:', { error, request });
      if (error instanceof GeminiServiceError) {
        throw error;
      }
      return {
        analysis: '',
        error: error instanceof Error ? error.message : 'Unknown error occurred',
      };
    }
  }
  private buildAnalysisPrompt(request: RepositoryAnalysisRequest): string {
    const contextInfo = request.context ? `\nAdditional context: ${request.context}` : '';
    return `
      Analyze the following repository:
      Path: ${request.repoPath}
      Query: ${request.query}${contextInfo}
      Please provide your response in the following format:
      Analysis:
      [Detailed analysis of the repository structure and code patterns]
      Suggestions:
      1. [First suggestion]
      2. [Second suggestion]
      ...
      Issues:
      * [First issue]
      * [Second issue]
      ...
      Ensure each section is clearly marked and suggestions/issues are properly formatted with numbers or bullet points.
    `.trim();
  }
  private parseAnalysisResponse(text: string): { suggestions: string[]; issues: string[] } {
    const sections = {
      suggestions: [] as string[],
      issues: [] as string[],
    };
    const lines = text.split('\n');
    let currentSection: keyof typeof sections | null = null;
    for (const line of lines) {
      const trimmedLine = line.trim();
      // Determine section
      if (trimmedLine.toLowerCase().includes('suggestion')) {
        currentSection = 'suggestions';
        continue;
      } else if (trimmedLine.toLowerCase().includes('issue')) {
        currentSection = 'issues';
        continue;
      }
      // Process line if in a valid section
      if (currentSection && trimmedLine) {
        const match = trimmedLine.match(/^(?:\d+\.|[-‚Ä¢*])\s*(.+)$/);
        if (match) {
          sections[currentSection].push(match[1].trim());
        }
      }
      // Exit section on empty line
      if (currentSection && !trimmedLine) {
        currentSection = null;
      }
    }
    return sections;
  }
}
</file>

<file path="mcp-server/src/server.js">
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("@modelcontextprotocol/sdk/server/index.js");
const stdio_js_1 = require("@modelcontextprotocol/sdk/server/stdio.js");
const web_search_js_1 = require("./capabilities/tools/web-search.js");
function main() {
    return __awaiter(this, void 0, void 0, function* () {
        try {
            console.log("Starting MCP server...");
            const server = new index_js_1.Server({
                name: "cursor-tools-mcp-server",
                version: "0.1.0",
                description: "MCP server mimicking cursor-tools functionalities."
            }, {
                capabilities: {
                    resources: {}, // Resources will be defined here
                    tools: {
                        'web-search': web_search_js_1.webSearchTool
                    }
                }
            });
            const transport = new stdio_js_1.StdioServerTransport();
            console.log("Connecting to transport...");
            yield server.connect(transport);
            console.log("‚úÖ MCP Server started using stdio transport.");
            console.log("Available tools:");
            console.log("  - web-search: Perform web searches using Perplexity AI");
        }
        catch (error) {
            console.error("‚ùå Server failed to start:", error);
            process.exit(1);
        }
    });
}
// Handle process termination
process.on('SIGINT', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
process.on('SIGTERM', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
// Start the server
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="mcp-server/src/server.ts">
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { webSearchTool } from './capabilities/tools/web-search.js';
import { config, ServerConfigSchema } from './config/index.js';
import { logger } from './utils/logger.js';
import { z } from 'zod';
async function main() {
    try {
        console.log("Starting MCP server...");
        const server = new Server({
            name: "cursor-tools-mcp-server",
            version: "0.1.0",
            description: "MCP server mimicking cursor-tools functionalities."
        }, {
            capabilities: {
                resources: {}, // Resources will be defined here
                tools: {
                    'web-search': webSearchTool
                }
            }
        });
        const transport = new StdioServerTransport();
        console.log("Connecting to transport...");
        await server.connect(transport);
        console.log("‚úÖ MCP Server started using stdio transport.");
        console.log("Available tools:");
        console.log("  - web-search: Perform web searches using Perplexity AI");
    } catch (error) {
        console.error("‚ùå Server failed to start:", error);
        process.exit(1);
    }
}
// Handle process termination
process.on('SIGINT', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
process.on('SIGTERM', () => {
    console.log("\nShutting down MCP server...");
    process.exit(0);
});
// Start the server
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="mcp-server/src/test-client.js">
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("@modelcontextprotocol/sdk/client/index.js");
const stdio_js_1 = require("@modelcontextprotocol/sdk/client/stdio.js");
const zod_1 = require("zod");
// Define response schema
const WebSearchResponseSchema = zod_1.z.object({
    result: zod_1.z.object({
        searchResults: zod_1.z.string(),
        savedToFile: zod_1.z.string().optional()
    })
});
function main() {
    return __awaiter(this, void 0, void 0, function* () {
        // Initialize transport with required parameters
        const transport = new stdio_js_1.StdioClientTransport({
            command: 'node',
            args: ['dist/server.js']
        });
        const client = new index_js_1.Client({
            name: "test-client",
            version: "0.1.0"
        }, {
            capabilities: {}
        });
        try {
            console.log("Connecting to MCP server...");
            yield client.connect(transport);
            console.log("‚úÖ Connected to MCP server\n");
            // Test web search
            console.log("Testing web search tool...");
            const response = yield client.request({
                method: "tool/execute",
                params: {
                    toolName: 'web-search',
                    version: '0.1.0',
                    arguments: {
                        query: "What are the latest developments in AI?",
                        saveTo: "local-research/ai-developments.md"
                    }
                }
            }, WebSearchResponseSchema);
            console.log("\nWeb Search Results:");
            console.log("------------------");
            console.log(response.result.searchResults);
            if (response.result.savedToFile) {
                console.log(`\nResults saved to: ${response.result.savedToFile}`);
            }
        }
        catch (error) {
            console.error("‚ùå Error:", error);
        }
        finally {
            console.log("\nClosing client connection...");
            client.close();
        }
    });
}
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="mcp-server/src/test-client.ts">
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import { z } from 'zod';
import { spawn } from 'child_process';
import { logger } from './utils/logger.js';
import { config } from './config/index.js';
// Define response schema
const WebSearchResponseSchema = z.object({
    result: z.object({
        searchResults: z.string(),
        savedToFile: z.string().optional()
    })
});
async function main() {
    // Initialize transport with required parameters
    const transport = new StdioClientTransport({
        command: 'node',
        args: ['dist/server.js']
    });
    const client = new Client({
        name: "test-client",
        version: "0.1.0"
    }, {
        capabilities: {}
    });
    try {
        console.log("Connecting to MCP server...");
        await client.connect(transport);
        console.log("‚úÖ Connected to MCP server\n");
        // Test web search
        console.log("Testing web search tool...");
        const response = await client.request({
            method: "tool/execute",
            params: {
                toolName: 'web-search',
                version: '0.1.0',
                arguments: {
                    query: "What are the latest developments in AI?",
                    saveTo: "local-research/ai-developments.md"
                }
            }
        }, WebSearchResponseSchema);
        console.log("\nWeb Search Results:");
        console.log("------------------");
        console.log(response.result.searchResults);
        if (response.result.savedToFile) {
            console.log(`\nResults saved to: ${response.result.savedToFile}`);
        }
    } catch (error) {
        console.error("‚ùå Error:", error);
    } finally {
        console.log("\nClosing client connection...");
        client.close();
    }
}
main().catch((error) => {
    console.error("Fatal error:", error);
    process.exit(1);
});
</file>

<file path="mcp-server/src/test-setup.js">
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("@modelcontextprotocol/sdk/server/index.js");
const playwright_1 = require("playwright");
const rest_1 = require("@octokit/rest");
const axios_1 = __importDefault(require("axios"));
const dotenv_1 = __importDefault(require("dotenv"));
function testSetup() {
    return __awaiter(this, void 0, void 0, function* () {
        try {
            console.log('üîç Starting dependency verification...\n');
            // Test dotenv first to load environment variables
            dotenv_1.default.config();
            console.log('‚úÖ dotenv loaded successfully');
            // Test MCP SDK
            const server = new index_js_1.Server({
                name: "test-server",
                version: "1.0.0"
            }, {
                capabilities: {
                    resources: {},
                    tools: {}
                }
            });
            console.log('‚úÖ MCP SDK initialized successfully');
            // Test Playwright
            console.log('\nüåê Testing browser automation...');
            const browser = yield playwright_1.chromium.launch();
            yield browser.close();
            console.log('‚úÖ Playwright working correctly');
            // Test Octokit
            console.log('\nüì¶ Testing GitHub integration...');
            const octokit = new rest_1.Octokit();
            const { status } = yield octokit.rest.meta.root();
            console.log(`‚úÖ Octokit connected successfully (status: ${status})`);
            // Test Axios
            console.log('\nüîå Testing HTTP client...');
            const response = yield axios_1.default.get('https://api.github.com');
            console.log(`‚úÖ Axios working correctly (status: ${response.status})`);
            console.log('\n‚ú® All dependencies verified successfully!');
        }
        catch (error) {
            console.error('\n‚ùå Setup test failed:', error);
            process.exit(1);
        }
    });
}
testSetup();
</file>

<file path="mcp-server/src/test-setup.ts">
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { chromium } from 'playwright';
import { Octokit } from '@octokit/rest';
import axios from 'axios';
import dotenv from 'dotenv';
async function testSetup() {
  try {
    console.log('üîç Starting dependency verification...\n');
    // Test dotenv first to load environment variables
    dotenv.config();
    console.log('‚úÖ dotenv loaded successfully');
    // Test MCP SDK
    const server = new Server({
      name: "test-server",
      version: "1.0.0"
    }, {
      capabilities: {
        resources: {},
        tools: {}
      }
    });
    console.log('‚úÖ MCP SDK initialized successfully');
    // Test Playwright
    console.log('\nüåê Testing browser automation...');
    const browser = await chromium.launch();
    await browser.close();
    console.log('‚úÖ Playwright working correctly');
    // Test Octokit
    console.log('\nüì¶ Testing GitHub integration...');
    const octokit = new Octokit();
    const { status } = await octokit.rest.meta.root();
    console.log(`‚úÖ Octokit connected successfully (status: ${status})`);
    // Test Axios
    console.log('\nüîå Testing HTTP client...');
    const response = await axios.get('https://api.github.com');
    console.log(`‚úÖ Axios working correctly (status: ${response.status})`);
    console.log('\n‚ú® All dependencies verified successfully!');
  } catch (error) {
    console.error('\n‚ùå Setup test failed:', error);
    process.exit(1);
  }
}
testSetup();
</file>

<file path="mcp-server/src/utils/logger.js">
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.logger = void 0;
const index_js_1 = require("../config/index.js");
// Define log levels and their numeric values
const LogLevels = {
    debug: 0,
    info: 1,
    warn: 2,
    error: 3
};
class Logger {
    constructor(logLevel = 'info') {
        this.currentLogLevel = logLevel;
    }
    shouldLog(level) {
        return LogLevels[level] >= LogLevels[this.currentLogLevel];
    }
    formatMessage(level, message, context) {
        return {
            level,
            message,
            timestamp: new Date().toISOString(),
            context
        };
    }
    log(level, message, context) {
        if (!this.shouldLog(level))
            return;
        const logMessage = this.formatMessage(level, message, context);
        const output = JSON.stringify(logMessage);
        switch (level) {
            case 'error':
                console.error(output);
                break;
            case 'warn':
                console.warn(output);
                break;
            default:
                console.log(output);
        }
    }
    debug(message, context) {
        this.log('debug', message, context);
    }
    info(message, context) {
        this.log('info', message, context);
    }
    warn(message, context) {
        this.log('warn', message, context);
    }
    error(message, context) {
        this.log('error', message, context);
    }
}
// Create and export singleton instance
exports.logger = new Logger(index_js_1.config.logLevel);
</file>

<file path="mcp-server/src/utils/logger.ts">
import { config } from '../config/index.js';
// Define log levels and their numeric values
const LogLevels = {
    debug: 0,
    info: 1,
    warn: 2,
    error: 3
} as const;
type LogLevel = keyof typeof LogLevels;
interface LogMessage {
    level: LogLevel;
    message: string;
    timestamp: string;
    context?: Record<string, unknown>;
}
class Logger {
    private currentLogLevel: LogLevel;
    constructor(logLevel: LogLevel = 'info') {
        this.currentLogLevel = logLevel;
    }
    private shouldLog(level: LogLevel): boolean {
        return LogLevels[level] >= LogLevels[this.currentLogLevel];
    }
    private formatMessage(level: LogLevel, message: string, context?: Record<string, unknown>): LogMessage {
        return {
            level,
            message,
            timestamp: new Date().toISOString(),
            context
        };
    }
    private log(level: LogLevel, message: string, context?: Record<string, unknown>) {
        if (!this.shouldLog(level)) return;
        const logMessage = this.formatMessage(level, message, context);
        const output = JSON.stringify(logMessage);
        switch (level) {
            case 'error':
                console.error(output);
                break;
            case 'warn':
                console.warn(output);
                break;
            default:
                console.log(output);
        }
    }
    debug(message: string, context?: Record<string, unknown>) {
        this.log('debug', message, context);
    }
    info(message: string, context?: Record<string, unknown>) {
        this.log('info', message, context);
    }
    warn(message: string, context?: Record<string, unknown>) {
        this.log('warn', message, context);
    }
    error(message: string, context?: Record<string, unknown>) {
        this.log('error', message, context);
    }
}
// Create and export singleton instance
export const logger = new Logger(config.logLevel);
</file>

<file path="mcp-server/src/utils/retry.ts">
import { logger } from './logger.js';
export interface RetryOptions {
  maxAttempts: number;
  initialDelay: number;
  maxDelay: number;
  backoffFactor: number;
  retryableErrors?: Array<string | RegExp>;
}
export const defaultRetryOptions: RetryOptions = {
  maxAttempts: 3,
  initialDelay: 1000,
  maxDelay: 10000,
  backoffFactor: 2,
  retryableErrors: [
    'ECONNRESET',
    'ETIMEDOUT',
    'ECONNREFUSED',
    'RATE_LIMIT',
    /^5\d{2}$/,  // 5XX errors
    'socket hang up',
  ],
};
export class RetryError extends Error {
  constructor(
    message: string,
    public readonly attempts: number,
    public readonly lastError: Error
  ) {
    super(message);
    this.name = 'RetryError';
  }
}
export async function withRetry<T>(
  operation: () => Promise<T>,
  options: Partial<RetryOptions> = {}
): Promise<T> {
  const retryOptions = { ...defaultRetryOptions, ...options };
  let lastError: Error | null = null;
  let delay = retryOptions.initialDelay;
  for (let attempt = 1; attempt <= retryOptions.maxAttempts; attempt++) {
    try {
      return await operation();
    } catch (error) {
      lastError = error as Error;
      if (attempt === retryOptions.maxAttempts) {
        throw new RetryError(
          `Operation failed after ${attempt} attempts`,
          attempt,
          lastError
        );
      }
      const shouldRetry = retryOptions.retryableErrors?.some(pattern => {
        if (pattern instanceof RegExp) {
          return pattern.test(lastError?.message || '');
        }
        return lastError?.message?.includes(pattern);
      });
      if (!shouldRetry) {
        throw lastError;
      }
      logger.warn(`Attempt ${attempt} failed, retrying in ${delay}ms`, {
        error: lastError.message,
        attempt,
        nextDelay: delay,
      });
      await new Promise(resolve => setTimeout(resolve, delay));
      delay = Math.min(delay * retryOptions.backoffFactor, retryOptions.maxDelay);
    }
  }
  throw new RetryError(
    'Retry operation failed unexpectedly',
    retryOptions.maxAttempts,
    lastError!
  );
}
</file>

<file path="mcp-server/tsconfig.json">
{
  "compilerOptions": {
    /* Visit https://aka.ms/tsconfig to read more about this file */

    /* Projects */
    // "incremental": true,                              /* Save .tsbuildinfo files to allow for incremental compilation of projects. */
    // "composite": true,                                /* Enable constraints that allow a TypeScript project to be used with project references. */
    // "tsBuildInfoFile": "./.tsbuildinfo",              /* Specify the path to .tsbuildinfo incremental compilation file. */
    // "disableSourceOfProjectReferenceRedirect": true,  /* Disable preferring source files instead of declaration files when referencing composite projects. */
    // "disableSolutionSearching": true,                 /* Opt a project out of multi-project reference checking when editing. */
    // "disableReferencedProjectLoad": true,             /* Reduce the number of projects loaded automatically by TypeScript. */

    /* Language and Environment */
    "target": "ES2022",
    // "lib": [],                                        /* Specify a set of bundled library declaration files that describe the target runtime environment. */
    // "jsx": "preserve",                                /* Specify what JSX code is generated. */
    // "experimentalDecorators": true,                   /* Enable experimental support for legacy experimental decorators. */
    // "emitDecoratorMetadata": true,                    /* Emit design-type metadata for decorated declarations in source files. */
    // "jsxFactory": "",                                 /* Specify the JSX factory function used when targeting React JSX emit, e.g. 'React.createElement' or 'h'. */
    // "jsxFragmentFactory": "",                         /* Specify the JSX Fragment reference used for fragments when targeting React JSX emit e.g. 'React.Fragment' or 'Fragment'. */
    // "jsxImportSource": "",                            /* Specify module specifier used to import the JSX factory functions when using 'jsx: react-jsx*'. */
    // "reactNamespace": "",                             /* Specify the object invoked for 'createElement'. This only applies when targeting 'react' JSX emit. */
    // "noLib": true,                                    /* Disable including any library files, including the default lib.d.ts. */
    // "useDefineForClassFields": true,                  /* Emit ECMAScript-standard-compliant class fields. */
    // "moduleDetection": "auto",                        /* Control what method is used to detect module-format JS files. */

    /* Modules */
    "module": "NodeNext",
    "rootDir": "./src",
    "moduleResolution": "NodeNext",
    "baseUrl": ".",
    "paths": {
      "@/*": ["src/*"]
    },
    // "rootDirs": [],                                   /* Allow multiple folders to be treated as one when resolving modules. */
    // "typeRoots": [],                                  /* Specify multiple folders that act like './node_modules/@types'. */
    "types": ["node", "jest"],
    // "allowUmdGlobalAccess": true,                     /* Allow accessing UMD globals from modules. */
    // "moduleSuffixes": [],                             /* List of file name suffixes to search when resolving a module. */
    // "allowImportingTsExtensions": true,               /* Allow imports to include TypeScript file extensions. Requires '--moduleResolution bundler' and either '--noEmit' or '--emitDeclarationOnly' to be set. */
    // "resolvePackageJsonExports": true,                /* Use the package.json 'exports' field when resolving package imports. */
    // "resolvePackageJsonImports": true,                /* Use the package.json 'imports' field when resolving imports. */
    // "customConditions": [],                           /* Conditions to set in addition to the resolver-specific defaults when resolving imports. */
    "resolveJsonModule": true,
    // "allowArbitraryExtensions": true,                 /* Enable importing files with any extension, provided a declaration file is present. */
    // "noResolve": true,                                /* Disallow 'import's, 'require's or '<reference>'s from expanding the number of files TypeScript should add to a project. */

    /* JavaScript Support */
    "allowJs": true,
    // "checkJs": true,                                  /* Enable error reporting in type-checked JavaScript files. */
    // "maxNodeModuleJsDepth": 1,                        /* Specify the maximum folder depth used for checking JavaScript files from 'node_modules'. Only applicable with 'allowJs'. */

    /* Emit */
    // "declaration": true,                              /* Generate .d.ts files from TypeScript and JavaScript files in your project. */
    // "declarationMap": true,                           /* Create sourcemaps for d.ts files. */
    // "emitDeclarationOnly": true,                      /* Only output d.ts files and not JavaScript files. */
    // "sourceMap": true,                                /* Create source map files for emitted JavaScript files. */
    // "inlineSourceMap": true,                          /* Include sourcemap files inside the emitted JavaScript. */
    // "outFile": "./",                                  /* Specify a file that bundles all outputs into one JavaScript file. If 'declaration' is true, also designates a file that bundles all .d.ts output. */
    "outDir": "./dist",
    // "removeComments": true,                           /* Disable emitting comments. */
    // "noEmit": true,                                   /* Disable emitting files from a compilation. */
    // "importHelpers": true,                            /* Allow importing helper functions from tslib once per project, instead of including them per-file. */
    // "importsNotUsedAsValues": "remove",               /* Specify emit/checking behavior for imports that are only used for types. */
    // "downlevelIteration": true,                       /* Emit more compliant, but verbose and less performant JavaScript for iteration. */
    // "sourceRoot": "",                                 /* Specify the root path for debuggers to find the reference source code. */
    // "mapRoot": "",                                    /* Specify the location where debugger should locate map files instead of generated locations. */
    // "inlineSources": true,                            /* Include source code in the sourcemaps inside the emitted JavaScript. */
    // "emitBOM": true,                                  /* Emit a UTF-8 Byte Order Mark (BOM) in the beginning of output files. */
    // "newLine": "crlf",                                /* Set the newline character for emitting files. */
    // "stripInternal": true,                            /* Disable emitting declarations that have '@internal' in their JSDoc comments. */
    // "noEmitHelpers": true,                            /* Disable generating custom helper functions like '__extends' in compiled output. */
    // "noEmitOnError": true,                            /* Disable emitting files if any type checking errors are reported. */
    // "preserveConstEnums": true,                       /* Disable erasing 'const enum' declarations in generated code. */
    // "declarationDir": "./",                           /* Specify the output directory for generated declaration files. */
    // "preserveValueImports": true,                     /* Preserve unused imported values in the JavaScript output that would otherwise be removed. */

    /* Interop Constraints */
    "isolatedModules": true,
    // "verbatimModuleSyntax": true,                     /* Do not transform or elide any imports or exports not marked as type-only, ensuring they are written in the output file's format based on the 'module' setting. */
    // "allowSyntheticDefaultImports": true,             /* Allow 'import x from y' when a module doesn't have a default export. */
    "esModuleInterop": true,
    // "preserveSymlinks": true,                         /* Disable resolving symlinks to their realpath. This correlates to the same flag in node. */
    "forceConsistentCasingInFileNames": true,

    /* Type Checking */
    "strict": true,
    // "noImplicitAny": true,                            /* Enable error reporting for expressions and declarations with an implied 'any' type. */
    // "strictNullChecks": true,                         /* When type checking, take into account 'null' and 'undefined'. */
    // "strictFunctionTypes": true,                      /* When assigning functions, check to ensure parameters and the return values are subtype-compatible. */
    // "strictBindCallApply": true,                      /* Check that the arguments for 'bind', 'call', and 'apply' methods match the original function. */
    // "strictPropertyInitialization": true,             /* Check for class properties that are declared but not set in the constructor. */
    // "noImplicitThis": true,                           /* Enable error reporting when 'this' is given the type 'any'. */
    // "useUnknownInCatchVariables": true,               /* Default catch clause variables as 'unknown' instead of 'any'. */
    // "alwaysStrict": true,                             /* Ensure 'use strict' is always emitted. */
    // "noUnusedLocals": true,                           /* Enable error reporting when local variables aren't read. */
    // "noUnusedParameters": true,                       /* Raise an error when a function parameter isn't read. */
    // "exactOptionalPropertyTypes": true,               /* Interpret optional property types as written, rather than adding 'undefined'. */
    // "noImplicitReturns": true,                        /* Enable error reporting for codepaths that do not explicitly return in a function. */
    // "noFallthroughCasesInSwitch": true,               /* Enable error reporting for fallthrough cases in switch statements. */
    // "noUncheckedIndexedAccess": true,                 /* Add 'undefined' to a type when accessed using an index. */
    // "noImplicitOverride": true,                       /* Ensure overriding members in derived classes are marked with an override modifier. */
    // "noPropertyAccessFromIndexSignature": true,       /* Enforces using indexed accessors for keys declared using an indexed type. */
    // "allowUnusedLabels": true,                        /* Disable error reporting for unused labels. */
    // "allowUnreachableCode": true,                     /* Disable error reporting for unreachable code. */

    /* Completeness */
    // "skipDefaultLibCheck": true,                      /* Skip type checking .d.ts files that are included with TypeScript. */
    "skipLibCheck": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
</file>

<file path="package.json">
{
  "name": "developer-tools",
  "version": "1.0.0",
  "description": "A comprehensive suite of development tools including MCP server implementation",
  "type": "module",
  "main": "dist/server.js",
  "exports": {
    ".": {
      "import": "./dist/server.js",
      "types": "./dist/server.d.ts"
    }
  },
  "scripts": {
    "build": "tsc",
    "start": "node dist/server.js",
    "dev": "ts-node --esm src/server.ts",
    "test:client": "node dist/test-client.js",
    "test": "node --experimental-vm-modules node_modules/jest/bin/jest.js",
    "test:watch": "node --experimental-vm-modules node_modules/jest/bin/jest.js --watch",
    "test:coverage": "node --experimental-vm-modules node_modules/jest/bin/jest.js --coverage",
    "test:rate-limiter": "node --experimental-vm-modules node_modules/jest/bin/jest.js src/utils/__tests__/rate-limiter.test.ts",
    "test:github-pr": "node --experimental-vm-modules node_modules/jest/bin/jest.js src/resources/__tests__/github-pr.resource.test.ts",
    "lint": "eslint . --ext .ts",
    "lint:fix": "eslint . --ext .ts --fix",
    "format": "prettier --write \"src/**/*.ts\"",
    "prepare": "husky install"
  },
  "keywords": [
    "mcp",
    "development-tools",
    "typescript",
    "ai-tools"
  ],
  "author": "freshtechbro",
  "license": "MIT",
  "dependencies": {
    "@modelcontextprotocol/sdk": "1.2.0",
    "@octokit/rest": "19.0.13",
    "axios": "1.6.5",
    "body-parser": "^1.20.3",
    "cors": "^2.8.5",
    "dotenv": "16.3.1",
    "express": "^4.21.2",
    "playwright": "1.41.2",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/cors": "^2.8.17",
    "@types/express": "^5.0.0",
    "@types/jest": "^29.5.11",
    "@types/node": "20.11.5",
    "@typescript-eslint/eslint-plugin": "^6.19.1",
    "@typescript-eslint/parser": "^6.19.1",
    "cursor-tools": "latest",
    "eslint": "^8.56.0",
    "eslint-config-prettier": "^9.1.0",
    "eslint-plugin-prettier": "^5.1.3",
    "husky": "^8.0.3",
    "jest": "^29.7.0",
    "lint-staged": "^15.2.0",
    "prettier": "^3.2.4",
    "ts-jest": "^29.1.2",
    "ts-node": "10.9.2",
    "typescript": "5.3.3"
  },
  "lint-staged": {
    "*.ts": [
      "eslint --fix",
      "prettier --write"
    ]
  }
}
</file>

<file path="public/index.html">
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MCP Server Test Interface</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        .container {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
        }
        .panel {
            flex: 1;
            min-width: 300px;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            background-color: #f9f9f9;
        }
        .form-group {
            margin-bottom: 15px;
        }
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
        }
        input, select, textarea {
            width: 100%;
            padding: 8px;
            border: 1px solid #ddd;
            border-radius: 4px;
            box-sizing: border-box;
        }
        textarea {
            min-height: 100px;
            font-family: monospace;
        }
        button {
            background-color: #3498db;
            color: white;
            border: none;
            padding: 10px 15px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
        }
        button:hover {
            background-color: #2980b9;
        }
        .result {
            background-color: #f5f5f5;
            border: 1px solid #ddd;
            border-radius: 4px;
            padding: 10px;
            margin-top: 15px;
            overflow: auto;
            max-height: 300px;
            font-family: monospace;
            white-space: pre-wrap;
        }
        .tabs {
            display: flex;
            border-bottom: 1px solid #ddd;
            margin-bottom: 15px;
        }
        .tab {
            padding: 10px 15px;
            cursor: pointer;
            border: 1px solid transparent;
            border-bottom: none;
            margin-bottom: -1px;
        }
        .tab.active {
            background-color: #f9f9f9;
            border-color: #ddd;
            border-radius: 5px 5px 0 0;
        }
        .tab-content {
            display: none;
        }
        .tab-content.active {
            display: block;
        }
        .status {
            padding: 5px 10px;
            border-radius: 4px;
            display: inline-block;
            margin-left: 10px;
            font-size: 12px;
        }
        .status.connected {
            background-color: #2ecc71;
            color: white;
        }
        .status.disconnected {
            background-color: #e74c3c;
            color: white;
        }
        .log-entry {
            margin-bottom: 5px;
            padding: 5px;
            border-bottom: 1px solid #eee;
        }
        .log-entry.error {
            color: #e74c3c;
        }
        .log-entry.info {
            color: #3498db;
        }
    </style>
</head>
<body>
    <h1>MCP Server Test Interface</h1>
    <div class="container">
        <div class="panel">
            <h2>Connection Settings</h2>
            <div class="form-group">
                <label for="transport-type">Transport Type</label>
                <select id="transport-type">
                    <option value="http">HTTP</option>
                    <option value="sse">SSE</option>
                </select>
            </div>
            <div class="form-group">
                <label for="server-url">Server URL</label>
                <input type="text" id="server-url" value="http://localhost:3001">
            </div>
            <div class="form-group">
                <label for="endpoint-path">Endpoint Path</label>
                <input type="text" id="endpoint-path" value="/mcp">
            </div>
            <button id="connect-btn">Connect</button>
            <span id="connection-status" class="status disconnected">Disconnected</span>
        </div>
        <div class="panel">
            <h2>Tool Execution</h2>
            <div class="tabs">
                <div class="tab active" data-tab="web-search">Web Search</div>
                <div class="tab" data-tab="repo-analysis">Repo Analysis</div>
                <div class="tab" data-tab="browser-automation">Browser Automation</div>
                <div class="tab" data-tab="custom">Custom Request</div>
            </div>
            <div class="tab-content active" id="web-search-tab">
                <div class="form-group">
                    <label for="search-query">Search Query</label>
                    <input type="text" id="search-query" value="latest news about AI">
                </div>
                <button id="search-btn">Execute Search</button>
            </div>
            <div class="tab-content" id="repo-analysis-tab">
                <div class="form-group">
                    <label for="repo-query">Repository Query</label>
                    <input type="text" id="repo-query" value="Explain the main functionality">
                </div>
                <button id="repo-btn">Analyze Repository</button>
            </div>
            <div class="tab-content" id="browser-automation-tab">
                <div class="form-group">
                    <label for="browser-url">URL to Open</label>
                    <input type="text" id="browser-url" value="https://example.com">
                </div>
                <div class="form-group">
                    <label for="browser-action">Action</label>
                    <input type="text" id="browser-action" value="Click on the first link">
                </div>
                <button id="browser-btn">Execute Browser Action</button>
            </div>
            <div class="tab-content" id="custom-tab">
                <div class="form-group">
                    <label for="custom-request">Custom JSON-RPC Request</label>
                    <textarea id="custom-request">{
  "method": "tool/execute",
  "params": {
    "toolName": "web-search",
    "version": "0.1.0",
    "arguments": {
      "query": "custom query"
    }
  }
}</textarea>
                </div>
                <button id="custom-btn">Send Custom Request</button>
            </div>
            <h3>Result</h3>
            <div id="result" class="result">No result yet</div>
        </div>
    </div>
    <div class="panel">
        <h2>Event Log</h2>
        <div id="event-log" class="result"></div>
    </div>
    <!-- Include the MCP client -->
    <script src="mcp-client.js"></script>
    <script>
        // Tab switching
        document.querySelectorAll('.tab').forEach(tab => {
            tab.addEventListener('click', () => {
                // Remove active class from all tabs
                document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
                document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));
                // Add active class to clicked tab
                tab.classList.add('active');
                document.getElementById(`${tab.dataset.tab}-tab`).classList.add('active');
            });
        });
        // Logging function
        function log(message, type = 'info') {
            const logEntry = document.createElement('div');
            logEntry.classList.add('log-entry', type);
            logEntry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
            const eventLog = document.getElementById('event-log');
            eventLog.insertBefore(logEntry, eventLog.firstChild);
        }
        // Initialize MCP client
        let mcpClient = null;
        // Connection handling
        document.getElementById('connect-btn').addEventListener('click', async () => {
            const transportType = document.getElementById('transport-type').value;
            const serverUrl = document.getElementById('server-url').value;
            const endpointPath = document.getElementById('endpoint-path').value;
            if (mcpClient && mcpClient.connected) {
                // Disconnect if already connected
                mcpClient.disconnect();
                mcpClient = null;
                document.getElementById('connection-status').textContent = 'Disconnected';
                document.getElementById('connection-status').classList.remove('connected');
                document.getElementById('connection-status').classList.add('disconnected');
                document.getElementById('connect-btn').textContent = 'Connect';
                log('Disconnected from server');
                return;
            }
            // Create a new MCP client
            mcpClient = new MCPClient({
                transportType,
                serverUrl,
                endpointPath,
                onMessage: (data) => {
                    log(`Received message: ${JSON.stringify(data)}`);
                    document.getElementById('result').textContent = JSON.stringify(data, null, 2);
                },
                onError: (error) => {
                    log(`Error: ${error.message}`, 'error');
                },
                onStatusChange: (status) => {
                    if (status.connected) {
                        document.getElementById('connection-status').textContent = `Connected (${status.transportType.toUpperCase()})`;
                        document.getElementById('connection-status').classList.remove('disconnected');
                        document.getElementById('connection-status').classList.add('connected');
                        document.getElementById('connect-btn').textContent = 'Disconnect';
                        log(`Connected to server using ${status.transportType.toUpperCase()} transport`);
                    } else {
                        document.getElementById('connection-status').textContent = 'Disconnected';
                        document.getElementById('connection-status').classList.remove('connected');
                        document.getElementById('connection-status').classList.add('disconnected');
                        document.getElementById('connect-btn').textContent = 'Connect';
                        log('Disconnected from server');
                    }
                }
            });
            try {
                // Connect to the server
                const connected = await mcpClient.connect();
                if (!connected) {
                    log('Failed to connect to server', 'error');
                }
            } catch (error) {
                log(`Connection error: ${error.message}`, 'error');
            }
        });
        // Web Search button
        document.getElementById('search-btn').addEventListener('click', async () => {
            if (!mcpClient || !mcpClient.connected) {
                log('Not connected to server. Please connect first.', 'error');
                return;
            }
            const query = document.getElementById('search-query').value;
            log(`Executing web search: "${query}"`);
            try {
                const result = await mcpClient.webSearch(query);
                log(`Search request sent with ID: ${result.id}`);
            } catch (error) {
                log(`Error executing search: ${error.message}`, 'error');
            }
        });
        // Repo Analysis button
        document.getElementById('repo-btn').addEventListener('click', async () => {
            if (!mcpClient || !mcpClient.connected) {
                log('Not connected to server. Please connect first.', 'error');
                return;
            }
            const query = document.getElementById('repo-query').value;
            log(`Executing repo analysis: "${query}"`);
            try {
                const result = await mcpClient.repoAnalysis(query);
                log(`Analysis request sent with ID: ${result.id}`);
            } catch (error) {
                log(`Error executing analysis: ${error.message}`, 'error');
            }
        });
        // Browser Automation button
        document.getElementById('browser-btn').addEventListener('click', async () => {
            if (!mcpClient || !mcpClient.connected) {
                log('Not connected to server. Please connect first.', 'error');
                return;
            }
            const url = document.getElementById('browser-url').value;
            const action = document.getElementById('browser-action').value;
            log(`Executing browser automation: "${action}" on ${url}`);
            try {
                const result = await mcpClient.browserAutomation(url, action);
                log(`Browser automation request sent with ID: ${result.id}`);
            } catch (error) {
                log(`Error executing browser automation: ${error.message}`, 'error');
            }
        });
        // Custom Request button
        document.getElementById('custom-btn').addEventListener('click', async () => {
            if (!mcpClient || !mcpClient.connected) {
                log('Not connected to server. Please connect first.', 'error');
                return;
            }
            try {
                const customRequest = JSON.parse(document.getElementById('custom-request').value);
                log(`Sending custom request: ${JSON.stringify(customRequest)}`);
                const result = await mcpClient.sendRequest(customRequest);
                log(`Custom request sent with ID: ${result.id}`);
            } catch (error) {
                log(`Error sending custom request: ${error.message}`, 'error');
            }
        });
        // Initial log message
        log('MCP Server Test Interface loaded');
    </script>
</body>
</html>
</file>

<file path="public/mcp-client.js">
/**
 * MCP Client - A simple client for the Model Context Protocol
 */
class MCPClient {
    /**
     * Create a new MCP client
     * @param {Object} options - Configuration options
     * @param {string} options.transportType - 'http' or 'sse'
     * @param {string} options.serverUrl - Base URL of the MCP server
     * @param {string} options.endpointPath - Path to the MCP endpoint
     * @param {Function} options.onMessage - Callback for received messages
     * @param {Function} options.onError - Callback for errors
     * @param {Function} options.onStatusChange - Callback for connection status changes
     */
    constructor(options) {
        this.transportType = options.transportType || 'http';
        this.serverUrl = options.serverUrl || 'http://localhost:3001';
        this.endpointPath = options.endpointPath || '/mcp';
        this.onMessage = options.onMessage || (() => {});
        this.onError = options.onError || (() => {});
        this.onStatusChange = options.onStatusChange || (() => {});
        this.connected = false;
        this.sseSource = null;
        this.requestId = 1;
    }
    /**
     * Connect to the MCP server
     * @returns {Promise<boolean>} - True if connection successful
     */
    async connect() {
        if (this.connected) {
            return true;
        }
        try {
            if (this.transportType === 'sse') {
                // For SSE, establish EventSource connection
                const clientId = Date.now();
                const sseUrl = `${this.serverUrl}${this.endpointPath}?clientId=${clientId}`;
                return new Promise((resolve, reject) => {
                    try {
                        this.sseSource = new EventSource(sseUrl);
                        this.sseSource.onopen = () => {
                            this.connected = true;
                            this.onStatusChange({ connected: true, transportType: 'sse' });
                            resolve(true);
                        };
                        this.sseSource.onmessage = (event) => {
                            try {
                                const data = JSON.parse(event.data);
                                this.onMessage(data);
                            } catch (error) {
                                this.onError(new Error(`Error parsing SSE message: ${error.message}`));
                            }
                        };
                        this.sseSource.onerror = (error) => {
                            const errorMsg = error.message || 'Unknown SSE connection error';
                            this.onError(new Error(errorMsg));
                            if (this.connected) {
                                this.disconnect();
                            }
                            reject(new Error(errorMsg));
                        };
                        // Set a connection timeout
                        setTimeout(() => {
                            if (!this.connected) {
                                this.sseSource.close();
                                this.sseSource = null;
                                reject(new Error('Connection timeout'));
                            }
                        }, 10000);
                    } catch (error) {
                        reject(new Error(`Failed to create SSE connection: ${error.message}`));
                    }
                });
            } else {
                // For HTTP, just mark as connected since there's no persistent connection
                this.connected = true;
                this.onStatusChange({ connected: true, transportType: 'http' });
                return true;
            }
        } catch (error) {
            this.onError(error);
            return false;
        }
    }
    /**
     * Disconnect from the MCP server
     */
    disconnect() {
        if (this.sseSource) {
            this.sseSource.close();
            this.sseSource = null;
        }
        this.connected = false;
        this.onStatusChange({ connected: false });
    }
    /**
     * Send a request to the MCP server
     * @param {Object} request - The request object to send
     * @returns {Promise<Object>} - The response from the server
     */
    async sendRequest(request) {
        if (!this.connected) {
            throw new Error('Not connected to MCP server');
        }
        // Add id if not present
        if (!request.id) {
            request.id = this.requestId++;
        }
        try {
            if (this.transportType === 'sse') {
                // For SSE, send via POST to the message endpoint
                const response = await fetch(`${this.serverUrl}${this.endpointPath}/message`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(request)
                });
                if (!response.ok) {
                    throw new Error(`HTTP error ${response.status}: ${response.statusText}`);
                }
                // For SSE, the actual result will come through the SSE connection
                // But we still return the immediate response
                return await response.json();
            } else {
                // For HTTP, send directly to the endpoint
                const response = await fetch(`${this.serverUrl}${this.endpointPath}`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(request)
                });
                if (!response.ok) {
                    throw new Error(`HTTP error ${response.status}: ${response.statusText}`);
                }
                return await response.json();
            }
        } catch (error) {
            this.onError(error);
            throw error;
        }
    }
    /**
     * Execute a tool
     * @param {string} toolName - Name of the tool to execute
     * @param {string} version - Version of the tool
     * @param {Object} args - Arguments for the tool
     * @returns {Promise<Object>} - The response from the server
     */
    async executeTool(toolName, version, args) {
        const request = {
            method: 'tool/execute',
            params: {
                toolName,
                version: version || '0.1.0',
                arguments: args
            }
        };
        return this.sendRequest(request);
    }
    /**
     * Execute a web search
     * @param {string} query - The search query
     * @returns {Promise<Object>} - The search results
     */
    async webSearch(query) {
        return this.executeTool('web-search', '0.1.0', { query });
    }
    /**
     * Execute a repository analysis
     * @param {string} query - The analysis query
     * @returns {Promise<Object>} - The analysis results
     */
    async repoAnalysis(query) {
        return this.executeTool('repo-analysis', '0.1.0', { query });
    }
    /**
     * Execute a browser automation action
     * @param {string} url - The URL to open
     * @param {string} action - The action to perform
     * @returns {Promise<Object>} - The automation results
     */
    async browserAutomation(url, action) {
        return this.executeTool('browser-automation', '0.1.0', { url, action });
    }
}
// Export the client
if (typeof module !== 'undefined' && module.exports) {
    module.exports = MCPClient;
} else {
    window.MCPClient = MCPClient;
}
</file>

<file path="public/README.md">
# MCP Server Web Interface

This is a simple web interface for testing the Model Context Protocol (MCP) server. It allows you to connect to the server using either HTTP or SSE transport and execute various tools.

## Features

- Connect to the MCP server using HTTP or SSE transport
- Execute web search queries
- Execute repository analysis queries
- Execute browser automation actions
- Send custom JSON-RPC requests
- View real-time responses and logs

## Usage

1. Start the MCP server with HTTP or SSE transport enabled
2. Open the web interface in your browser (default: http://localhost:3003)
3. Configure the connection settings:
   - Transport Type: HTTP or SSE
   - Server URL: The base URL of the MCP server (default: http://localhost:3001)
   - Endpoint Path: The path to the MCP endpoint (default: /mcp for HTTP, /mcp-sse for SSE)
4. Click "Connect" to establish a connection to the server
5. Use the tabs to execute different tools:
   - Web Search: Execute web search queries
   - Repo Analysis: Execute repository analysis queries
   - Browser Automation: Execute browser automation actions
   - Custom Request: Send custom JSON-RPC requests
6. View the results and event log for detailed information

## Configuration

The web interface is served by the MCP server when the `WEB_INTERFACE_ENABLED` environment variable is set to `true`. You can configure the port using the `WEB_INTERFACE_PORT` environment variable (default: 3003).

## Files

- `index.html`: The main HTML file for the web interface
- `mcp-client.js`: A JavaScript client for the MCP server

## Development

To modify the web interface, edit the files in the `public` directory. The changes will be reflected when you refresh the page.

## Security Considerations

This web interface is intended for testing and development purposes only. It does not include authentication or authorization mechanisms. Do not expose it to the public internet without proper security measures in place.
</file>

<file path="README.md">
# Developer Tools

A comprehensive suite of development tools including an MCP (Model Context Protocol) server implementation and various utilities for enhancing developer productivity.

## üöÄ Features

- **MCP Server Implementation**: A TypeScript-based server implementing the Model Context Protocol
- **Web Search Integration**: Powered by Perplexity AI
- **Repository Analysis**: Using Google's Gemini AI
- **Browser Automation**: For web interaction and testing
- **GitHub Integration**: Access to GitHub pull requests and issues
- **Rate Limiting**: Built-in token bucket rate limiting for all external API calls
- **REST API**: Optional HTTP API for accessing MCP resources
- **Search History**: Store and retrieve past searches
- **Comprehensive Documentation**: Including research and implementation guides

## üìã Prerequisites

- Node.js (v16 or higher)
- npm or yarn
- TypeScript knowledge for development
- Playwright for browser automation capabilities

## üõ†Ô∏è Installation

1. Clone the repository:
```bash
git clone https://github.com/freshtechbro/developer-tools.git
cd developer-tools
```

2. Install dependencies:
```bash
npm install
```

3. Install Playwright (optional, for browser automation):
```bash
npm install playwright
```

4. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your actual API keys and configuration
```

## üîß Configuration

The following environment variables are required:

- `PERPLEXITY_API_KEY`: Your Perplexity AI API key
- `GOOGLE_API_KEY`: Your Google API key for Gemini
- `GITHUB_TOKEN`: Your GitHub personal access token (for GitHub PR resource)
- `NODE_ENV`: Development environment (development/production/test)
- `LOG_LEVEL`: Logging level (debug/info/warn/error)
- `PORT`: Server port (default: 3000)
- `HOST`: Server host (default: localhost)
- `REST_API_ENABLED`: Enable REST API server (true/false)
- `REST_API_PORT`: REST API server port (default: 3000)
- `PERPLEXITY_RATE_LIMIT_TOKENS`: Maximum tokens for Perplexity API (default: 100)
- `PERPLEXITY_RATE_LIMIT_REFILL`: Tokens refill rate per second (default: 0.5)
- `GEMINI_RATE_LIMIT_TOKENS`: Maximum tokens for Gemini API (default: 60)
- `GEMINI_RATE_LIMIT_REFILL`: Tokens refill rate per second (default: 0.2)

## üöÄ Usage

1. Start the MCP server:
```bash
npm run start
```

2. For development with hot-reload:
```bash
npm run dev
```

3. Build the project:
```bash
npm run build
```

## üß© Services

The project is organized into modular services:

### PerplexityService
Handles web search operations using the Perplexity AI API. It provides:
- Web search functionality with customizable parameters
- Detailed logging for search operations
- Error handling for API failures
- Rate limiting to prevent API quota exhaustion

### GeminiService
Manages interactions with the Google Gemini API for:
- Code and repository analysis
- Content generation
- AI-powered insights
- Rate limiting to prevent API quota exhaustion

### FileStorageService
Provides file system operations with:
- File reading/writing with configurable options
- Directory creation
- Append operations
- File existence checking
- File deletion

### BrowserService
Provides browser automation capabilities using Playwright:
- Web page navigation and content collection
- Form filling and submission
- Data extraction from web pages
- Screenshot capture
- Console and network request monitoring

## üîß Tools

The MCP server provides the following tools:

### Web Search
```typescript
// Example usage
const result = await webSearchTool.execute({
  query: "TypeScript best practices",
  saveToFile: "search-results.md" // Optional
});
```

### Repository Analysis
```typescript
// Example usage
const result = await repoAnalysisTool.execute({
  query: "Analyze code quality",
  targetPath: "./src",
  maxDepth: 3,
  saveToFile: "analysis-results.md" // Optional
});
```

### Browser Automation
```typescript
// Example usage - Navigate to a URL
const result = await browserAutomationTool.execute({
  action: "navigate",
  url: "https://example.com",
  options: {
    captureScreenshot: true,
    captureHtml: true,
    captureConsole: true
  }
});

// Example usage - Fill a form
const result = await browserAutomationTool.execute({
  action: "form",
  url: "https://example.com/login",
  formData: {
    username: "user",
    password: "pass"
  }
});

// Example usage - Extract data
const result = await browserAutomationTool.execute({
  action: "extract",
  url: "https://example.com/products",
  selectors: {
    titles: ".product-title",
    prices: ".product-price"
  }
});
```

### GitHub Pull Requests
```typescript
// Example usage - List PRs
const result = await githubPRTool.execute({
  owner: "owner",
  repo: "repo",
  count: 10
});

// Example usage - Get specific PR
const result = await githubPRTool.execute({
  owner: "owner",
  repo: "repo",
  prNumber: 123
});
```

## üåê REST API

When enabled, the REST API provides HTTP endpoints for accessing MCP resources:

### Search History Endpoints

- `GET /api/search-history`: Get all search history entries with pagination
- `GET /api/search-history/search?term=query`: Search through history
- `GET /api/search-history/:id`: Get a specific search by ID
- `POST /api/search-history`: Add a new search entry
- `DELETE /api/search-history/:id`: Delete a specific search
- `DELETE /api/search-history`: Clear all search history

### GitHub PR Endpoints

- `GET /api/github/pr?owner=<owner>&repo=<repo>&count=<count>`: Get recent pull requests
- `GET /api/github/pr?owner=<owner>&repo=<repo>&prNumber=<number>`: Get a specific pull request

Enable the REST API by setting `REST_API_ENABLED=true` in your `.env` file.

## üìö Documentation

Detailed documentation is available in the `local-research` directory:

- `mcp-setup-guide.md`: Complete setup instructions
- `dependencies-installation-guide.md`: Dependency management guide
- `typescript-esm-config.md`: TypeScript and ESM configuration details
- Additional implementation and research documents

## üîÑ Rate Limiting

The application implements a token bucket rate limiter to prevent API quota exhaustion:

- Each service (Perplexity, Gemini, GitHub) has its own rate limiter
- Configurable maximum tokens, refill rate, and wait behavior
- Default settings in the `.env.example` file
- Automatic token refill based on elapsed time
- Optional wait for tokens to become available or immediate rejection

## üß™ Testing

Run the test suite:
```bash
npm test
```

## ü§ù Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üîê Security

- Environment variables and sensitive data are never committed to the repository
- API keys should be kept secure and not shared
- Rate limiting prevents API abuse and quota exhaustion
- See `.env.example` for required environment variables
- Branch protection rules are in place for the main branch

## üôè Acknowledgments

- Model Context Protocol team for the SDK
- Perplexity AI for search capabilities
- Google Gemini for AI features
- GitHub for repository API access
- Playwright team for browser automation capabilities
</file>

<file path="src/capabilities/tools/__tests__/web-search.test.ts">
import { jest, beforeEach, describe, it, expect } from '@jest/globals';
import { webSearchTool } from '../web-search.js';
import { config } from '../../../config/index.js';
import axios from 'axios';
// Mock axios
jest.mock('axios', () => ({
    post: jest.fn(),
    isAxiosError: jest.fn()
}));
// Mock config
jest.mock('../../../config/index', () => ({
    config: {
        env: 'test',
        perplexityApiKey: undefined,
        logLevel: 'info'
    }
}));
// Mock logger
jest.mock('../../../utils/logger', () => ({
    logger: {
        info: jest.fn(),
        warn: jest.fn(),
        error: jest.fn(),
        debug: jest.fn()
    }
}));
describe('Web Search Tool', () => {
    beforeEach(() => {
        jest.clearAllMocks();
    });
    describe('when PERPLEXITY_API_KEY is not provided', () => {
        it('should return mock results in test environment', async () => {
            const request = { query: 'test query' };
            const result = await webSearchTool.execute(request);
            expect(result).toEqual({ searchResults: 'Mock search results for testing' });
            expect(axios.post).not.toHaveBeenCalled();
        });
    });
    describe('when PERPLEXITY_API_KEY is provided', () => {
        beforeEach(() => {
            (config as any).perplexityApiKey = 'test-api-key';
        });
        it('should make API call and return results', async () => {
            const mockResponse = {
                data: {
                    choices: [{ message: { content: 'API search results' } }]
                }
            };
            (axios.post as jest.Mock).mockResolvedValueOnce(mockResponse);
            const request = { query: 'test query' };
            const result = await webSearchTool.execute(request);
            expect(result).toEqual({ searchResults: 'API search results' });
            expect(axios.post).toHaveBeenCalledWith(
                expect.any(String),
                expect.objectContaining({
                    messages: [{ role: 'user', content: 'test query' }]
                }),
                expect.objectContaining({
                    headers: { 'Authorization': 'Bearer test-api-key' }
                })
            );
        });
        it('should handle API errors gracefully', async () => {
            const mockError = { response: { data: { error: 'API Error' } } };
            (axios.post as jest.Mock).mockRejectedValueOnce(mockError);
            (axios.isAxiosError as jest.Mock).mockReturnValue(true);
            const request = { query: 'test query' };
            await expect(webSearchTool.execute(request)).rejects.toThrow('Web search failed: API Error');
        });
        it('should validate request schema', async () => {
            const invalidRequest = { query: '' };
            await expect(webSearchTool.execute(invalidRequest)).rejects.toThrow('Search query is required');
        });
        it('should handle saving results to file when requested', async () => {
            const mockResponse = {
                data: {
                    choices: [{ message: { content: 'API search results' } }]
                }
            };
            (axios.post as jest.Mock).mockResolvedValueOnce(mockResponse);
            const request = { query: 'test query', saveToFile: true };
            const result = await webSearchTool.execute(request);
            expect(result).toMatchObject({
                searchResults: 'API search results',
                savedToFile: expect.stringContaining('web-search-')
            });
        });
    });
});
</file>

<file path="src/capabilities/tools/browser-automation.ts">
import { z } from 'zod';
import { logger } from '../../utils/logger.js';
import type { Tool } from '../../types/tool.js';
import { browserService } from '../../services/browser.service.js';
import { fileStorageService } from '../../services/file-storage.service.js';
// Define common schemas
const BrowserOptionsSchema = z.object({
  headless: z.boolean().optional().default(true),
  viewport: z.object({
    width: z.number(),
    height: z.number()
  }).optional(),
  userAgent: z.string().optional()
});
// Schema for page navigation
const BrowserNavigateSchema = z.object({
  url: z.string().url('Invalid URL format'),
  action: z.literal('navigate'),
  options: z.object({
    captureScreenshot: z.boolean().optional().default(false),
    captureHtml: z.boolean().optional().default(false),
    captureConsole: z.boolean().optional().default(false),
    captureNetwork: z.boolean().optional().default(false),
    waitForSelector: z.string().optional(),
    waitForTimeout: z.number().optional(),
    executeScript: z.string().optional(),
    saveScreenshotTo: z.string().optional()
  }).optional().default({}),
  browserOptions: BrowserOptionsSchema.optional().default({})
});
// Schema for form submission
const BrowserFormSchema = z.object({
  url: z.string().url('Invalid URL format'),
  action: z.literal('form'),
  formData: z.record(z.string()),
  options: z.object({
    submitSelector: z.string().optional(),
    waitForNavigation: z.boolean().optional().default(true),
    captureScreenshot: z.boolean().optional().default(false),
    saveScreenshotTo: z.string().optional()
  }).optional().default({}),
  browserOptions: BrowserOptionsSchema.optional().default({})
});
// Schema for data extraction
const BrowserExtractSchema = z.object({
  url: z.string().url('Invalid URL format'),
  action: z.literal('extract'),
  selectors: z.record(z.string()),
  browserOptions: BrowserOptionsSchema.optional().default({})
});
// Union schema for all browser actions
const BrowserRequestSchema = z.discriminatedUnion('action', [
  BrowserNavigateSchema,
  BrowserFormSchema,
  BrowserExtractSchema
]);
// Schema for browser response
const BrowserResponseSchema = z.object({
  success: z.boolean(),
  url: z.string(),
  title: z.string().optional(),
  content: z.string().optional(),
  screenshot: z.string().optional(),
  consoleMessages: z.array(z.string()).optional(),
  networkRequests: z.array(z.object({
    url: z.string(),
    method: z.string(),
    status: z.number().optional(),
    contentType: z.string().optional()
  })).optional(),
  extractedData: z.record(z.union([z.string(), z.array(z.string())])).optional(),
  error: z.string().optional()
});
export const browserAutomationTool: Tool = {
  name: 'browser-automation',
  version: '0.1.0',
  description: 'Automates browser actions like navigation, form filling, and data extraction using Playwright',
  execute: async (request: unknown): Promise<unknown> => {
    // Validate request against our schema
    const validatedRequest = BrowserRequestSchema.parse(request);
    try {
      logger.info('Executing browser automation tool', { 
        action: validatedRequest.action, 
        url: validatedRequest.url 
      });
      // Initialize browser with provided options
      await browserService.initBrowser(validatedRequest.browserOptions);
      // Handle different action types
      switch (validatedRequest.action) {
        case 'navigate': {
          const result = await browserService.navigateAndCollect(validatedRequest.url, {
            captureScreenshot: validatedRequest.options.captureScreenshot,
            screenshotPath: validatedRequest.options.saveScreenshotTo,
            captureHtml: validatedRequest.options.captureHtml,
            captureConsole: validatedRequest.options.captureConsole,
            captureNetwork: validatedRequest.options.captureNetwork,
            waitForSelector: validatedRequest.options.waitForSelector,
            waitForTimeout: validatedRequest.options.waitForTimeout,
            executeScript: validatedRequest.options.executeScript
          });
          return BrowserResponseSchema.parse({
            success: true,
            ...result
          });
        }
        case 'form': {
          const result = await browserService.fillForm(validatedRequest.url, validatedRequest.formData, {
            submitSelector: validatedRequest.options.submitSelector,
            waitForNavigation: validatedRequest.options.waitForNavigation,
            captureScreenshot: validatedRequest.options.captureScreenshot,
            screenshotPath: validatedRequest.options.saveScreenshotTo
          });
          return BrowserResponseSchema.parse({
            success: true,
            ...result
          });
        }
        case 'extract': {
          const extractedData = await browserService.extractData(validatedRequest.url, validatedRequest.selectors);
          return BrowserResponseSchema.parse({
            success: true,
            url: validatedRequest.url,
            extractedData
          });
        }
      }
    } catch (error) {
      logger.error('Browser automation failed', {
        error: error instanceof Error ? error.message : String(error),
        action: (request as any)?.action,
        url: (request as any)?.url
      });
      // Ensure we close the browser even on error
      await browserService.closeBrowser().catch(err => {
        logger.error('Failed to close browser after error', {
          error: err instanceof Error ? err.message : String(err)
        });
      });
      if (error instanceof z.ZodError) {
        return BrowserResponseSchema.parse({
          success: false,
          url: (request as any)?.url || 'unknown',
          error: `Validation error: ${error.errors[0]?.message || 'Invalid data format'}`
        });
      }
      return BrowserResponseSchema.parse({
        success: false,
        url: (request as any)?.url || 'unknown',
        error: error instanceof Error ? error.message : String(error)
      });
    } finally {
      // Always close the browser when done
      await browserService.closeBrowser().catch(err => {
        logger.error('Failed to close browser', {
          error: err instanceof Error ? err.message : String(err)
        });
      });
    }
  },
  requestSchema: BrowserRequestSchema,
  responseSchema: BrowserResponseSchema
};
</file>

<file path="src/capabilities/tools/repo-analysis.ts">
import { z } from 'zod';
import * as fs from 'fs/promises';
import * as path from 'path';
import type { Tool } from '../../types/tool.js';
import { logger } from '../../utils/logger.js';
import { geminiService } from '../../services/gemini.service.js';
import { fileStorageService } from '../../services/file-storage.service.js';
// Schema for repository analysis request
const repoAnalysisRequestSchema = z.object({
  query: z.string().describe('The analysis query or question about the repository'),
  analysisType: z.enum(['code', 'documentation', 'both']).default('both')
    .describe('Type of analysis to perform'),
  targetPath: z.string().optional()
    .describe('Specific path or file to analyze. If not provided, analyzes the entire repository'),
  maxDepth: z.number().optional().default(3)
    .describe('Maximum directory depth for analysis'),
  saveToFile: z.boolean().optional().default(false)
    .describe('Whether to save the analysis to a file'),
});
// Schema for repository analysis response
const repoAnalysisResponseSchema = z.object({
  analysis: z.string().describe('The analysis results from Gemini'),
  codeInsights: z.object({
    architecture: z.array(z.string()).optional(),
    dependencies: z.array(z.string()).optional(),
    patterns: z.array(z.string()).optional(),
  }).optional(),
  documentationInsights: z.object({
    coverage: z.number().optional(),
    quality: z.string().optional(),
    recommendations: z.array(z.string()).optional(),
  }).optional(),
  savedToFile: z.string().optional()
    .describe('Path to the saved analysis file if saveToFile was true'),
});
// Cache interface for storing analysis results
interface AnalysisCache {
  timestamp: number;
  result: z.infer<typeof repoAnalysisResponseSchema>;
}
const analysisCache = new Map<string, AnalysisCache>();
const CACHE_TTL = 1000 * 60 * 60; // 1 hour
export const repoAnalysisTool: Tool = {
  name: 'repo-analysis',
  version: '0.2.0',
  description: 'Analyzes repository code and documentation using Google Gemini',
  execute: async (request: unknown) => {
    const parsedRequest = repoAnalysisRequestSchema.parse(request);
    const cacheKey = JSON.stringify({
      query: parsedRequest.query,
      analysisType: parsedRequest.analysisType,
      targetPath: parsedRequest.targetPath,
    });
    // Check cache first
    const cachedResult = analysisCache.get(cacheKey);
    if (cachedResult && Date.now() - cachedResult.timestamp < CACHE_TTL) {
      logger.info('Returning cached analysis result', { cacheKey });
      return cachedResult.result;
    }
    try {
      // Get repository content based on targetPath and maxDepth
      const repoContent = await getRepositoryContent(
        parsedRequest.targetPath || '.',
        parsedRequest.maxDepth
      );
      // Prepare structured prompt
      const prompt = createStructuredPrompt(
        parsedRequest.query,
        repoContent,
        parsedRequest.analysisType
      );
      // Call Gemini API for analysis through our service
      logger.info('Sending repository analysis request to Gemini', { 
        contentLength: repoContent.join('\n').length
      });
      const geminiResponse = await geminiService.generateContent(prompt, {
        temperature: 0.2, // Lower temperature for more deterministic/analytical responses
      });
      // Parse the response to extract structured data
      const parsedAnalysis = parseGeminiResponse(geminiResponse.content);
      // Save to file if requested
      let savedFilePath: string | undefined;
      if (parsedRequest.saveToFile) {
        try {
          const filename = `repo-analysis-${Date.now()}.md`;
          const savePath = path.join('local-research', filename);
          // Format the analysis as markdown
          const markdownContent = formatAnalysisAsMarkdown(
            parsedRequest.query,
            parsedAnalysis,
            parsedRequest.targetPath || '.',
            parsedRequest.analysisType
          );
          savedFilePath = await fileStorageService.saveToFile(savePath, markdownContent, {
            createDirectory: true
          });
          logger.info('Analysis saved to file', { path: savedFilePath });
        } catch (error) {
          logger.error('Failed to save analysis to file', {
            error: error instanceof Error ? error.message : String(error)
          });
          // Continue execution even if file saving fails
        }
      }
      // Construct response
      const response = {
        ...parsedAnalysis,
        savedToFile: savedFilePath
      };
      // Cache the result
      analysisCache.set(cacheKey, {
        timestamp: Date.now(),
        result: response,
      });
      return response;
    } catch (error) {
      logger.error('Error in repo analysis:', {
        error: error instanceof Error ? error.message : String(error),
        stack: error instanceof Error ? error.stack : undefined
      });
      if (error instanceof z.ZodError) {
        throw new Error(`Validation error: ${error.errors[0]?.message || 'Invalid data format'}`);
      }
      throw error; // Let service errors propagate
    }
  },
  requestSchema: repoAnalysisRequestSchema,
  responseSchema: repoAnalysisResponseSchema,
};
/**
 * Gets repository content by recursively traversing directories
 */
async function getRepositoryContent(
  targetPath: string,
  maxDepth: number,
  currentDepth = 0
): Promise<string[]> {
  const contents: string[] = [];
  try {
    const stats = await fs.stat(targetPath);
    if (stats.isFile()) {
      // Only include certain file types that are likely to be relevant for code analysis
      const fileExt = path.extname(targetPath).toLowerCase();
      const relevantExtensions = [
        '.ts', '.js', '.tsx', '.jsx', '.json', '.md', '.html', '.css', 
        '.scss', '.sass', '.less', '.yaml', '.yml', '.toml', '.xml',
        '.py', '.java', '.c', '.cpp', '.h', '.hpp', '.go', '.rs', '.php'
      ];
      if (relevantExtensions.includes(fileExt) || fileExt === '') {
        const content = await fs.readFile(targetPath, 'utf-8');
        contents.push(`File: ${targetPath}\n${content}`);
      }
    } else if (stats.isDirectory() && currentDepth < maxDepth) {
      const files = await fs.readdir(targetPath);
      for (const file of files) {
        // Skip hidden files/directories and common directories to ignore
        if (file.startsWith('.') || 
            ['node_modules', 'dist', 'build', 'out', 'coverage', '.git'].includes(file)) {
          continue;
        }
        const fullPath = path.join(targetPath, file);
        const subContents = await getRepositoryContent(
          fullPath,
          maxDepth,
          currentDepth + 1
        );
        contents.push(...subContents);
      }
    }
  } catch (error) {
    logger.error(`Error reading ${targetPath}:`, {
      error: error instanceof Error ? error.message : String(error)
    });
  }
  return contents;
}
/**
 * Creates a structured prompt for Gemini
 */
function createStructuredPrompt(
  query: string,
  repoContent: string[],
  analysisType: 'code' | 'documentation' | 'both'
): string {
  return `You are a software analysis expert. Analyze the following repository content and answer this query: ${query}
Analysis type: ${analysisType}
Repository content:
${repoContent.join('\n\n')}
Please provide your answer in the following structured format:
# Main Analysis
[Your detailed analysis addressing the query]
# Code Insights
## Architecture
- [Key architectural pattern or component 1]
- [Key architectural pattern or component 2]
- ...
## Dependencies
- [Important dependency 1]
- [Important dependency 2]
- ...
## Patterns
- [Design pattern or code pattern 1]
- [Design pattern or code pattern 2]
- ...
# Documentation Insights
## Coverage
[Percentage estimate of documentation coverage, e.g., 60%]
## Quality
[Assessment of documentation quality: Excellent/Good/Fair/Poor]
## Recommendations
- [Documentation improvement 1]
- [Documentation improvement 2]
- ...
Be factual and base your analysis only on the provided content.`;
}
/**
 * Parse Gemini's response to extract structured insights
 */
function parseGeminiResponse(geminiText: string): z.infer<typeof repoAnalysisResponseSchema> {
  // Initialize result with default values
  const result: z.infer<typeof repoAnalysisResponseSchema> = {
    analysis: '',
    codeInsights: {
      architecture: [],
      dependencies: [],
      patterns: []
    },
    documentationInsights: {
      coverage: 0,
      quality: 'Poor',
      recommendations: []
    }
  };
  // Extract main analysis
  const mainAnalysisMatch = geminiText.match(/# Main Analysis\s+([\s\S]+?)(?=# Code Insights|$)/i);
  if (mainAnalysisMatch) {
    result.analysis = mainAnalysisMatch[1].trim();
  }
  // Extract architecture insights
  const architectureMatch = geminiText.match(/## Architecture\s+([\s\S]+?)(?=## Dependencies|## Patterns|# Documentation Insights|$)/i);
  if (architectureMatch) {
    const architectureItems = architectureMatch[1].match(/- (.+)/g);
    if (architectureItems) {
      result.codeInsights.architecture = architectureItems.map(item => item.replace(/^- /, '').trim());
    }
  }
  // Extract dependencies insights
  const dependenciesMatch = geminiText.match(/## Dependencies\s+([\s\S]+?)(?=## Patterns|# Documentation Insights|$)/i);
  if (dependenciesMatch) {
    const dependencyItems = dependenciesMatch[1].match(/- (.+)/g);
    if (dependencyItems) {
      result.codeInsights.dependencies = dependencyItems.map(item => item.replace(/^- /, '').trim());
    }
  }
  // Extract patterns insights
  const patternsMatch = geminiText.match(/## Patterns\s+([\s\S]+?)(?=# Documentation Insights|$)/i);
  if (patternsMatch) {
    const patternItems = patternsMatch[1].match(/- (.+)/g);
    if (patternItems) {
      result.codeInsights.patterns = patternItems.map(item => item.replace(/^- /, '').trim());
    }
  }
  // Extract documentation coverage
  const coverageMatch = geminiText.match(/## Coverage\s+(\d+)%/i);
  if (coverageMatch) {
    result.documentationInsights.coverage = parseInt(coverageMatch[1], 10);
  }
  // Extract documentation quality
  const qualityMatch = geminiText.match(/## Quality\s+(\w+)/i);
  if (qualityMatch) {
    result.documentationInsights.quality = qualityMatch[1].trim();
  }
  return result;
}
/**
 * Format the analysis as markdown for saving to file
 */
function formatAnalysisAsMarkdown(
  query: string,
  analysis: z.infer<typeof repoAnalysisResponseSchema>,
  targetPath: string,
  analysisType: 'code' | 'documentation' | 'both'
): string {
  const timestamp = new Date().toISOString();
  let markdown = `# Repository Analysis\n\n`;
  markdown += `**Query:** ${query}\n`;
  markdown += `**Target Path:** ${targetPath}\n`;
  markdown += `**Analysis Type:** ${analysisType}\n`;
  markdown += `**Date:** ${timestamp}\n\n`;
  markdown += `## Main Analysis\n\n${analysis.analysis}\n\n`;
  if (analysis.codeInsights) {
    markdown += `## Code Insights\n\n`;
    if (analysis.codeInsights.architecture?.length) {
      markdown += `### Architecture\n\n`;
      analysis.codeInsights.architecture.forEach(item => {
        markdown += `- ${item}\n`;
      });
      markdown += '\n';
    }
    if (analysis.codeInsights.dependencies?.length) {
      markdown += `### Dependencies\n\n`;
      analysis.codeInsights.dependencies.forEach(item => {
        markdown += `- ${item}\n`;
      });
      markdown += '\n';
    }
    if (analysis.codeInsights.patterns?.length) {
      markdown += `### Patterns\n\n`;
      analysis.codeInsights.patterns.forEach(item => {
        markdown += `- ${item}\n`;
      });
      markdown += '\n';
    }
  }
  if (analysis.documentationInsights) {
    markdown += `## Documentation Insights\n\n`;
    if (analysis.documentationInsights.coverage !== undefined) {
      markdown += `### Coverage\n\n${analysis.documentationInsights.coverage}%\n\n`;
    }
    if (analysis.documentationInsights.quality) {
      markdown += `### Quality\n\n${analysis.documentationInsights.quality}\n\n`;
    }
    if (analysis.documentationInsights.recommendations?.length) {
      markdown += `### Recommendations\n\n`;
      analysis.documentationInsights.recommendations.forEach(item => {
        markdown += `- ${item}\n`;
      });
      markdown += '\n';
    }
  }
  return markdown;
}
</file>

<file path="src/capabilities/tools/web-search.ts">
import { z } from 'zod';
import { logger } from '../../utils/logger.js';
import type { Tool } from '../../types/tool.js';
import { perplexityService } from '../../services/perplexity.service.js';
import { fileStorageService } from '../../services/file-storage.service.js';
// Define request and response schemas
const WebSearchRequestSchema = z.object({
    query: z.string().min(1, "Search query cannot be empty"),
    saveToFile: z.boolean().optional().default(false),
    maxTokens: z.number().optional().default(150)
});
const WebSearchResponseSchema = z.object({
    searchResults: z.string(),
    savedToFile: z.string().optional(),
    metadata: z.object({
        model: z.string().optional(),
        tokenUsage: z.object({
            promptTokens: z.number().optional(),
            completionTokens: z.number().optional(),
            totalTokens: z.number().optional()
        }).optional()
    }).optional()
});
type WebSearchRequest = z.infer<typeof WebSearchRequestSchema>;
type WebSearchResponse = z.infer<typeof WebSearchResponseSchema>;
export const webSearchTool: Tool = {
    name: 'web-search',
    version: '0.2.0',
    description: 'Performs a web search using Perplexity AI.',
    execute: async (request: unknown): Promise<unknown> => {
        // Validate request
        const { query, saveToFile, maxTokens } = WebSearchRequestSchema.parse(request);
        try {
            logger.info("Executing web search tool", { query, saveToFile });
            // Use PerplexityService to perform the search
            const searchResult = await perplexityService.search(query, { maxTokens });
            // If saveToFile is true, save results to file using FileStorageService
            let savedFilePath: string | undefined;
            if (saveToFile) {
                try {
                    const savePath = `local-research/web-search-${Date.now()}.md`;
                    logger.debug("Saving search results to file", { path: savePath });
                    savedFilePath = await fileStorageService.saveToFile(savePath, searchResult.content, {
                        createDirectory: true
                    });
                    logger.info("Search results saved successfully", { path: savedFilePath });
                } catch (fsError) {
                    logger.error("Failed to save search results to file", {
                        error: fsError instanceof Error ? fsError.message : String(fsError),
                        query
                    });
                    // Continue execution even if file saving fails
                }
            }
            // Format the response according to the schema
            return WebSearchResponseSchema.parse({
                searchResults: searchResult.content,
                savedToFile: savedFilePath,
                metadata: searchResult.metadata
            });
        } catch (error) {
            logger.error("Web search tool execution failed", {
                error: error instanceof Error ? error.message : String(error),
                query,
                stack: error instanceof Error ? error.stack : undefined
            });
            if (error instanceof z.ZodError) {
                throw new Error(`Validation error: ${error.errors[0]?.message || 'Invalid data format'}`);
            }
            throw error; // Let the service's error propagate
        }
    },
    requestSchema: WebSearchRequestSchema,
    responseSchema: WebSearchResponseSchema
};
</file>

<file path="src/config/index.ts">
import { z } from 'zod';
import dotenv from 'dotenv';
// Load environment variables
dotenv.config();
// Define environment variable schema
const EnvSchema = z.object({
    NODE_ENV: z.enum(['development', 'production', 'test']).default('development'),
    LOG_LEVEL: z.enum(['debug', 'info', 'warn', 'error']).default('info'),
    PERPLEXITY_API_KEY: z.string().optional(),
    GOOGLE_API_KEY: z.string(),
    PORT: z.string().optional(),
    HOST: z.string().optional(),
    REST_API_ENABLED: z.enum(['true', 'false']).default('false'),
    REST_API_PORT: z.string().optional(),
    HTTP_TRANSPORT_ENABLED: z.enum(['true', 'false']).default('false'),
    HTTP_TRANSPORT_PORT: z.string().optional(),
    HTTP_TRANSPORT_PATH: z.string().optional(),
    SSE_TRANSPORT_ENABLED: z.enum(['true', 'false']).default('false'),
    SSE_TRANSPORT_PORT: z.string().optional(),
    SSE_TRANSPORT_PATH: z.string().optional(),
    HTTPS_ENABLED: z.enum(['true', 'false']).default('false'),
    HTTPS_KEY_PATH: z.string().optional(),
    HTTPS_CERT_PATH: z.string().optional(),
    WEB_INTERFACE_ENABLED: z.enum(['true', 'false']).default('true'),
    WEB_INTERFACE_PORT: z.string().optional()
});
// Define REST API configuration schema
const RestApiConfigSchema = z.object({
    enabled: z.boolean().default(false),
    port: z.number().default(3000),
    host: z.string().default('localhost')
});
// Define HTTP transport configuration schema
const HttpTransportConfigSchema = z.object({
    enabled: z.boolean().default(false),
    port: z.number().default(3000),
    host: z.string().default('localhost'),
    path: z.string().default('/mcp')
});
// Define SSE transport configuration schema
const SseTransportConfigSchema = z.object({
    enabled: z.boolean().default(false),
    port: z.number().default(3001),
    host: z.string().default('localhost'),
    path: z.string().default('/mcp-sse')
});
// Define HTTPS configuration schema
const HttpsConfigSchema = z.object({
    enabled: z.boolean().default(false),
    keyPath: z.string().optional(),
    certPath: z.string().optional()
});
// Define Web Interface configuration schema
const WebInterfaceConfigSchema = z.object({
    enabled: z.boolean().default(true),
    port: z.number().default(3002)
});
// Define server configuration schema
export const ServerConfigSchema = z.object({
    name: z.string(),
    version: z.string(),
    description: z.string(),
    logLevel: z.enum(['debug', 'info', 'warn', 'error']).default('info'),
    env: z.enum(['development', 'production', 'test']).default('development'),
    port: z.number().optional(),
    host: z.string().optional(),
    restApi: RestApiConfigSchema.optional(),
    httpTransport: HttpTransportConfigSchema.optional(),
    sseTransport: SseTransportConfigSchema.optional(),
    https: HttpsConfigSchema.optional(),
    webInterface: WebInterfaceConfigSchema.optional(),
    features: z.object({
        webSearch: z.boolean().default(true),
        repoAnalysis: z.boolean().default(true),
        browserAutomation: z.boolean().default(true),
        webInterface: z.boolean().default(true)
    }).optional()
});
// Parse and validate environment variables
const env = EnvSchema.parse(process.env);
// Log the environment variables for debugging
console.log('Loaded environment variables:', {
    REST_API_ENABLED: env.REST_API_ENABLED,
    HTTP_TRANSPORT_ENABLED: env.HTTP_TRANSPORT_ENABLED,
    SSE_TRANSPORT_ENABLED: env.SSE_TRANSPORT_ENABLED,
    WEB_INTERFACE_ENABLED: env.WEB_INTERFACE_ENABLED
});
// Export validated configuration
export const config = {
    name: "cursor-tools-mcp-server",
    version: "0.1.0",
    description: "MCP server mimicking cursor-tools functionalities.",
    logLevel: env.LOG_LEVEL,
    env: env.NODE_ENV,
    port: env.PORT ? parseInt(env.PORT, 10) : undefined,
    host: env.HOST,
    perplexityApiKey: env.PERPLEXITY_API_KEY,
    googleApiKey: env.GOOGLE_API_KEY,
    restApi: {
        enabled: env.REST_API_ENABLED === 'true',
        port: env.REST_API_PORT ? parseInt(env.REST_API_PORT, 10) : 3000,
        host: env.HOST || 'localhost'
    },
    httpTransport: {
        enabled: env.HTTP_TRANSPORT_ENABLED === 'true',
        port: env.HTTP_TRANSPORT_PORT ? parseInt(env.HTTP_TRANSPORT_PORT, 10) : 3001,
        host: env.HOST || 'localhost',
        path: env.HTTP_TRANSPORT_PATH || '/mcp'
    },
    sseTransport: {
        enabled: env.SSE_TRANSPORT_ENABLED === 'true',
        port: env.SSE_TRANSPORT_PORT ? parseInt(env.SSE_TRANSPORT_PORT, 10) : 3002,
        host: env.HOST || 'localhost',
        path: env.SSE_TRANSPORT_PATH || '/mcp-sse'
    },
    https: {
        enabled: env.HTTPS_ENABLED === 'true',
        keyPath: env.HTTPS_KEY_PATH,
        certPath: env.HTTPS_CERT_PATH
    },
    webInterface: {
        enabled: env.WEB_INTERFACE_ENABLED === 'true',
        port: env.WEB_INTERFACE_PORT ? parseInt(env.WEB_INTERFACE_PORT, 10) : 3003
    },
    features: {
        webSearch: true,
        repoAnalysis: true,
        browserAutomation: true,
        webInterface: env.WEB_INTERFACE_ENABLED === 'true'
    }
};
// Export environment variables
export const environment = env;
</file>

<file path="src/resources/__tests__/github-pr.resource.test.ts">
import { jest, describe, it, expect, beforeEach } from '@jest/globals';
import path from 'path';
// Import the fileStorageService to spy on its methods
import { fileStorageService } from '../../services/file-storage.service.js';
// Spy on fileStorageService methods
jest.spyOn(fileStorageService, 'saveToFile').mockResolvedValue('/mock/path');
jest.spyOn(fileStorageService, 'readFromFile').mockResolvedValue('{}');
jest.spyOn(fileStorageService, 'fileExists').mockResolvedValue(false);
jest.spyOn(fileStorageService, 'deleteFile').mockResolvedValue(true);
// Mock the modules
jest.mock('@octokit/rest');
jest.mock('../../utils/logger.js', () => ({
  logger: {
    debug: jest.fn(),
    info: jest.fn(),
    warn: jest.fn(),
    error: jest.fn()
  }
}));
jest.mock('../../utils/rate-limiter.js');
// Import the GitHubPRResource class
import { GitHubPRResource } from '../github-pr.resource';
describe('GitHubPRResource', () => {
  const TEST_CACHE_DIR = '/test/cache/dir';
  const TEST_TOKEN = 'fake-token';
  it('should initialize and create the cache directory', async () => {
    // Create an instance 
    const resource = new GitHubPRResource({
      githubToken: TEST_TOKEN,
      cacheDir: TEST_CACHE_DIR
    });
    // Call initialize
    await resource.initialize();
    // Verify the directory creation was attempted
    expect(fileStorageService.saveToFile).toHaveBeenCalledWith(
      expect.stringMatching(/\.gitkeep$/),
      '',
      expect.objectContaining({ createDirectory: true })
    );
    // Get the actual called path
    if ((fileStorageService.saveToFile as jest.Mock).mock.calls.length > 0) {
      const actualFilePath = (fileStorageService.saveToFile as jest.Mock).mock.calls[0][0];
      // Check if the path contains the expected parts
      expect(path.normalize(actualFilePath)).toContain(path.normalize(TEST_CACHE_DIR));
    }
  });
  // Test the list method by mocking it directly
  it('should list pull requests', async () => {
    // Create a mock implementation of the list method
    const mockList = jest.fn().mockResolvedValue({
      resources: [{
        id: 1,
        number: 1,
        title: 'Test PR 1',
        state: 'open',
        html_url: 'https://github.com/test/repo/pull/1',
        user: { login: 'testuser', avatar_url: 'https://github.com/testuser.png' },
        created_at: '2023-01-01',
        updated_at: '2023-01-02', 
        body: 'Test PR body',
        labels: []
      }]
    });
    // Create an instance and override the list method
    const resource = new GitHubPRResource({
      githubToken: TEST_TOKEN,
      cacheDir: TEST_CACHE_DIR
    });
    // Replace the list method with our mock
    resource.list = mockList;
    // Call the list method
    const result = await resource.list({
      owner: 'testowner',
      repo: 'testrepo',
      state: 'open'
    });
    // Verify the mock was called with the correct parameters
    expect(mockList).toHaveBeenCalledWith({
      owner: 'testowner',
      repo: 'testrepo',
      state: 'open'
    });
    // Verify the result structure
    expect(result).toHaveProperty('resources');
    expect(result.resources).toHaveLength(1);
    expect(result.resources[0]).toHaveProperty('id', 1);
    expect(result.resources[0]).toHaveProperty('title', 'Test PR 1');
  });
  // Test error handling by mocking the list method to throw
  it('should handle errors when listing pull requests', async () => {
    // Create a mock implementation that throws an error
    const mockList = jest.fn().mockRejectedValue(
      new Error('API rate limit exceeded')
    );
    // Create an instance and override the list method
    const resource = new GitHubPRResource({
      githubToken: TEST_TOKEN,
      cacheDir: TEST_CACHE_DIR
    });
    // Replace the list method with our mock
    resource.list = mockList;
    // Call the list method and expect it to throw
    await expect(resource.list({
      owner: 'testowner',
      repo: 'testrepo'
    })).rejects.toThrow('API rate limit exceeded');
    // Verify the mock was called with the correct parameters
    expect(mockList).toHaveBeenCalledWith({
      owner: 'testowner',
      repo: 'testrepo'
    });
  });
  // Test the get method by mocking it directly
  it('should get a specific pull request', async () => {
    // Create a mock implementation of the read method
    const mockRead = jest.fn().mockResolvedValue({
      resource: {
        id: 123,
        number: 123,
        title: 'Test PR',
        state: 'open',
        html_url: 'https://github.com/test/repo/pull/123',
        user: { login: 'testuser', avatar_url: 'https://github.com/testuser.png' },
        created_at: '2023-01-01',
        updated_at: '2023-01-02',
        body: 'Test PR body',
        labels: []
      }
    });
    // Create an instance and override the read method
    const resource = new GitHubPRResource({
      githubToken: TEST_TOKEN,
      cacheDir: TEST_CACHE_DIR
    });
    // Replace the read method with our mock
    resource.read = mockRead;
    // Call the read method
    const result = await resource.read({
      owner: 'testowner',
      repo: 'testrepo',
      pull_number: 123
    });
    // Verify the mock was called with the correct parameters
    expect(mockRead).toHaveBeenCalledWith({
      owner: 'testowner',
      repo: 'testrepo',
      pull_number: 123
    });
    // Verify the result structure
    expect(result).toHaveProperty('resource');
    expect(result.resource).toHaveProperty('id', 123);
    expect(result.resource).toHaveProperty('number', 123);
    expect(result.resource).toHaveProperty('title', 'Test PR');
  });
});
</file>

<file path="src/resources/github-pr.resource.ts">
import { z } from 'zod';
import { Octokit } from '@octokit/rest';
import { logger } from '../utils/logger.js';
import { RateLimiter } from '../utils/rate-limiter.js';
import { config } from '../config/index.js';
import { fileStorageService } from '../services/file-storage.service.js';
import * as path from 'path';
// GitHub authentication token from config or environment
const GITHUB_TOKEN = process.env.GITHUB_TOKEN || '';
// Define schemas for the resource
const GitHubPRListRequestSchema = z.object({
  owner: z.string().min(1, "Owner is required"),
  repo: z.string().min(1, "Repository is required"),
  state: z.enum(['open', 'closed', 'all']).optional().default('open'),
  per_page: z.number().min(1).max(100).optional().default(10),
  page: z.number().min(1).optional().default(1)
});
const GitHubPRReadRequestSchema = z.object({
  owner: z.string().min(1, "Owner is required"),
  repo: z.string().min(1, "Repository is required"),
  pull_number: z.number().min(1, "Pull request number is required")
});
const GitHubPRSchema = z.object({
  id: z.number(),
  number: z.number(),
  title: z.string(),
  state: z.enum(['open', 'closed']),
  html_url: z.string().url(),
  user: z.object({
    login: z.string(),
    avatar_url: z.string().url()
  }),
  created_at: z.string(),
  updated_at: z.string(),
  body: z.string().nullable(),
  labels: z.array(z.object({
    name: z.string(),
    color: z.string()
  })),
  comments: z.number().optional(),
  commits: z.number().optional(),
  additions: z.number().optional(),
  deletions: z.number().optional(),
  changed_files: z.number().optional()
});
const GitHubPRListResponseSchema = z.object({
  resources: z.array(GitHubPRSchema)
});
const GitHubPRReadResponseSchema = z.object({
  resource: GitHubPRSchema
});
// Interface for GitHubPRResource configuration
export interface GitHubPRResourceConfig {
  githubToken?: string;
  cacheDir?: string;
}
class GitHubPRResource {
  private octokit: Octokit;
  private rateLimiter: RateLimiter;
  private initialized: boolean = false;
  private readonly cacheDir: string;
  constructor(config?: GitHubPRResourceConfig) {
    // Use provided token or fallback to environment variable
    const githubToken = config?.githubToken || GITHUB_TOKEN;
    // Use provided cache directory or fallback to default
    this.cacheDir = config?.cacheDir || path.join(process.cwd(), 'cache', 'github-pr');
    this.octokit = new Octokit({
      auth: githubToken
    });
    // Create a rate limiter for GitHub API (5000 requests per hour for authenticated requests)
    this.rateLimiter = new RateLimiter('github-api', {
      maxTokens: 5000,
      refillRate: 1.38, // ~5000 requests per hour (5000/3600)
      waitForTokens: true
    });
    logger.debug("GitHub PR resource created with rate limiter", {
      resource: 'github-pr',
      maxTokens: 5000,
      refillRate: 1.38
    });
  }
  /**
   * Initialize the resource
   */
  async initialize(): Promise<void> {
    if (this.initialized) {
      return;
    }
    try {
      // Create cache directory if needed
      await fileStorageService.saveToFile(
        path.join(this.cacheDir, '.gitkeep'),
        '',
        { createDirectory: true }
      );
      this.initialized = true;
      logger.info("GitHub PR resource initialized", { resource: 'github-pr' });
    } catch (error) {
      logger.error("Failed to initialize GitHub PR resource", {
        error: error instanceof Error ? error.message : String(error)
      });
      throw new Error(`Failed to initialize GitHub PR resource: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  /**
   * List pull requests for a repository
   */
  async list(request: z.infer<typeof GitHubPRListRequestSchema>): Promise<z.infer<typeof GitHubPRListResponseSchema>> {
    try {
      // Validate request
      const validatedRequest = GitHubPRListRequestSchema.parse(request);
      const { owner, repo, state, per_page, page } = validatedRequest;
      logger.info("Listing GitHub pull requests", { owner, repo, state, page });
      // Check if results are cached
      const cacheKey = `${owner}-${repo}-${state}-${per_page}-${page}`;
      const cachePath = path.join(this.cacheDir, `${cacheKey}.json`);
      let pullRequests;
      let fromCache = false;
      // Try to get from cache first
      if (await fileStorageService.fileExists(cachePath)) {
        try {
          const cacheContent = await fileStorageService.readFromFile(cachePath);
          pullRequests = JSON.parse(cacheContent);
          fromCache = true;
          logger.debug("Using cached GitHub PR data", { owner, repo, cachePath });
        } catch (error) {
          logger.warn("Failed to read GitHub PR cache, will fetch fresh data", {
            error: error instanceof Error ? error.message : String(error),
            cachePath
          });
        }
      }
      // Fetch from GitHub API if not in cache
      if (!pullRequests) {
        // Acquire a token before making the API request
        await this.rateLimiter.acquireToken();
        const response = await this.octokit.pulls.list({
          owner,
          repo,
          state,
          per_page,
          page
        });
        pullRequests = response.data;
        // Save to cache
        try {
          await fileStorageService.saveToFile(
            cachePath,
            JSON.stringify(pullRequests),
            { createDirectory: true }
          );
          logger.debug("Saved GitHub PR data to cache", { cachePath });
        } catch (error) {
          logger.warn("Failed to cache GitHub PR data", {
            error: error instanceof Error ? error.message : String(error),
            cachePath
          });
        }
      }
      // Transform and validate response
      const resources = pullRequests.map(pr => ({
        id: pr.id,
        number: pr.number,
        title: pr.title,
        state: pr.state as 'open' | 'closed',
        html_url: pr.html_url,
        user: {
          login: pr.user?.login || 'unknown',
          avatar_url: pr.user?.avatar_url || ''
        },
        created_at: pr.created_at,
        updated_at: pr.updated_at,
        body: pr.body,
        labels: pr.labels.map(label => ({
          name: (label as any).name || 'unknown',
          color: (label as any).color || 'ffffff'
        })),
        comments: pr.comments,
        commits: (pr as any).commits,
        additions: (pr as any).additions,
        deletions: (pr as any).deletions,
        changed_files: (pr as any).changed_files
      }));
      logger.info("GitHub pull requests retrieved", {
        owner,
        repo,
        count: resources.length,
        fromCache
      });
      return { resources };
    } catch (error) {
      logger.error("Failed to list GitHub pull requests", {
        error: error instanceof Error ? error.message : String(error),
        request
      });
      if (error instanceof z.ZodError) {
        throw new Error(`Invalid request: ${error.errors[0]?.message}`);
      }
      throw new Error(`Failed to list GitHub pull requests: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  /**
   * Get a specific pull request
   */
  async read(request: z.infer<typeof GitHubPRReadRequestSchema>): Promise<z.infer<typeof GitHubPRReadResponseSchema>> {
    try {
      // Validate request
      const validatedRequest = GitHubPRReadRequestSchema.parse(request);
      const { owner, repo, pull_number } = validatedRequest;
      logger.info("Getting GitHub pull request", { owner, repo, pull_number });
      // Check if result is cached
      const cacheKey = `${owner}-${repo}-${pull_number}`;
      const cachePath = path.join(this.cacheDir, `pr-${cacheKey}.json`);
      let pullRequest;
      let fromCache = false;
      // Try to get from cache first
      if (await fileStorageService.fileExists(cachePath)) {
        try {
          const cacheContent = await fileStorageService.readFromFile(cachePath);
          pullRequest = JSON.parse(cacheContent);
          fromCache = true;
          logger.debug("Using cached GitHub PR data", { owner, repo, pull_number, cachePath });
        } catch (error) {
          logger.warn("Failed to read GitHub PR cache, will fetch fresh data", {
            error: error instanceof Error ? error.message : String(error),
            cachePath
          });
        }
      }
      // Fetch from GitHub API if not in cache
      if (!pullRequest) {
        // Acquire a token before making the API request
        await this.rateLimiter.acquireToken();
        const [prResponse, commitsResponse] = await Promise.all([
          // Get PR details
          this.octokit.pulls.get({
            owner,
            repo,
            pull_number
          }),
          // Get PR commits count
          this.octokit.pulls.listCommits({
            owner,
            repo,
            pull_number,
            per_page: 1
          })
        ]);
        pullRequest = {
          ...prResponse.data,
          commits: commitsResponse.data[0] ? (await this.octokit.pulls.get({
            owner,
            repo,
            pull_number
          })).data.commits : 0
        };
        // Save to cache
        try {
          await fileStorageService.saveToFile(
            cachePath,
            JSON.stringify(pullRequest),
            { createDirectory: true }
          );
          logger.debug("Saved GitHub PR data to cache", { cachePath });
        } catch (error) {
          logger.warn("Failed to cache GitHub PR data", {
            error: error instanceof Error ? error.message : String(error),
            cachePath
          });
        }
      }
      // Transform and validate response
      const resource = {
        id: pullRequest.id,
        number: pullRequest.number,
        title: pullRequest.title,
        state: pullRequest.state as 'open' | 'closed',
        html_url: pullRequest.html_url,
        user: {
          login: pullRequest.user?.login || 'unknown',
          avatar_url: pullRequest.user?.avatar_url || ''
        },
        created_at: pullRequest.created_at,
        updated_at: pullRequest.updated_at,
        body: pullRequest.body,
        labels: (pullRequest.labels || []).map(label => ({
          name: (label as any).name || 'unknown',
          color: (label as any).color || 'ffffff'
        })),
        comments: pullRequest.comments,
        commits: pullRequest.commits,
        additions: pullRequest.additions,
        deletions: pullRequest.deletions,
        changed_files: pullRequest.changed_files
      };
      logger.info("GitHub pull request retrieved", {
        owner,
        repo,
        pull_number,
        fromCache
      });
      return { resource };
    } catch (error) {
      logger.error("Failed to get GitHub pull request", {
        error: error instanceof Error ? error.message : String(error),
        request
      });
      if (error instanceof z.ZodError) {
        throw new Error(`Invalid request: ${error.errors[0]?.message}`);
      }
      throw new Error(`Failed to get GitHub pull request: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
}
// Export a singleton instance
export const githubPrResource = new GitHubPRResource();
// Export schemas
export {
  GitHubPRListRequestSchema,
  GitHubPRReadRequestSchema,
  GitHubPRSchema,
  GitHubPRListResponseSchema,
  GitHubPRReadResponseSchema
};
// Export the resource
export { GitHubPRResource };
</file>

<file path="src/resources/search-history.resource.ts">
import { z } from 'zod';
import { v4 as uuidv4 } from 'uuid';
import { fileStorageService } from '../services/file-storage.service.js';
import { logger } from '../utils/logger.js';
import path from 'path';
/**
 * Interface for a search history entry
 */
export interface SearchHistoryEntry {
  id: string;
  query: string;
  timestamp: string;
  results: string;
  metadata?: Record<string, any>;
}
/**
 * Service for managing search history
 */
export class SearchHistoryResource {
  private storageDir: string;
  private historyFile: string;
  private searchHistory: SearchHistoryEntry[] = [];
  private initialized = false;
  constructor(storageDir = 'data/search-history') {
    this.storageDir = storageDir;
    this.historyFile = path.join(this.storageDir, 'history.json');
  }
  /**
   * Initialize the search history resource
   */
  async initialize(): Promise<void> {
    if (this.initialized) {
      return;
    }
    try {
      // Check if history file exists
      const exists = await fileStorageService.fileExists(this.historyFile);
      if (exists) {
        const historyData = await fileStorageService.readFromFile(this.historyFile);
        try {
          this.searchHistory = JSON.parse(historyData);
          logger.info('Search history loaded', { count: this.searchHistory.length });
        } catch (error) {
          logger.error('Failed to parse search history', { 
            error: error instanceof Error ? error.message : String(error) 
          });
          this.searchHistory = [];
        }
      } else {
        // Create directory if it doesn't exist
        await fileStorageService.saveToFile(this.historyFile, JSON.stringify([]), {
          createDir: true
        });
        logger.info('Created new search history file');
      }
      this.initialized = true;
    } catch (error) {
      logger.error('Failed to initialize search history', { 
        error: error instanceof Error ? error.message : String(error) 
      });
      throw error;
    }
  }
  /**
   * Add a new search to history
   */
  async addSearch(query: string, results: string, metadata?: Record<string, any>): Promise<SearchHistoryEntry> {
    await this.ensureInitialized();
    const entry: SearchHistoryEntry = {
      id: uuidv4(),
      query,
      timestamp: new Date().toISOString(),
      results,
      metadata
    };
    this.searchHistory.push(entry);
    await this.saveHistory();
    logger.info('Added search to history', { id: entry.id, query });
    return entry;
  }
  /**
   * Get all search history
   */
  async getHistory(limit?: number, offset = 0): Promise<SearchHistoryEntry[]> {
    await this.ensureInitialized();
    const history = this.searchHistory
      .sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime())
      .slice(offset, limit ? offset + limit : undefined);
    logger.info('Retrieved search history', { count: history.length });
    return history;
  }
  /**
   * Get a specific search by ID
   */
  async getSearch(id: string): Promise<SearchHistoryEntry | null> {
    await this.ensureInitialized();
    const entry = this.searchHistory.find(entry => entry.id === id);
    if (entry) {
      logger.info('Retrieved search entry', { id });
      return entry;
    }
    logger.info('Search entry not found', { id });
    return null;
  }
  /**
   * Delete a search from history
   */
  async deleteSearch(id: string): Promise<boolean> {
    await this.ensureInitialized();
    const initialLength = this.searchHistory.length;
    this.searchHistory = this.searchHistory.filter(entry => entry.id !== id);
    const wasDeleted = initialLength > this.searchHistory.length;
    if (wasDeleted) {
      await this.saveHistory();
      logger.info('Deleted search from history', { id });
    } else {
      logger.info('Search entry not found for deletion', { id });
    }
    return wasDeleted;
  }
  /**
   * Search through history for matching queries
   */
  async searchHistory(term: string): Promise<SearchHistoryEntry[]> {
    await this.ensureInitialized();
    const lowerTerm = term.toLowerCase();
    const matches = this.searchHistory.filter(
      entry => entry.query.toLowerCase().includes(lowerTerm)
    ).sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());
    logger.info('Searched history', { term, matchCount: matches.length });
    return matches;
  }
  /**
   * Clear all search history
   */
  async clearHistory(): Promise<void> {
    await this.ensureInitialized();
    this.searchHistory = [];
    await this.saveHistory();
    logger.info('Cleared search history');
  }
  /**
   * Save the current history to disk
   */
  private async saveHistory(): Promise<void> {
    try {
      await fileStorageService.saveToFile(
        this.historyFile,
        JSON.stringify(this.searchHistory, null, 2),
        { createDir: true }
      );
      logger.info('Saved search history', { count: this.searchHistory.length });
    } catch (error) {
      logger.error('Failed to save search history', { 
        error: error instanceof Error ? error.message : String(error) 
      });
      throw error;
    }
  }
  /**
   * Ensure the resource is initialized
   */
  private async ensureInitialized(): Promise<void> {
    if (!this.initialized) {
      await this.initialize();
    }
  }
}
// Export a singleton instance
export const searchHistoryResource = new SearchHistoryResource();
</file>

<file path="src/routes/search-history.routes.ts">
import express from 'express';
import { z } from 'zod';
import { searchHistoryResource } from '../resources/search-history.resource.js';
import { logger } from '../utils/logger.js';
const router = express.Router();
// Validation schemas
const AddSearchSchema = z.object({
  query: z.string().min(1, 'Query is required'),
  results: z.string(),
  metadata: z.record(z.any()).optional()
});
const SearchQuerySchema = z.object({
  term: z.string().min(1, 'Search term is required')
});
const IdParamSchema = z.object({
  id: z.string().uuid('Invalid ID format')
});
const PaginationSchema = z.object({
  limit: z.coerce.number().optional().default(20),
  offset: z.coerce.number().optional().default(0)
});
/**
 * GET /api/search-history
 * Retrieve all search history entries with pagination
 */
router.get('/', async (req, res) => {
  try {
    const { limit, offset } = PaginationSchema.parse({
      limit: req.query.limit,
      offset: req.query.offset
    });
    const history = await searchHistoryResource.getHistory(limit, offset);
    res.json({
      success: true,
      data: history,
      count: history.length,
      pagination: { limit, offset }
    });
  } catch (error) {
    logger.error('Failed to retrieve search history', {
      error: error instanceof Error ? error.message : String(error)
    });
    if (error instanceof z.ZodError) {
      return res.status(400).json({
        success: false,
        error: 'Invalid pagination parameters',
        details: error.errors
      });
    }
    res.status(500).json({
      success: false,
      error: 'Failed to retrieve search history'
    });
  }
});
/**
 * GET /api/search-history/search
 * Search through history for matching queries
 */
router.get('/search', async (req, res) => {
  try {
    const { term } = SearchQuerySchema.parse(req.query);
    const results = await searchHistoryResource.searchHistory(term);
    res.json({
      success: true,
      data: results,
      count: results.length
    });
  } catch (error) {
    logger.error('Failed to search history', {
      error: error instanceof Error ? error.message : String(error),
      query: req.query
    });
    if (error instanceof z.ZodError) {
      return res.status(400).json({
        success: false,
        error: 'Invalid search parameters',
        details: error.errors
      });
    }
    res.status(500).json({
      success: false,
      error: 'Failed to search history'
    });
  }
});
/**
 * GET /api/search-history/:id
 * Get a specific search history entry by ID
 */
router.get('/:id', async (req, res) => {
  try {
    const { id } = IdParamSchema.parse(req.params);
    const entry = await searchHistoryResource.getSearch(id);
    if (!entry) {
      return res.status(404).json({
        success: false,
        error: 'Search history entry not found'
      });
    }
    res.json({
      success: true,
      data: entry
    });
  } catch (error) {
    logger.error('Failed to retrieve search history entry', {
      error: error instanceof Error ? error.message : String(error),
      id: req.params.id
    });
    if (error instanceof z.ZodError) {
      return res.status(400).json({
        success: false,
        error: 'Invalid ID format',
        details: error.errors
      });
    }
    res.status(500).json({
      success: false,
      error: 'Failed to retrieve search history entry'
    });
  }
});
/**
 * POST /api/search-history
 * Add a new search to history
 */
router.post('/', async (req, res) => {
  try {
    const { query, results, metadata } = AddSearchSchema.parse(req.body);
    const entry = await searchHistoryResource.addSearch(query, results, metadata);
    res.status(201).json({
      success: true,
      data: entry
    });
  } catch (error) {
    logger.error('Failed to add search to history', {
      error: error instanceof Error ? error.message : String(error),
      body: req.body
    });
    if (error instanceof z.ZodError) {
      return res.status(400).json({
        success: false,
        error: 'Invalid search data',
        details: error.errors
      });
    }
    res.status(500).json({
      success: false,
      error: 'Failed to add search to history'
    });
  }
});
/**
 * DELETE /api/search-history/:id
 * Delete a search history entry by ID
 */
router.delete('/:id', async (req, res) => {
  try {
    const { id } = IdParamSchema.parse(req.params);
    const deleted = await searchHistoryResource.deleteSearch(id);
    if (!deleted) {
      return res.status(404).json({
        success: false,
        error: 'Search history entry not found'
      });
    }
    res.json({
      success: true,
      message: 'Search history entry deleted'
    });
  } catch (error) {
    logger.error('Failed to delete search history entry', {
      error: error instanceof Error ? error.message : String(error),
      id: req.params.id
    });
    if (error instanceof z.ZodError) {
      return res.status(400).json({
        success: false,
        error: 'Invalid ID format',
        details: error.errors
      });
    }
    res.status(500).json({
      success: false,
      error: 'Failed to delete search history entry'
    });
  }
});
/**
 * DELETE /api/search-history
 * Clear all search history
 */
router.delete('/', async (req, res) => {
  try {
    await searchHistoryResource.clearHistory();
    res.json({
      success: true,
      message: 'Search history cleared'
    });
  } catch (error) {
    logger.error('Failed to clear search history', {
      error: error instanceof Error ? error.message : String(error)
    });
    res.status(500).json({
      success: false,
      error: 'Failed to clear search history'
    });
  }
});
export const searchHistoryRoutes = router;
</file>

<file path="src/server.ts">
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { HttpServerTransport } from './transports/http.js';
import { SSEServerTransport } from './transports/sse.js';
import { webSearchTool } from './capabilities/tools/web-search.js';
import { repoAnalysisTool } from './capabilities/tools/repo-analysis.js';
import { browserAutomationTool } from './capabilities/tools/browser-automation.js';
import { config, ServerConfigSchema } from './config/index.js';
import { logger } from './utils/logger.js';
import { z } from 'zod';
import express from 'express';
import cors from 'cors';
import https from 'https';
import fs from 'fs';
import path from 'path';
import { searchHistoryRoutes } from './routes/search-history.routes.js';
import { searchHistoryResource } from './resources/search-history.resource.js';
import { githubPrResource } from './resources/github-pr.resource.js';
import { createWebInterface } from './web-interface.js';
// Define health check schema
const HealthCheckSchema = z.object({
    status: z.enum(['healthy', 'unhealthy']),
    uptime: z.number(),
    timestamp: z.string(),
    version: z.string()
});
// Define tool execution request schema
const ToolExecuteRequestSchema = z.object({
    method: z.literal('tool/execute'),
    params: z.object({
        toolName: z.string(),
        version: z.string(),
        arguments: z.record(z.unknown())
    })
});
// Define tool interface
interface Tool {
    name: string;
    version: string;
    description: string;
    execute: (request: unknown) => Promise<unknown>;
    requestSchema: z.ZodType;
    responseSchema: z.ZodType;
}
async function main() {
    try {
        logger.info("Starting MCP server...", { config });
        // Validate server configuration
        const validatedConfig = ServerConfigSchema.parse(config);
        // Initialize resources
        await searchHistoryResource.initialize();
        await githubPrResource.initialize();
        // Create tools map
        const tools: Record<string, Tool> = {
            'web-search': webSearchTool,
            'repo-analysis': repoAnalysisTool,
            'browser-automation': browserAutomationTool,
            'health-check': {
                name: 'health-check',
                version: '0.1.0',
                description: 'Check server health status',
                execute: async () => {
                    const health = {
                        status: 'healthy',
                        uptime: process.uptime(),
                        timestamp: new Date().toISOString(),
                        version: validatedConfig.version
                    };
                    return HealthCheckSchema.parse(health);
                },
                requestSchema: z.object({}),
                responseSchema: HealthCheckSchema
            }
        };
        // Create MCP server
        const server = new Server({
            name: validatedConfig.name,
            version: validatedConfig.version,
            description: validatedConfig.description,
            tools
        }, {
            capabilities: {
                protocol: {
                    version: '0.1.0',
                    name: 'jsonrpc'
                }
            }
        });
        // Determine transport type
        let transport;
        let transportType = 'stdio';
        let app;
        // Set up HTTP/SSE transport if enabled
        // Process config values first for debugging
        console.log('Transport config:', {
            restApi: validatedConfig.restApi?.enabled,
            httpTransport: validatedConfig.httpTransport?.enabled,
            sseTransport: validatedConfig.sseTransport?.enabled,
            webInterface: validatedConfig.webInterface?.enabled
        });
        // ALWAYS create Express app (regardless of config)
        app = express();
        app.use(cors());
        app.use(express.json());
        // Add search history routes
        app.use('/api/search-history', searchHistoryRoutes);
        // Add health check endpoint
        app.get('/health', (req, res) => {
            const health = {
                status: 'healthy',
                uptime: process.uptime(),
                timestamp: new Date().toISOString(),
                version: validatedConfig.version
            };
            res.json(health);
        });
        // Set up HTTP server (no HTTPS for now)
        const http = await import('http');
        const httpServer = http.createServer(app);
        // Start the REST API server
        const restApiPort = validatedConfig.restApi?.port || 3000;
        const host = validatedConfig.host || 'localhost';
        httpServer.listen(restApiPort, host, () => {
            logger.info(`REST API server listening on ${host}:${restApiPort}`);
        });
        // ALWAYS set up HTTP transport
        const httpTransportPort = validatedConfig.httpTransport?.port || 3001;
        const httpTransportPath = validatedConfig.httpTransport?.path || '/mcp';
        // Create a separate Express app for HTTP transport
        const httpApp = express();
        httpApp.use(cors());
        httpApp.use(express.json());
        const httpTransportServer = http.createServer(httpApp);
        httpTransportServer.listen(httpTransportPort, host, () => {
            logger.info(`HTTP transport server listening on ${host}:${httpTransportPort}`);
        });
        transport = new HttpServerTransport(httpApp, { path: httpTransportPath });
        transportType = 'HTTP';
        logger.info(`HTTP transport enabled on ${httpTransportPath}`);
        // ALWAYS set up SSE transport
        const sseTransportPort = validatedConfig.sseTransport?.port || 3002;
        const sseTransportPath = validatedConfig.sseTransport?.path || '/mcp-sse';
        // Create a separate Express app for SSE transport
        const sseApp = express();
        sseApp.use(cors());
        sseApp.use(express.json());
        const sseTransportServer = http.createServer(sseApp);
        sseTransportServer.listen(sseTransportPort, host, () => {
            logger.info(`SSE transport server listening on ${host}:${sseTransportPort}`);
        });
        // Create SSE Transport (but still use HTTP transport for main communications)
        new SSEServerTransport(sseApp, { path: sseTransportPath });
        logger.info(`SSE transport enabled on ${sseTransportPath}`);
        // Set up error handlers
        process.on('uncaughtException', (error) => {
            logger.error("Uncaught exception", { error: error.message, stack: error.stack });
            process.exit(1);
        });
        process.on('unhandledRejection', (reason, promise) => {
            logger.error("Unhandled rejection", { reason });
            process.exit(1);
        });
        // Handle termination
        process.on('SIGINT', async () => {
            logger.info("Shutting down server...");
            process.exit(0);
        });
        process.on('SIGTERM', async () => {
            logger.info("Shutting down server...");
            process.exit(0);
        });
        // Connect to transport
        logger.debug("Connecting to transport...");
        if (transport) {
            await server.connect(transport);
            logger.info(`MCP server started with ${transportType} transport`);
            logger.info(`Enabled features: ${Object.keys(config.features || {}).filter(key => (config.features || {})[key as keyof typeof config.features]).join(', ') || 'web-search, repo-analysis'}`);
            // Always start the web interface
            const webInterfacePort = validatedConfig.webInterface?.port || 3003;
            createWebInterface(webInterfacePort);
            logger.info(`Web interface started on port ${webInterfacePort}`);
        } else {
            throw new Error("No transport configured");
        }
    } catch (error) {
        logger.error("Server failed to start", { 
            error: error instanceof Error ? error.message : String(error),
            stack: error instanceof Error ? error.stack : undefined
        });
        process.exit(1);
    }
}
// Start the server
main();
</file>

<file path="src/services/__mocks__/file-storage.service.js">
import { jest } from '@jest/globals';
// Create mock functions for file operations
const mockSaveToFile = jest.fn().mockResolvedValue('/mock/path');
const mockReadFromFile = jest.fn().mockResolvedValue('{}');
const mockFileExists = jest.fn().mockResolvedValue(false);
const mockDeleteFile = jest.fn().mockResolvedValue(true);
const mockAppendToFile = jest.fn().mockResolvedValue('/mock/path');
// Export mock file storage service
export const fileStorageService = {
  saveToFile: mockSaveToFile,
  readFromFile: mockReadFromFile,
  fileExists: mockFileExists,
  deleteFile: mockDeleteFile,
  appendToFile: mockAppendToFile
};
// Export class for compatibility
export class FileStorageService {
  saveToFile = mockSaveToFile;
  readFromFile = mockReadFromFile;
  fileExists = mockFileExists;
  deleteFile = mockDeleteFile;
  appendToFile = mockAppendToFile;
}
</file>

<file path="src/services/__tests__/gemini.service.test.ts">
import { jest, beforeEach, describe, it, expect } from '@jest/globals';
import { GeminiService } from '../gemini.service.js';
import { logger } from '../../utils/logger.js';
// Mock the Google Generative AI SDK
jest.mock('@google/generative-ai', () => {
  return {
    GoogleGenerativeAI: jest.fn().mockImplementation(() => ({
      getGenerativeModel: jest.fn().mockImplementation(() => ({
        generateContent: jest.fn().mockImplementation(async () => ({
          response: {
            text: () => 'Test response'
          }
        }))
      }))
    }))
  };
});
// Mock RateLimiter
jest.mock('../../utils/rate-limiter', () => ({
  RateLimiter: jest.fn().mockImplementation(() => ({
    acquireToken: jest.fn().mockResolvedValue(undefined)
  }))
}));
// Mock logger
jest.mock('../../utils/logger', () => ({
  logger: {
    debug: jest.fn(),
    info: jest.fn(),
    warn: jest.fn(),
    error: jest.fn()
  }
}));
// Import the mocked dependencies
const { GoogleGenerativeAI } = await import('@google/generative-ai');
const { RateLimiter } = await import('../../utils/rate-limiter.js');
describe('GeminiService', () => {
  let geminiService: GeminiService;
  const mockApiKey = 'test-api-key';
  beforeEach(() => {
    jest.clearAllMocks();
    // Initialize service with test API key
    geminiService = new GeminiService({
      apiKey: mockApiKey,
      rateLimitConfig: {
        maxTokens: 60,
        refillRate: 0.2
      }
    });
  });
  describe('initialize', () => {
    it('should create a GoogleGenerativeAI instance', async () => {
      await geminiService.initialize();
      expect(GoogleGenerativeAI).toHaveBeenCalledWith(mockApiKey);
    });
    it('should create a RateLimiter instance', async () => {
      await geminiService.initialize();
      expect(RateLimiter).toHaveBeenCalledWith('gemini', {
        maxTokens: 60,
        refillRate: 0.2
      });
    });
    it('should log an error if initialization fails', async () => {
      (GoogleGenerativeAI as jest.Mock).mockImplementationOnce(() => {
        throw new Error('Google AI initialization error');
      });
      await expect(geminiService.initialize()).rejects.toThrow('Failed to initialize GeminiService');
      expect(logger.error).toHaveBeenCalled();
    });
  });
  describe('analyzeRepository', () => {
    let mockGenerateContent: jest.Mock;
    beforeEach(async () => {
      await geminiService.initialize();
      mockGenerateContent = (GoogleGenerativeAI as jest.Mock).mock.results[0].value.getGenerativeModel().generateContent;
    });
    it('should acquire a token before making API request', async () => {
      await geminiService.analyzeRepository({
        query: 'Analyze this code',
        codeContent: 'function test() { return true; }'
      });
      // Check that acquireToken was called before the API request
      const rateLimiterInstance = (RateLimiter as jest.Mock).mock.results[0].value;
      expect(rateLimiterInstance.acquireToken).toHaveBeenCalledWith(5);
      expect(mockGenerateContent).toHaveBeenCalledAfter(rateLimiterInstance.acquireToken as jest.Mock);
    });
    it('should call Gemini API with correct parameters', async () => {
      await geminiService.analyzeRepository({
        query: 'Analyze this code',
        codeContent: 'function test() { return true; }'
      });
      expect(mockGenerateContent).toHaveBeenCalledWith({
        contents: expect.objectContaining({
          parts: expect.arrayContaining([
            expect.objectContaining({
              text: expect.stringContaining('Analyze this code')
            }),
            expect.objectContaining({
              text: expect.stringContaining('function test() { return true; }')
            })
          ])
        }),
        generationConfig: expect.objectContaining({
          temperature: 0.2
        })
      });
    });
    it('should return analysis result from the API', async () => {
      mockGenerateContent.mockResolvedValueOnce({
        response: {
          text: () => 'Code analysis: This is a simple function'
        }
      });
      const result = await geminiService.analyzeRepository({
        query: 'Analyze this code',
        codeContent: 'function test() { return true; }'
      });
      expect(result).toEqual({
        analysis: 'Code analysis: This is a simple function'
      });
    });
    it('should handle rate limiting errors', async () => {
      // Mock rate limiter throwing an error
      const rateLimiterInstance = (RateLimiter as jest.Mock).mock.results[0].value;
      (rateLimiterInstance.acquireToken as jest.Mock).mockRejectedValueOnce(
        new Error('Rate limit exceeded')
      );
      await expect(geminiService.analyzeRepository({
        query: 'Analyze this code',
        codeContent: 'function test() { return true; }'
      })).rejects.toThrow('Rate limit exceeded for Gemini API: Rate limit exceeded');
      expect(logger.warn).toHaveBeenCalled();
      // The API request should not be made if rate limit is exceeded
      expect(mockGenerateContent).not.toHaveBeenCalled();
    });
    it('should handle API errors gracefully', async () => {
      mockGenerateContent.mockRejectedValueOnce(new Error('API error'));
      await expect(geminiService.analyzeRepository({
        query: 'Analyze this code',
        codeContent: 'function test() { return true; }'
      })).rejects.toThrow('Gemini API request failed: API error');
      expect(logger.error).toHaveBeenCalled();
    });
    it('should use different token costs based on code content size', async () => {
      // Short content (5 tokens - base cost)
      await geminiService.analyzeRepository({
        query: 'Analyze',
        codeContent: 'function test() { return true; }'
      });
      const rateLimiterInstance = (RateLimiter as jest.Mock).mock.results[0].value;
      expect(rateLimiterInstance.acquireToken).toHaveBeenLastCalledWith(5);
      // Medium content (10 tokens)
      const mediumCode = 'function test() {\n' + '  // Some comment\n'.repeat(10) + '  return true;\n}';
      await geminiService.analyzeRepository({
        query: 'Analyze',
        codeContent: mediumCode
      });
      expect(rateLimiterInstance.acquireToken).toHaveBeenLastCalledWith(10);
      // Large content (20 tokens)
      const largeCode = 'function test() {\n' + '  // Some comment\n'.repeat(50) + '  return true;\n}';
      await geminiService.analyzeRepository({
        query: 'Analyze',
        codeContent: largeCode
      });
      expect(rateLimiterInstance.acquireToken).toHaveBeenLastCalledWith(20);
    });
  });
  describe('generateContent', () => {
    let mockGenerateContent: jest.Mock;
    beforeEach(async () => {
      await geminiService.initialize();
      mockGenerateContent = (GoogleGenerativeAI as jest.Mock).mock.results[0].value.getGenerativeModel().generateContent;
    });
    it('should acquire a token before making API request', async () => {
      await geminiService.generateContent({
        prompt: 'Generate documentation'
      });
      // Check that acquireToken was called before the API request
      const rateLimiterInstance = (RateLimiter as jest.Mock).mock.results[0].value;
      expect(rateLimiterInstance.acquireToken).toHaveBeenCalledWith(3);
      expect(mockGenerateContent).toHaveBeenCalledAfter(rateLimiterInstance.acquireToken as jest.Mock);
    });
    it('should call Gemini API with correct parameters', async () => {
      await geminiService.generateContent({
        prompt: 'Generate documentation',
        temperature: 0.8
      });
      expect(mockGenerateContent).toHaveBeenCalledWith({
        contents: expect.objectContaining({
          parts: expect.arrayContaining([
            expect.objectContaining({
              text: 'Generate documentation'
            })
          ])
        }),
        generationConfig: expect.objectContaining({
          temperature: 0.8
        })
      });
    });
    it('should return generated content from the API', async () => {
      mockGenerateContent.mockResolvedValueOnce({
        response: {
          text: () => '# Documentation\n\nThis is a sample documentation.'
        }
      });
      const result = await geminiService.generateContent({
        prompt: 'Generate documentation'
      });
      expect(result).toEqual({
        content: '# Documentation\n\nThis is a sample documentation.'
      });
    });
    it('should handle rate limiting errors', async () => {
      // Mock rate limiter throwing an error
      const rateLimiterInstance = (RateLimiter as jest.Mock).mock.results[0].value;
      (rateLimiterInstance.acquireToken as jest.Mock).mockRejectedValueOnce(
        new Error('Rate limit exceeded')
      );
      await expect(geminiService.generateContent({
        prompt: 'Generate documentation'
      })).rejects.toThrow('Rate limit exceeded for Gemini API: Rate limit exceeded');
      expect(logger.warn).toHaveBeenCalled();
      // The API request should not be made if rate limit is exceeded
      expect(mockGenerateContent).not.toHaveBeenCalled();
    });
    it('should handle API errors gracefully', async () => {
      mockGenerateContent.mockRejectedValueOnce(new Error('API error'));
      await expect(geminiService.generateContent({
        prompt: 'Generate documentation'
      })).rejects.toThrow('Gemini API request failed: API error');
      expect(logger.error).toHaveBeenCalled();
    });
  });
});
</file>

<file path="src/services/__tests__/perplexity.service.test.ts">
import { jest, beforeEach, describe, it, expect } from '@jest/globals';
import { PerplexityService } from '../perplexity.service.js';
import { logger } from '../../utils/logger.js';
// Mock the fetch API
global.fetch = jest.fn();
// Mock RateLimiter
jest.mock('../../utils/rate-limiter', () => ({
  RateLimiter: jest.fn().mockImplementation(() => ({
    acquireToken: jest.fn().mockResolvedValue(undefined)
  }))
}));
// Mock logger
jest.mock('../../utils/logger', () => ({
  logger: {
    debug: jest.fn(),
    info: jest.fn(),
    warn: jest.fn(),
    error: jest.fn()
  }
}));
// Import the mocked RateLimiter
const { RateLimiter } = await import('../../utils/rate-limiter.js');
describe('PerplexityService', () => {
  let perplexityService: PerplexityService;
  const mockApiKey = 'test-api-key';
  beforeEach(() => {
    jest.clearAllMocks();
    (global.fetch as jest.Mock).mockClear();
    // Initialize service with test API key
    perplexityService = new PerplexityService({
      apiKey: mockApiKey,
      rateLimitConfig: {
        maxTokens: 10,
        refillRate: 1
      }
    });
  });
  describe('initialize', () => {
    it('should create a RateLimiter instance', async () => {
      await perplexityService.initialize();
      expect(RateLimiter).toHaveBeenCalledWith('perplexity', {
        maxTokens: 10,
        refillRate: 1
      });
    });
    it('should log an error if initialization fails', async () => {
      (RateLimiter as jest.Mock).mockImplementationOnce(() => {
        throw new Error('Rate limiter error');
      });
      await expect(perplexityService.initialize()).rejects.toThrow('Failed to initialize PerplexityService');
      expect(logger.error).toHaveBeenCalled();
    });
  });
  describe('search', () => {
    beforeEach(async () => {
      await perplexityService.initialize();
    });
    it('should acquire a token before making API request', async () => {
      // Mock fetch response
      (global.fetch as jest.Mock).mockResolvedValueOnce({
        ok: true,
        json: jest.fn().mockResolvedValue({
          answer: 'Test answer',
          search_results: [
            { title: 'Result 1', url: 'https://example.com/1' }
          ]
        })
      });
      await perplexityService.search('test query');
      // Check that acquireToken was called before the API request
      const rateLimiterInstance = (RateLimiter as jest.Mock).mock.results[0].value;
      expect(rateLimiterInstance.acquireToken).toHaveBeenCalledWith(1);
      expect(global.fetch).toHaveBeenCalledAfter(rateLimiterInstance.acquireToken as jest.Mock);
    });
    it('should make API request with correct parameters', async () => {
      // Mock fetch response
      (global.fetch as jest.Mock).mockResolvedValueOnce({
        ok: true,
        json: jest.fn().mockResolvedValue({
          answer: 'Test answer',
          search_results: [
            { title: 'Result 1', url: 'https://example.com/1' }
          ]
        })
      });
      await perplexityService.search('test query');
      expect(global.fetch).toHaveBeenCalledWith(
        'https://api.perplexity.ai/search',
        expect.objectContaining({
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${mockApiKey}`
          },
          body: JSON.stringify({
            query: 'test query'
          })
        })
      );
    });
    it('should return formatted search results', async () => {
      // Mock fetch response
      (global.fetch as jest.Mock).mockResolvedValueOnce({
        ok: true,
        json: jest.fn().mockResolvedValue({
          answer: 'Test answer',
          search_results: [
            { 
              title: 'Result 1', 
              url: 'https://example.com/1',
              snippet: 'This is a snippet'
            }
          ]
        })
      });
      const result = await perplexityService.search('test query');
      expect(result).toEqual({
        answer: 'Test answer',
        results: [
          {
            title: 'Result 1',
            url: 'https://example.com/1',
            snippet: 'This is a snippet'
          }
        ]
      });
    });
    it('should handle API errors gracefully', async () => {
      // Mock fetch error response
      (global.fetch as jest.Mock).mockResolvedValueOnce({
        ok: false,
        status: 429,
        statusText: 'Too Many Requests'
      });
      await expect(perplexityService.search('test query')).rejects.toThrow(
        'Perplexity API request failed: 429 Too Many Requests'
      );
      expect(logger.error).toHaveBeenCalled();
    });
    it('should handle network errors gracefully', async () => {
      // Mock fetch network error
      (global.fetch as jest.Mock).mockRejectedValueOnce(new Error('Network error'));
      await expect(perplexityService.search('test query')).rejects.toThrow(
        'Failed to make request to Perplexity API: Network error'
      );
      expect(logger.error).toHaveBeenCalled();
    });
    it('should handle rate limiting errors', async () => {
      // Mock rate limiter throwing an error
      const rateLimiterInstance = (RateLimiter as jest.Mock).mock.results[0].value;
      (rateLimiterInstance.acquireToken as jest.Mock).mockRejectedValueOnce(
        new Error('Rate limit exceeded')
      );
      await expect(perplexityService.search('test query')).rejects.toThrow(
        'Rate limit exceeded for Perplexity API: Rate limit exceeded'
      );
      expect(logger.warn).toHaveBeenCalled();
      // The API request should not be made if rate limit is exceeded
      expect(global.fetch).not.toHaveBeenCalled();
    });
    it('should use different token costs based on query complexity', async () => {
      // Mock fetch response
      (global.fetch as jest.Mock).mockResolvedValue({
        ok: true,
        json: jest.fn().mockResolvedValue({
          answer: 'Test answer',
          search_results: []
        })
      });
      const rateLimiterInstance = (RateLimiter as jest.Mock).mock.results[0].value;
      // Short query (1 token)
      await perplexityService.search('short query');
      expect(rateLimiterInstance.acquireToken).toHaveBeenLastCalledWith(1);
      // Medium query (2 tokens)
      await perplexityService.search('this is a medium length query with multiple words');
      expect(rateLimiterInstance.acquireToken).toHaveBeenLastCalledWith(2);
      // Long query (3 tokens)
      const longQuery = 'this is a very long query ' + 'with lots of words '.repeat(20);
      await perplexityService.search(longQuery);
      expect(rateLimiterInstance.acquireToken).toHaveBeenLastCalledWith(3);
    });
  });
});
</file>

<file path="src/services/browser.service.ts">
import * as playwright from 'playwright';
import * as path from 'path';
import { logger } from '../utils/logger.js';
import { fileStorageService } from './file-storage.service.js';
export interface BrowserOptions {
  headless?: boolean;
  timeout?: number;
  viewport?: { width: number; height: number };
  userAgent?: string;
}
export interface PageResult {
  url: string;
  title: string;
  content?: string;
  screenshot?: string;
  consoleMessages?: string[];
  networkRequests?: Array<{
    url: string;
    method: string;
    status?: number;
    contentType?: string;
  }>;
}
export class BrowserService {
  private browser: playwright.Browser | null = null;
  private context: playwright.BrowserContext | null = null;
  /**
   * Initialize browser instance
   * @param options Browser configuration options
   */
  async initBrowser(options: BrowserOptions = {}): Promise<void> {
    try {
      if (this.browser) {
        await this.closeBrowser();
      }
      logger.info('Initializing browser', { options });
      this.browser = await playwright.chromium.launch({
        headless: options.headless !== false, // Default to headless: true
      });
      this.context = await this.browser.newContext({
        viewport: options.viewport || { width: 1280, height: 720 },
        userAgent: options.userAgent
      });
      logger.debug('Browser initialized successfully');
    } catch (error) {
      logger.error('Failed to initialize browser', {
        error: error instanceof Error ? error.message : String(error)
      });
      throw new Error(`Failed to initialize browser: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  /**
   * Navigate to a URL and collect page information
   * @param url The URL to navigate to
   * @param options Options for page navigation and data collection
   * @returns Page result with collected information
   */
  async navigateAndCollect(url: string, options: {
    captureScreenshot?: boolean;
    screenshotPath?: string;
    captureHtml?: boolean;
    captureConsole?: boolean;
    captureNetwork?: boolean;
    waitForSelector?: string;
    waitForTimeout?: number;
    executeScript?: string;
  } = {}): Promise<PageResult> {
    try {
      if (!this.browser || !this.context) {
        await this.initBrowser();
      }
      const page = await this.context!.newPage();
      const consoleMessages: string[] = [];
      const networkRequests: PageResult['networkRequests'] = [];
      // Set up listeners if needed
      if (options.captureConsole) {
        page.on('console', message => {
          consoleMessages.push(`[${message.type()}] ${message.text()}`);
        });
      }
      if (options.captureNetwork) {
        page.on('request', request => {
          networkRequests.push({
            url: request.url(),
            method: request.method()
          });
        });
        page.on('response', response => {
          const request = response.request();
          const existingRequest = networkRequests.find(r => r.url === request.url() && r.method === request.method());
          if (existingRequest) {
            existingRequest.status = response.status();
            existingRequest.contentType = response.headers()['content-type'];
          }
        });
      }
      // Navigate to the URL
      logger.info('Navigating to URL', { url });
      await page.goto(url, { waitUntil: 'domcontentloaded' });
      // Wait for selector if specified
      if (options.waitForSelector) {
        logger.debug('Waiting for selector', { selector: options.waitForSelector });
        await page.waitForSelector(options.waitForSelector);
      }
      // Wait for timeout if specified
      if (options.waitForTimeout) {
        logger.debug('Waiting for timeout', { ms: options.waitForTimeout });
        await page.waitForTimeout(options.waitForTimeout);
      }
      // Execute custom script if provided
      let scriptResult: any;
      if (options.executeScript) {
        logger.debug('Executing custom script');
        scriptResult = await page.evaluate(options.executeScript);
      }
      // Collect page information
      const title = await page.title();
      // Capture HTML if requested
      let content: string | undefined;
      if (options.captureHtml) {
        content = await page.content();
      }
      // Capture screenshot if requested
      let screenshotPath: string | undefined;
      if (options.captureScreenshot) {
        const timestamp = Date.now();
        const filename = options.screenshotPath || path.join('screenshots', `screenshot-${timestamp}.png`);
        logger.debug('Capturing screenshot', { path: filename });
        const screenshotBuffer = await page.screenshot({ fullPage: true });
        screenshotPath = await fileStorageService.saveToFile(filename, screenshotBuffer.toString('base64'), {
          createDirectory: true
        });
      }
      // Close the page to free resources
      await page.close();
      return {
        url,
        title,
        content,
        screenshot: screenshotPath,
        consoleMessages: options.captureConsole ? consoleMessages : undefined,
        networkRequests: options.captureNetwork ? networkRequests : undefined
      };
    } catch (error) {
      logger.error('Error during page navigation', {
        error: error instanceof Error ? error.message : String(error),
        url
      });
      throw new Error(`Failed to navigate to ${url}: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  /**
   * Fill a form and submit it
   * @param url The URL of the form
   * @param formData Map of form field selectors to values
   * @param options Additional options
   * @returns Result of the form submission
   */
  async fillForm(url: string, formData: Record<string, string>, options: {
    submitSelector?: string;
    waitForNavigation?: boolean;
    captureScreenshot?: boolean;
    screenshotPath?: string;
  } = {}): Promise<PageResult> {
    try {
      if (!this.browser || !this.context) {
        await this.initBrowser();
      }
      const page = await this.context!.newPage();
      // Navigate to the URL
      logger.info('Navigating to form URL', { url });
      await page.goto(url, { waitUntil: 'domcontentloaded' });
      // Fill form fields
      for (const [selector, value] of Object.entries(formData)) {
        logger.debug(`Filling form field: ${selector}`);
        await page.fill(selector, value);
      }
      // Capture screenshot before submit if requested
      let screenshotBeforePath: string | undefined;
      if (options.captureScreenshot) {
        const timestamp = Date.now();
        const filename = options.screenshotPath 
          ? `${options.screenshotPath}-before.png`
          : path.join('screenshots', `form-before-${timestamp}.png`);
        logger.debug('Capturing form before submission', { path: filename });
        const screenshotBuffer = await page.screenshot({ fullPage: true });
        screenshotBeforePath = await fileStorageService.saveToFile(filename, screenshotBuffer.toString('base64'), {
          createDirectory: true
        });
      }
      // Submit the form
      if (options.submitSelector) {
        logger.debug('Clicking submit button', { selector: options.submitSelector });
        await page.click(options.submitSelector);
      } else {
        logger.debug('Pressing Enter to submit form');
        await page.keyboard.press('Enter');
      }
      // Wait for navigation if requested
      if (options.waitForNavigation) {
        logger.debug('Waiting for navigation after form submission');
        await page.waitForLoadState('domcontentloaded');
      }
      // Capture post-submission information
      const title = await page.title();
      const currentUrl = page.url();
      // Capture screenshot after submit if requested
      let screenshotAfterPath: string | undefined;
      if (options.captureScreenshot) {
        const timestamp = Date.now();
        const filename = options.screenshotPath 
          ? `${options.screenshotPath}-after.png`
          : path.join('screenshots', `form-after-${timestamp}.png`);
        logger.debug('Capturing form after submission', { path: filename });
        const screenshotBuffer = await page.screenshot({ fullPage: true });
        screenshotAfterPath = await fileStorageService.saveToFile(filename, screenshotBuffer.toString('base64'), {
          createDirectory: true
        });
      }
      // Close the page
      await page.close();
      return {
        url: currentUrl,
        title,
        screenshot: screenshotAfterPath || screenshotBeforePath
      };
    } catch (error) {
      logger.error('Error during form submission', {
        error: error instanceof Error ? error.message : String(error),
        url
      });
      throw new Error(`Failed to submit form at ${url}: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  /**
   * Extract data from a webpage
   * @param url The URL to extract data from
   * @param selectors Map of data keys to CSS selectors
   * @returns Extracted data
   */
  async extractData(url: string, selectors: Record<string, string>): Promise<Record<string, string | string[]>> {
    try {
      if (!this.browser || !this.context) {
        await this.initBrowser();
      }
      const page = await this.context!.newPage();
      // Navigate to the URL
      logger.info('Navigating to URL for data extraction', { url });
      await page.goto(url, { waitUntil: 'domcontentloaded' });
      // Extract data
      const result: Record<string, string | string[]> = {};
      for (const [key, selector] of Object.entries(selectors)) {
        logger.debug(`Extracting data for: ${key}`, { selector });
        // Check if this is a multi-element selector
        if (selector.startsWith('MULTI:')) {
          const actualSelector = selector.substring(6);
          const elements = await page.$$(actualSelector);
          const textValues = await Promise.all(
            elements.map(element => element.textContent())
          );
          result[key] = textValues.filter(Boolean) as string[];
        } else {
          const element = await page.$(selector);
          if (element) {
            const text = await element.textContent();
            result[key] = text || '';
          } else {
            result[key] = '';
          }
        }
      }
      // Close the page
      await page.close();
      return result;
    } catch (error) {
      logger.error('Error during data extraction', {
        error: error instanceof Error ? error.message : String(error),
        url
      });
      throw new Error(`Failed to extract data from ${url}: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  /**
   * Close the browser instance
   */
  async closeBrowser(): Promise<void> {
    try {
      if (this.context) {
        await this.context.close();
        this.context = null;
      }
      if (this.browser) {
        await this.browser.close();
        this.browser = null;
        logger.info('Browser closed successfully');
      }
    } catch (error) {
      logger.error('Error closing browser', {
        error: error instanceof Error ? error.message : String(error)
      });
    }
  }
}
// Export singleton instance
export const browserService = new BrowserService();
</file>

<file path="src/services/file-storage.service.ts">
import * as fs from 'fs/promises';
import * as path from 'path';
import { logger } from '../utils/logger.js';
export interface SaveOptions {
  createDirectory?: boolean;
  encoding?: BufferEncoding;
  flag?: string;
}
export interface ReadOptions {
  encoding?: BufferEncoding;
  flag?: string;
}
export class FileStorageService {
  /**
   * Save content to a file
   * @param filePath The path to save the file to
   * @param content The content to save
   * @param options Additional options for saving
   * @returns The absolute path to the saved file
   */
  async saveToFile(filePath: string, content: string, options: SaveOptions = {}): Promise<string> {
    try {
      const normalizedPath = path.normalize(filePath);
      const dirPath = path.dirname(normalizedPath);
      // Create directory if needed
      if (options.createDirectory) {
        await fs.mkdir(dirPath, { recursive: true });
      }
      // Write the file
      await fs.writeFile(normalizedPath, content, {
        encoding: options.encoding || 'utf-8',
        flag: options.flag || 'w'
      });
      logger.info('File saved successfully', { path: normalizedPath });
      return path.resolve(normalizedPath);
    } catch (error) {
      logger.error('Failed to save file', {
        error: error instanceof Error ? error.message : String(error),
        path: filePath
      });
      throw new Error(`Failed to save file: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  /**
   * Append content to a file
   * @param filePath The path to append to
   * @param content The content to append
   * @param options Additional options
   * @returns The absolute path to the file
   */
  async appendToFile(filePath: string, content: string, options: SaveOptions = {}): Promise<string> {
    return this.saveToFile(filePath, content, {
      ...options,
      flag: 'a'
    });
  }
  /**
   * Read content from a file
   * @param filePath The path to read from
   * @param options Additional options for reading
   * @returns The file content
   */
  async readFromFile(filePath: string, options: ReadOptions = {}): Promise<string> {
    try {
      const normalizedPath = path.normalize(filePath);
      const content = await fs.readFile(normalizedPath, {
        encoding: options.encoding || 'utf-8',
        flag: options.flag || 'r'
      });
      logger.debug('File read successfully', { path: normalizedPath });
      return content;
    } catch (error) {
      logger.error('Failed to read file', {
        error: error instanceof Error ? error.message : String(error),
        path: filePath
      });
      throw new Error(`Failed to read file: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  /**
   * Check if a file exists
   * @param filePath The path to check
   * @returns True if the file exists, false otherwise
   */
  async fileExists(filePath: string): Promise<boolean> {
    try {
      const normalizedPath = path.normalize(filePath);
      await fs.access(normalizedPath);
      return true;
    } catch {
      return false;
    }
  }
  /**
   * Delete a file
   * @param filePath The path to delete
   * @returns True if the file was deleted, false if it didn't exist
   */
  async deleteFile(filePath: string): Promise<boolean> {
    try {
      const normalizedPath = path.normalize(filePath);
      if (await this.fileExists(normalizedPath)) {
        await fs.unlink(normalizedPath);
        logger.info('File deleted successfully', { path: normalizedPath });
        return true;
      }
      logger.debug('File does not exist, no deletion needed', { path: normalizedPath });
      return false;
    } catch (error) {
      logger.error('Failed to delete file', {
        error: error instanceof Error ? error.message : String(error),
        path: filePath
      });
      throw new Error(`Failed to delete file: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
}
// Export singleton instance
export const fileStorageService = new FileStorageService();
</file>

<file path="src/services/gemini.service.ts">
import axios from 'axios';
import { config } from '../config/index.js';
import { logger } from '../utils/logger.js';
import { RateLimiter } from '../utils/rate-limiter.js';
const GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent";
export interface GeminiRequestOptions {
  maxOutputTokens?: number;
  temperature?: number;
  timeout?: number;
}
export interface GeminiResponse {
  content: string;
  metadata?: {
    promptTokens?: number;
    outputTokens?: number;
    totalTokens?: number;
    modelVersion?: string;
  }
}
export class GeminiService {
  private apiKey: string;
  private rateLimiter: RateLimiter;
  constructor(apiKey?: string) {
    this.apiKey = apiKey || config.googleApiKey || '';
    // Create a rate limiter for Google Gemini API
    // Default values: 60 requests per minute (1 per second)
    this.rateLimiter = new RateLimiter('gemini-api', {
      maxTokens: 60,
      refillRate: 1, // 1 token per second
      waitForTokens: true,
      maxWaitTime: 60000 // 1 minute max wait time
    });
    logger.debug("Gemini service initialized with rate limiter", {
      service: 'gemini',
      maxTokens: 60,
      refillRate: 1
    });
  }
  /**
   * Generate content using Google Gemini API
   * @param prompt The prompt to send to Gemini
   * @param options Additional options for the API call
   * @returns The generated content and metadata
   */
  async generateContent(prompt: string, options: GeminiRequestOptions = {}): Promise<GeminiResponse> {
    // Check for API key
    if (!this.apiKey) {
      const error = new Error("Google API Key not found in environment variables (GOOGLE_API_KEY)");
      logger.error("API key missing", { service: 'gemini' });
      throw error;
    }
    try {
      // Acquire a token before making the API request
      logger.debug("Acquiring rate limit token for Gemini API", { promptLength: prompt.length });
      await this.rateLimiter.acquireToken();
      logger.info("Calling Gemini API", { promptLength: prompt.length });
      const requestBody = {
        contents: [{
          parts: [{
            text: prompt
          }]
        }],
        generationConfig: {
          maxOutputTokens: options.maxOutputTokens,
          temperature: options.temperature
        }
      };
      // Remove undefined values from generationConfig
      Object.keys(requestBody.generationConfig).forEach(key => {
        if (requestBody.generationConfig[key] === undefined) {
          delete requestBody.generationConfig[key];
        }
      });
      const response = await axios.post(
        `${GEMINI_API_URL}?key=${this.apiKey}`,
        requestBody,
        { timeout: options.timeout || 30000 } // 30 second timeout by default
      );
      // Handle empty or invalid response
      if (!response.data?.candidates?.[0]?.content?.parts?.[0]?.text) {
        logger.warn("Unexpected Gemini API response format", { responseData: response.data });
        throw new Error("Invalid response format from Gemini API");
      }
      const content = response.data.candidates[0].content.parts[0].text;
      // Extract metadata if available
      const metadata = {};
      if (response.data.usageMetadata) {
        metadata.promptTokens = response.data.usageMetadata.promptTokenCount;
        metadata.outputTokens = response.data.usageMetadata.candidatesTokenCount;
        metadata.totalTokens = response.data.usageMetadata.totalTokenCount;
      }
      logger.debug("Received response from Gemini API", { contentLength: content.length });
      return {
        content,
        metadata
      };
    } catch (error) {
      logger.error("Error calling Gemini API", {
        error: error instanceof Error ? error.message : String(error),
        promptLength: prompt.length
      });
      if (axios.isAxiosError(error)) {
        const errorMessage = error.response?.data?.error || error.message;
        logger.error("Axios error details", {
          status: error.response?.status,
          data: error.response?.data
        });
        if (error.response?.status === 400) {
          throw new Error(`Invalid request to Gemini API: ${errorMessage}`);
        } else if (error.response?.status === 401 || error.response?.status === 403) {
          throw new Error(`Authentication error with Gemini API: ${errorMessage}`);
        } else if (error.response?.status === 429) {
          throw new Error(`Rate limit exceeded for Gemini API: ${errorMessage}`);
        } else if (error.response?.status >= 500) {
          throw new Error(`Gemini API server error: ${errorMessage}`);
        }
        throw new Error(`Failed to communicate with Gemini API: ${errorMessage}`);
      }
      throw new Error(`Failed to generate content with Gemini: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
}
// Export a singleton instance
export const geminiService = new GeminiService(config.googleApiKey);
</file>

<file path="src/services/perplexity.service.ts">
import axios from 'axios';
import { config } from '../config/index.js';
import { logger } from '../utils/logger.js';
import { RateLimiter } from '../utils/rate-limiter.js';
const PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions";
const PERPLEXITY_MODEL = "codellama-34b-instruct";
export interface SearchResult {
  content: string;
  metadata?: {
    model: string;
    tokenUsage?: {
      promptTokens?: number;
      completionTokens?: number;
      totalTokens?: number;
    }
  }
}
export class PerplexityService {
  private apiKey: string;
  private rateLimiter: RateLimiter;
  constructor(apiKey?: string) {
    this.apiKey = apiKey || config.perplexityApiKey || '';
    // Create a rate limiter for Perplexity API
    // Default values: 20 requests per minute (1 every 3 seconds)
    this.rateLimiter = new RateLimiter('perplexity-api', {
      maxTokens: 20,
      refillRate: 0.33,  // 1 token per 3 seconds
      waitForTokens: true,
      maxWaitTime: 60000 // 1 minute max wait time
    });
    logger.debug("Perplexity service initialized with rate limiter", {
      service: 'perplexity',
      maxTokens: 20,
      refillRate: 0.33
    });
  }
  /**
   * Performs a web search using Perplexity AI
   * @param query The search query
   * @param options Additional options for the search
   * @returns The search results
   */
  async search(query: string, options: { maxTokens?: number, timeout?: number } = {}): Promise<SearchResult> {
    // Handle test environment
    if (config.env === 'test' && !this.apiKey) {
      logger.warn("Perplexity API key not set in test environment, returning mock response", { service: 'perplexity' });
      return { 
        content: "Mock search results for testing",
        metadata: {
          model: PERPLEXITY_MODEL
        }
      };
    }
    // Check for API key in non-test environment
    if (!this.apiKey) {
      const error = new Error("Perplexity API key not set");
      logger.error("API key missing", { service: 'perplexity' });
      throw error;
    }
    try {
      // Acquire a token before making the API request
      logger.debug("Acquiring rate limit token for Perplexity API", { query });
      await this.rateLimiter.acquireToken();
      logger.info("Performing web search", { query });
      const response = await axios.post(PERPLEXITY_API_URL, {
        model: PERPLEXITY_MODEL,
        messages: [{ role: "user", content: query }],
        max_tokens: options.maxTokens || 150
      }, {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        timeout: options.timeout || 10000 // 10 second timeout by default
      });
      if (!response.data?.choices?.[0]?.message?.content) {
        logger.warn("Unexpected API response format", { 
          responseData: response.data,
          query 
        });
        throw new Error("Invalid response format from Perplexity API");
      }
      // Extract additional metadata if available
      const metadata: SearchResult['metadata'] = {
        model: response.data.model || PERPLEXITY_MODEL
      };
      if (response.data.usage) {
        metadata.tokenUsage = {
          promptTokens: response.data.usage.prompt_tokens,
          completionTokens: response.data.usage.completion_tokens,
          totalTokens: response.data.usage.total_tokens
        };
      }
      return {
        content: response.data.choices[0].message.content,
        metadata
      };
    } catch (error) {
      logger.error("Web search failed", {
        error: error instanceof Error ? error.message : String(error),
        query,
        stack: error instanceof Error ? error.stack : undefined
      });
      if (axios.isAxiosError(error)) {
        const status = error.response?.status;
        const errorMessage = error.response?.data?.error || error.message;
        logger.error("Axios error details", {
          status,
          data: error.response?.data,
          config: error.config
        });
        if (status === 401 || status === 403) {
          throw new Error("Invalid or expired API key");
        } else if (status === 429) {
          throw new Error("Rate limit exceeded");
        }
        throw new Error(`Web search failed: ${errorMessage}`);
      }
      throw new Error(`Web search failed: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
}
// Export a singleton instance
export const perplexityService = new PerplexityService(config.perplexityApiKey);
</file>

<file path="src/services/README.md">
# Services Directory

## Purpose

The `services` directory is intended to contain service modules that handle business logic and orchestration between data sources and the application. Services act as an abstraction layer that separates the tools (which handle the MCP protocol interfaces) from the underlying implementation details.

## Design Pattern

Services follow these principles:

1. **Single Responsibility**: Each service handles a specific domain or external integration
2. **Abstraction**: Services hide implementation details from tools
3. **Reusability**: Multiple tools can use the same service
4. **Testability**: Services can be mocked for testing tools

## Planned Services

- **PerplexityService**: Handle all Perplexity AI API interactions
- **GeminiService**: Handle all Google Gemini API interactions
- **FileStorageService**: Handle file system operations
- **BrowserService**: Handle browser automation operations

## Implementation Status

- [ ] PerplexityService (To be migrated from web-search tool)
- [ ] GeminiService (To be migrated from repo-analysis tool)
- [ ] FileStorageService (To be implemented)
- [ ] BrowserService (To be implemented)

## Usage Example

```typescript
// Example of how a tool would use a service
import { perplexityService } from '../services/perplexity.service.js';

// In tool's execute method
const searchResults = await perplexityService.search(query);
```
</file>

<file path="src/test-client.ts">
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import { z } from 'zod';
import { spawn } from 'child_process';
import { logger } from './utils/logger.js';
import { config } from './config/index.js';
// Define response schemas
const WebSearchResponseSchema = z.object({
    result: z.object({
        searchResults: z.string(),
        savedToFile: z.string().optional()
    })
});
const RepoAnalysisResponseSchema = z.object({
    result: z.object({
        analysis: z.string(),
        codeInsights: z.object({
            architecture: z.array(z.string()).optional(),
            dependencies: z.array(z.string()).optional(),
            patterns: z.array(z.string()).optional(),
        }).optional(),
        documentationInsights: z.object({
            coverage: z.number().optional(),
            quality: z.string().optional(),
            recommendations: z.array(z.string()).optional(),
        }).optional(),
    })
});
const HealthCheckResponseSchema = z.object({
    result: z.object({
        status: z.enum(['healthy', 'unhealthy']),
        uptime: z.number(),
        timestamp: z.string(),
        version: z.string()
    })
});
async function main() {
    // Initialize transport with required parameters
    const transport = new StdioClientTransport({
        command: 'node',
        args: ['dist/server.js']
    });
    const client = new Client({
        name: "test-client",
        version: "0.1.0"
    }, {
        capabilities: {}
    });
    try {
        logger.info("Connecting to MCP server...");
        await client.connect(transport);
        logger.info("Connected to MCP server");
        // Test health check
        logger.info("Testing health check tool...");
        const healthResponse = await client.request({
            method: "tool/execute",
            params: {
                toolName: 'health-check',
                version: '0.1.0',
                arguments: {}
            }
        }, HealthCheckResponseSchema);
        logger.info("Health check response:", healthResponse);
        // Test web search
        logger.info("Testing web search tool...");
        const webSearchResponse = await client.request({
            method: "tool/execute",
            params: {
                toolName: 'web-search',
                version: '0.1.0',
                arguments: {
                    query: "What is MCP (Model Context Protocol)?",
                    saveToFile: true
                }
            }
        }, WebSearchResponseSchema);
        logger.info("Web search response:", webSearchResponse);
        // Test repository analysis
        logger.info("Testing repository analysis tool...");
        const repoAnalysisResponse = await client.request({
            method: "tool/execute",
            params: {
                toolName: 'repo-analysis',
                version: '0.1.0',
                arguments: {
                    query: "What is the architecture of this project?",
                    analysisType: "both",
                    maxDepth: 2
                }
            }
        }, RepoAnalysisResponseSchema);
        logger.info("Repository analysis response:", repoAnalysisResponse);
    } catch (error) {
        if (error instanceof Error) {
            logger.error("Error occurred", { error: error.message });
        } else {
            logger.error("Unknown error occurred", { error: String(error) });
        }
    } finally {
        client.close();
    }
}
main().catch((error) => {
    if (error instanceof Error) {
        logger.error("Fatal error occurred", { error: error.message });
    } else {
        logger.error("Unknown fatal error occurred", { error: String(error) });
    }
    process.exit(1);
});
</file>

<file path="src/test-setup.ts">
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { chromium } from 'playwright';
import { Octokit } from '@octokit/rest';
import axios from 'axios';
import dotenv from 'dotenv';
async function testSetup() {
  try {
    console.log('üîç Starting dependency verification...\n');
    // Test dotenv first to load environment variables
    dotenv.config();
    console.log('‚úÖ dotenv loaded successfully');
    // Test MCP SDK
    const server = new Server({
      name: "test-server",
      version: "1.0.0"
    }, {
      capabilities: {
        resources: {},
        tools: {}
      }
    });
    console.log('‚úÖ MCP SDK initialized successfully');
    // Test Playwright
    console.log('\nüåê Testing browser automation...');
    const browser = await chromium.launch();
    await browser.close();
    console.log('‚úÖ Playwright working correctly');
    // Test Octokit
    console.log('\nüì¶ Testing GitHub integration...');
    const octokit = new Octokit();
    const { status } = await octokit.rest.meta.root();
    console.log(`‚úÖ Octokit connected successfully (status: ${status})`);
    // Test Axios
    console.log('\nüîå Testing HTTP client...');
    const response = await axios.get('https://api.github.com');
    console.log(`‚úÖ Axios working correctly (status: ${response.status})`);
    console.log('\n‚ú® All dependencies verified successfully!');
  } catch (error) {
    console.error('\n‚ùå Setup test failed:', error);
    process.exit(1);
  }
}
testSetup();
</file>

<file path="src/test/jest.setup.ts">
import { jest } from '@jest/globals';
// Set up test environment
process.env.NODE_ENV = 'test';
process.env.PERPLEXITY_API_KEY = undefined;
// Mock config
jest.mock('../config/index', () => ({
  config: {
    env: 'test',
    perplexityApiKey: undefined,
    googleApiKey: 'test-api-key',
    logLevel: 'info'
  }
}));
</file>

<file path="src/transports/http.ts">
import { Transport } from '@modelcontextprotocol/sdk/dist/esm/shared/transport.js';
import { JSONRPCMessage } from '@modelcontextprotocol/sdk/dist/esm/types.js';
import express from 'express';
import { logger } from '../utils/logger.js';
/**
 * Server transport for HTTP: this will send and receive messages over HTTP.
 * 
 * This transport is only available in Node.js environments.
 */
export class HttpServerTransport implements Transport {
    private _app: express.Application;
    private _path: string;
    private _sessionId: string;
    onclose?: () => void;
    onerror?: (error: Error) => void;
    onmessage?: (message: JSONRPCMessage) => void;
    /**
     * Creates a new HTTP server transport.
     * 
     * @param app Express application instance
     * @param options Configuration options
     */
    constructor(app: express.Application, options: { path?: string } = {}) {
        this._app = app;
        this._path = options.path || '/mcp';
        this._sessionId = Math.random().toString(36).substring(2, 15);
        // Set up the endpoint to receive messages
        this._app.post(this._path, express.json(), async (req, res) => {
            try {
                const message = req.body;
                logger.debug('Received message', { message });
                if (this.onmessage) {
                    // Handle the message
                    await this.handleMessage(message);
                    // Send a success response
                    res.status(200).json({ success: true });
                } else {
                    logger.warn('No message handler registered');
                    res.status(500).json({ error: 'No message handler registered' });
                }
            } catch (error) {
                logger.error('Error handling message', { 
                    error: error instanceof Error ? error.message : String(error) 
                });
                res.status(500).json({ 
                    error: error instanceof Error ? error.message : 'Unknown error' 
                });
                if (this.onerror && error instanceof Error) {
                    this.onerror(error);
                }
            }
        });
        logger.info('HTTP transport initialized', { path: this._path });
    }
    /**
     * Starts the transport.
     */
    async start(): Promise<void> {
        logger.info('Starting HTTP transport');
        // HTTP transport is ready as soon as it's created
        // No additional setup needed
    }
    /**
     * Handles a client message.
     */
    async handleMessage(message: unknown): Promise<void> {
        if (this.onmessage) {
            this.onmessage(message as JSONRPCMessage);
        }
    }
    /**
     * Closes the transport.
     */
    async close(): Promise<void> {
        logger.info('Closing HTTP transport');
        if (this.onclose) {
            this.onclose();
        }
    }
    /**
     * Sends a message to the client.
     * 
     * Note: Since HTTP is request/response based, this will log the message
     * but it can't actually send it to the client unless the client is making
     * a request at that moment.
     */
    async send(message: JSONRPCMessage): Promise<void> {
        logger.debug('Sending message', { message });
        // In a real implementation, this might use a queue or WebSocket to send messages
        // For now, we just log it since HTTP is request/response based
    }
    /**
     * Returns the session ID for this transport.
     */
    get sessionId(): string {
        return this._sessionId;
    }
}
</file>

<file path="src/transports/sse.ts">
import { Transport } from '@modelcontextprotocol/sdk/dist/esm/shared/transport.js';
import { JSONRPCMessage } from '@modelcontextprotocol/sdk/dist/esm/types.js';
import express from 'express';
import { logger } from '../utils/logger.js';
/**
 * Server transport for SSE: this will send messages over an SSE connection and receive messages from HTTP POST requests.
 * 
 * This transport is only available in Node.js environments.
 */
export class SSEServerTransport implements Transport {
    private _app: express.Application;
    private _path: string;
    private _sessionId: string;
    private _clients: Map<string, express.Response>;
    private _messageQueue: Map<string, JSONRPCMessage[]>;
    onclose?: () => void;
    onerror?: (error: Error) => void;
    onmessage?: (message: JSONRPCMessage) => void;
    /**
     * Creates a new SSE server transport.
     * 
     * @param app Express application instance
     * @param options Configuration options
     */
    constructor(app: express.Application, options: { path?: string } = {}) {
        this._app = app;
        this._path = options.path || '/mcp-sse';
        this._sessionId = Math.random().toString(36).substring(2, 15);
        this._clients = new Map();
        this._messageQueue = new Map();
        // Set up the SSE endpoint
        this._app.get(this._path, (req, res) => {
            const clientId = req.query.clientId as string || Math.random().toString(36).substring(2, 15);
            // Set headers for SSE
            res.setHeader('Content-Type', 'text/event-stream');
            res.setHeader('Cache-Control', 'no-cache');
            res.setHeader('Connection', 'keep-alive');
            res.setHeader('X-Accel-Buffering', 'no'); // Disable Nginx buffering
            // Send initial connection message
            res.write(`data: ${JSON.stringify({ type: 'connection', clientId })}\n\n`);
            // Store the client connection
            this._clients.set(clientId, res);
            logger.info('SSE client connected', { clientId, path: this._path });
            // Send any queued messages
            const queuedMessages = this._messageQueue.get(clientId) || [];
            if (queuedMessages.length > 0) {
                logger.debug('Sending queued messages', { count: queuedMessages.length });
                queuedMessages.forEach(message => {
                    res.write(`data: ${JSON.stringify(message)}\n\n`);
                });
                this._messageQueue.delete(clientId);
            }
            // Handle client disconnect
            req.on('close', () => {
                logger.info('SSE client disconnected', { clientId });
                this._clients.delete(clientId);
            });
        });
        // Set up the endpoint to receive messages
        this._app.post(`${this._path}/message`, express.json(), async (req, res) => {
            try {
                const message = req.body;
                const clientId = req.query.clientId as string;
                logger.debug('Received message', { message, clientId });
                if (this.onmessage) {
                    // Handle the message
                    await this.handleMessage(message);
                    // Send a success response
                    res.status(200).json({ success: true });
                } else {
                    logger.warn('No message handler registered');
                    res.status(500).json({ error: 'No message handler registered' });
                }
            } catch (error) {
                logger.error('Error handling message', { 
                    error: error instanceof Error ? error.message : String(error) 
                });
                res.status(500).json({ 
                    error: error instanceof Error ? error.message : 'Unknown error' 
                });
                if (this.onerror && error instanceof Error) {
                    this.onerror(error);
                }
            }
        });
        // Send keep-alive messages every 30 seconds
        setInterval(() => {
            this._clients.forEach((client, clientId) => {
                try {
                    client.write(': keep-alive\n\n');
                } catch (error) {
                    logger.error('Error sending keep-alive', { 
                        clientId,
                        error: error instanceof Error ? error.message : String(error) 
                    });
                    this._clients.delete(clientId);
                }
            });
        }, 30000);
        logger.info('SSE transport initialized', { path: this._path });
    }
    /**
     * Starts the transport.
     */
    async start(): Promise<void> {
        logger.info('Starting SSE transport');
        // SSE transport is ready as soon as it's created
        // No additional setup needed
    }
    /**
     * Handles a client message.
     */
    async handleMessage(message: unknown): Promise<void> {
        if (this.onmessage) {
            this.onmessage(message as JSONRPCMessage);
        }
    }
    /**
     * Closes the transport.
     */
    async close(): Promise<void> {
        logger.info('Closing SSE transport');
        // Send close message to all clients
        this._clients.forEach((client, clientId) => {
            try {
                client.write(`data: ${JSON.stringify({ type: 'close' })}\n\n`);
                client.end();
            } catch (error) {
                logger.error('Error closing client connection', { 
                    clientId,
                    error: error instanceof Error ? error.message : String(error) 
                });
            }
        });
        this._clients.clear();
        this._messageQueue.clear();
        if (this.onclose) {
            this.onclose();
        }
    }
    /**
     * Sends a message to all connected clients.
     */
    async send(message: JSONRPCMessage): Promise<void> {
        logger.debug('Sending message to all clients', { 
            clientCount: this._clients.size,
            message 
        });
        this._clients.forEach((client, clientId) => {
            try {
                client.write(`data: ${JSON.stringify(message)}\n\n`);
            } catch (error) {
                logger.error('Error sending message to client', { 
                    clientId,
                    error: error instanceof Error ? error.message : String(error) 
                });
                // Queue the message for when the client reconnects
                const queuedMessages = this._messageQueue.get(clientId) || [];
                queuedMessages.push(message);
                this._messageQueue.set(clientId, queuedMessages);
                // Remove the client
                this._clients.delete(clientId);
            }
        });
    }
    /**
     * Returns the session ID for this transport.
     */
    get sessionId(): string {
        return this._sessionId;
    }
}
</file>

<file path="src/types/tool.ts">
import { z } from 'zod';
export interface Tool {
    name: string;
    version: string;
    description: string;
    execute: (request: unknown) => Promise<unknown>;
    requestSchema: z.ZodType;
    responseSchema: z.ZodType;
}
</file>

<file path="src/utils/__mocks__/logger.js">
import { jest } from '@jest/globals';
// Create a silent logger for tests
export const logger = {
  debug: jest.fn(),
  info: jest.fn(),
  warn: jest.fn(),
  error: jest.fn()
};
</file>

<file path="src/utils/__mocks__/rate-limiter.js">
import { jest } from '@jest/globals';
// Create a mock rate limiter
export class RateLimiter {
  constructor() {
    this.acquireToken = jest.fn().mockResolvedValue(undefined);
  }
}
</file>

<file path="src/utils/__tests__/rate-limiter.test.ts">
import { jest, beforeEach, describe, it, expect } from '@jest/globals';
import { RateLimiter } from '../rate-limiter.js';
// Mock Date.now
const mockDateNow = jest.spyOn(Date, 'now');
// Mock setTimeout
jest.spyOn(global, 'setTimeout').mockImplementation((callback: Function) => {
  callback();
  return null as unknown as NodeJS.Timeout;
});
// Mock logger
jest.mock('../logger', () => ({
  logger: {
    debug: jest.fn(),
    info: jest.fn(),
    warn: jest.fn(),
    error: jest.fn()
  }
}));
describe('RateLimiter', () => {
  beforeEach(() => {
    jest.clearAllMocks();
    // Start time at a fixed value
    mockDateNow.mockReturnValue(1000);
  });
  describe('constructor', () => {
    it('should initialize with default values', () => {
      const limiter = new RateLimiter('test');
      expect(limiter.getAvailableTokens()).toBe(100);
    });
    it('should initialize with custom values', () => {
      const limiter = new RateLimiter('test', {
        maxTokens: 50,
        initialTokens: 25,
        refillRate: 5
      });
      expect(limiter.getAvailableTokens()).toBe(25);
    });
  });
  describe('acquireToken', () => {
    it('should consume a token if available', async () => {
      const limiter = new RateLimiter('test', { maxTokens: 10, initialTokens: 10 });
      await limiter.acquireToken();
      expect(limiter.getAvailableTokens()).toBe(9);
    });
    it('should consume multiple tokens if cost is provided', async () => {
      const limiter = new RateLimiter('test', { maxTokens: 10, initialTokens: 10 });
      await limiter.acquireToken(3);
      expect(limiter.getAvailableTokens()).toBe(7);
    });
    it('should throw error if not enough tokens and waitForTokens is false', async () => {
      const limiter = new RateLimiter('test', { 
        maxTokens: 10, 
        initialTokens: 2,
        waitForTokens: false
      });
      await limiter.acquireToken(1); // First token
      await limiter.acquireToken(1); // Second token
      await expect(limiter.acquireToken(1)).rejects.toThrow('Rate limit exceeded for test');
    });
    it('should refill tokens based on time passed', async () => {
      const limiter = new RateLimiter('test', {
        maxTokens: 10,
        initialTokens: 1,
        refillRate: 1 // 1 token per second
      });
      // Use the one available token
      await limiter.acquireToken();
      expect(limiter.getAvailableTokens()).toBe(0);
      // Advance time by 5 seconds
      mockDateNow.mockReturnValue(6000); // 1000 + 5000
      // Should have 5 tokens now
      expect(limiter.getAvailableTokens()).toBe(5);
      // Use 3 tokens
      await limiter.acquireToken(3);
      expect(limiter.getAvailableTokens()).toBe(2);
    });
    it('should wait for tokens to become available if needed', async () => {
      const limiter = new RateLimiter('test', {
        maxTokens: 10,
        initialTokens: 1,
        refillRate: 1 // 1 token per second
      });
      // Use the one available token
      await limiter.acquireToken();
      // Mock time advancement when setTimeout is called
      let timeAdvanced = false;
      jest.spyOn(global, 'setTimeout').mockImplementationOnce((callback: Function) => {
        timeAdvanced = true;
        mockDateNow.mockReturnValue(3000); // Advance 2 seconds
        callback();
        return null as unknown as NodeJS.Timeout;
      });
      // Try to acquire 2 tokens, should wait
      const acquirePromise = limiter.acquireToken(2);
      await acquirePromise;
      expect(timeAdvanced).toBe(true);
      expect(limiter.getAvailableTokens()).toBe(0); // Should have used the 2 tokens that were added
    });
    it('should throw error if waiting exceeds maxWaitTime', async () => {
      const limiter = new RateLimiter('test', {
        maxTokens: 10,
        initialTokens: 0,
        refillRate: 0.1, // Very slow refill
        maxWaitTime: 1000 // Short wait time
      });
      // Mock time advancement to exceed maxWaitTime
      jest.spyOn(global, 'setTimeout').mockImplementationOnce((callback: Function) => {
        mockDateNow.mockReturnValue(3000); // Advance 2 seconds, which exceeds maxWaitTime
        callback();
        return null as unknown as NodeJS.Timeout;
      });
      await expect(limiter.acquireToken()).rejects.toThrow('Timed out waiting for rate limit tokens');
    });
  });
  describe('getAvailableTokens', () => {
    it('should return current token count after refill', () => {
      const limiter = new RateLimiter('test', {
        maxTokens: 10,
        initialTokens: 5,
        refillRate: 1
      });
      // Advance time by 3 seconds
      mockDateNow.mockReturnValue(4000);
      // Should have 8 tokens now (5 initial + 3 from refill)
      expect(limiter.getAvailableTokens()).toBe(8);
    });
    it('should not exceed maxTokens on refill', () => {
      const limiter = new RateLimiter('test', {
        maxTokens: 10,
        initialTokens: 5,
        refillRate: 1
      });
      // Advance time by 20 seconds
      mockDateNow.mockReturnValue(21000);
      // Should have maxTokens (10) now
      expect(limiter.getAvailableTokens()).toBe(10);
    });
  });
});
</file>

<file path="src/utils/logger.ts">
import { config } from '../config/index.js';
// Define log levels and their numeric values
const LogLevels = {
    debug: 0,
    info: 1,
    warn: 2,
    error: 3
} as const;
type LogLevel = keyof typeof LogLevels;
interface LogMessage {
    level: LogLevel;
    message: string;
    timestamp: string;
    context?: Record<string, unknown>;
}
class Logger {
    private currentLogLevel: LogLevel;
    constructor(logLevel: LogLevel = 'info') {
        this.currentLogLevel = logLevel;
    }
    private shouldLog(level: LogLevel): boolean {
        return LogLevels[level] >= LogLevels[this.currentLogLevel];
    }
    private formatMessage(level: LogLevel, message: string, context?: Record<string, unknown>): LogMessage {
        return {
            level,
            message,
            timestamp: new Date().toISOString(),
            context
        };
    }
    private log(level: LogLevel, message: string, context?: Record<string, unknown>) {
        if (!this.shouldLog(level)) return;
        const logMessage = this.formatMessage(level, message, context);
        const output = JSON.stringify(logMessage);
        switch (level) {
            case 'error':
                console.error(output);
                break;
            case 'warn':
                console.warn(output);
                break;
            default:
                console.log(output);
        }
    }
    debug(message: string, context?: Record<string, unknown>) {
        this.log('debug', message, context);
    }
    info(message: string, context?: Record<string, unknown>) {
        this.log('info', message, context);
    }
    warn(message: string, context?: Record<string, unknown>) {
        this.log('warn', message, context);
    }
    error(message: string, context?: Record<string, unknown>) {
        this.log('error', message, context);
    }
}
// Export singleton instance
export const logger = new Logger(config.logLevel);
</file>

<file path="src/utils/rate-limiter.ts">
import { logger } from './logger.js';
export interface RateLimiterOptions {
  /**
   * Maximum number of tokens in the bucket
   * @default 100
   */
  maxTokens?: number;
  /**
   * Token refill rate per second
   * @default 10
   */
  refillRate?: number;
  /**
   * Initial number of tokens in the bucket (defaults to maxTokens)
   */
  initialTokens?: number;
  /**
   * Whether to wait for tokens to become available (true) or throw an error (false)
   * @default true
   */
  waitForTokens?: boolean;
  /**
   * Maximum time to wait for tokens in milliseconds
   * @default 30000 (30 seconds)
   */
  maxWaitTime?: number;
}
/**
 * Rate limiter using the token bucket algorithm
 * Used to limit the rate of requests to external APIs
 */
export class RateLimiter {
  private tokens: number;
  private readonly maxTokens: number;
  private lastRefill: number;
  private readonly refillRate: number; // tokens per second
  private readonly waitForTokens: boolean;
  private readonly maxWaitTime: number;
  private readonly name: string;
  /**
   * Creates a new rate limiter
   * @param name Name of the rate limiter for logging purposes
   * @param options Configuration options
   */
  constructor(name: string, options: RateLimiterOptions = {}) {
    this.maxTokens = options.maxTokens ?? 100;
    this.tokens = options.initialTokens ?? this.maxTokens;
    this.lastRefill = Date.now();
    this.refillRate = options.refillRate ?? 10;
    this.waitForTokens = options.waitForTokens ?? true;
    this.maxWaitTime = options.maxWaitTime ?? 30000;
    this.name = name;
    logger.debug(`Rate limiter created`, {
      name,
      maxTokens: this.maxTokens,
      refillRate: this.refillRate,
      initialTokens: this.tokens
    });
  }
  /**
   * Refills tokens based on time passed since last refill
   * @private
   */
  private refillTokens(): void {
    const now = Date.now();
    const timePassed = now - this.lastRefill;
    const tokensToAdd = Math.floor((timePassed / 1000) * this.refillRate);
    if (tokensToAdd > 0) {
      this.tokens = Math.min(this.maxTokens, this.tokens + tokensToAdd);
      this.lastRefill = now;
      logger.debug(`Tokens refilled`, {
        name: this.name,
        added: tokensToAdd,
        current: this.tokens,
        max: this.maxTokens
      });
    }
  }
  /**
   * Acquires a token, waiting if necessary
   * @param cost Number of tokens to consume (default: 1)
   * @throws Error if no tokens are available and waitForTokens is false,
   *         or if the wait time exceeds maxWaitTime
   */
  async acquireToken(cost: number = 1): Promise<void> {
    const startTime = Date.now();
    // Refill tokens first
    this.refillTokens();
    // Check if enough tokens are available
    if (this.tokens >= cost) {
      this.tokens -= cost;
      logger.debug(`Token acquired`, {
        name: this.name,
        cost,
        remaining: this.tokens
      });
      return;
    }
    // If we shouldn't wait, throw an error
    if (!this.waitForTokens) {
      const error = new Error(`Rate limit exceeded for ${this.name}`);
      logger.warn(`Rate limit exceeded`, {
        name: this.name,
        available: this.tokens,
        requested: cost
      });
      throw error;
    }
    // Otherwise, wait for tokens to become available
    while (this.tokens < cost) {
      // Check if we've exceeded the maximum wait time
      if (Date.now() - startTime > this.maxWaitTime) {
        const error = new Error(`Timed out waiting for rate limit tokens for ${this.name}`);
        logger.warn(`Rate limit wait timeout`, {
          name: this.name,
          waitedMs: Date.now() - startTime,
          maxWaitTime: this.maxWaitTime
        });
        throw error;
      }
      // Calculate time until next token is available
      const tokensNeeded = cost - this.tokens;
      const timeToWait = Math.ceil((tokensNeeded / this.refillRate) * 1000);
      logger.debug(`Waiting for tokens`, {
        name: this.name,
        tokensNeeded,
        timeToWait,
        waitedSoFar: Date.now() - startTime
      });
      // Wait for the calculated time
      await new Promise<void>(resolve => setTimeout(resolve, Math.min(timeToWait, 1000)));
      // Refill tokens after waiting
      this.refillTokens();
    }
    // Consume tokens
    this.tokens -= cost;
    logger.debug(`Token acquired after waiting`, {
      name: this.name,
      cost,
      remaining: this.tokens,
      waitedMs: Date.now() - startTime
    });
  }
  /**
   * Gets the current number of available tokens
   */
  getAvailableTokens(): number {
    this.refillTokens();
    return this.tokens;
  }
}
// Export a factory function to create rate limiters
export function createRateLimiter(name: string, options?: RateLimiterOptions): RateLimiter {
  return new RateLimiter(name, options);
}
</file>

<file path="src/web-interface.ts">
import express from 'express';
import path from 'path';
import { logger } from './utils/logger.js';
/**
 * Creates and configures an Express server to serve the web interface
 * @param port The port to listen on
 * @returns The configured Express app
 */
export function createWebInterface(port: number = 3002): express.Express {
  const app = express();
  // Serve static files from the public directory
  app.use(express.static(path.join(process.cwd(), 'public')));
  // Start the server
  app.listen(port, () => {
    logger.info(`Web interface server started on port ${port}`);
    logger.info(`Open http://localhost:${port} in your browser to access the web interface`);
  });
  return app;
}
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "allowJs": true,
    "declaration": true,
    "isolatedModules": true,
    "allowSyntheticDefaultImports": true,
    "verbatimModuleSyntax": true,
    "sourceMap": true,
    "baseUrl": ".",
    "paths": {
      "*": ["node_modules/*"]
    }
  },
  "ts-node": {
    "esm": true,
    "experimentalSpecifiers": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
</file>

<file path="wiki-home.md">
# Developer Tools Wiki

Welcome to the Developer Tools wiki! This wiki contains detailed documentation about the project's architecture, components, and usage guides.

## Navigation

* [Getting Started](Getting-Started)
* [Architecture Overview](Architecture-Overview)
* [API Documentation](API-Documentation)
* [Development Guide](Development-Guide)
* [Deployment Guide](Deployment-Guide)
* [Troubleshooting](Troubleshooting)

## Quick Links

* [MCP Server Documentation](MCP-Server)
* [Web Search Integration](Web-Search)
* [Repository Analysis](Repository-Analysis)
* [Browser Automation](Browser-Automation)

## Contributing

* [Development Setup](Development-Setup)
* [Coding Standards](Coding-Standards)
* [Testing Guidelines](Testing-Guidelines)
* [Pull Request Process](Pull-Request-Process)

## Support

* [FAQ](FAQ)
* [Known Issues](Known-Issues)
* [Release Notes](Release-Notes)

## Additional Resources

* [External Dependencies](External-Dependencies)
* [Security Guidelines](Security-Guidelines)
* [Performance Optimization](Performance-Optimization)

---
**Note**: This wiki is under active development. If you find any issues or have suggestions for improvement, please feel free to contribute or raise an issue in the main repository.
</file>

</files>
